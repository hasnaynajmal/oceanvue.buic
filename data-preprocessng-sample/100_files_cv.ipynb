{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "Model Pre Work\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Libraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = pd.read_csv(r'./100_files_mfcc.csv')\n",
    "ex_data['Features'] = ex_data['Features'].apply(lambda x: list(map(float, x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-351.6251220703125, 86.87262725830078, -14.98...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-433.6374816894531, 102.78813934326172, 4.263...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-459.4378967285156, 118.9866714477539, 14.566...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-503.5106201171875, 129.89466857910156, 12.60...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-290.6701965332031, 115.29109191894531, -9.09...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>[-497.34600830078125, 64.05010986328125, -9.53...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>[-507.68927001953125, 109.86592102050781, 2.85...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>[-408.8243408203125, 100.6327133178711, -5.617...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>[-433.462646484375, 86.5696029663086, -6.83201...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>[-443.96453857421875, 85.13563537597656, -11.1...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Features  Class\n",
       "0    [-351.6251220703125, 86.87262725830078, -14.98...  Cargo\n",
       "1    [-433.6374816894531, 102.78813934326172, 4.263...  Cargo\n",
       "2    [-459.4378967285156, 118.9866714477539, 14.566...  Cargo\n",
       "3    [-503.5106201171875, 129.89466857910156, 12.60...  Cargo\n",
       "4    [-290.6701965332031, 115.29109191894531, -9.09...  Cargo\n",
       "..                                                 ...    ...\n",
       "365  [-497.34600830078125, 64.05010986328125, -9.53...    Tug\n",
       "366  [-507.68927001953125, 109.86592102050781, 2.85...    Tug\n",
       "367  [-408.8243408203125, 100.6327133178711, -5.617...    Tug\n",
       "368  [-433.462646484375, 86.5696029663086, -6.83201...    Tug\n",
       "369  [-443.96453857421875, 85.13563537597656, -11.1...    Tug\n",
       "\n",
       "[370 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(ex_data['Features'].tolist())\n",
    "y=np.array(ex_data['Class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc Features       :  (370, 40)\n",
      "Class Labels shape  :  (370,)\n"
     ]
    }
   ],
   "source": [
    "print('mfcc Features       : ',X.shape)\n",
    "print('Class Labels shape  : ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy_1 = X\n",
    "y_copy_1 = y\n",
    "\n",
    "X_copy_2 = X\n",
    "y_copy_2 = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding the class labels of y_copy_1\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_copy_1 = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_copy_1,y_copy_1,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total count for all audio files loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo: 100\n",
      "Passenger: 100\n",
      "Tanker: 101\n",
      "Tug: 69\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each category\n",
    "category_count = Counter(y)\n",
    "\n",
    "# Print the total count of each category\n",
    "for category, count in category_count.items():\n",
    "    print(f'{category}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total count for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 58\n",
      "0: 76\n",
      "2: 82\n",
      "1: 80\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each category\n",
    "category_count = Counter(y_train)\n",
    "\n",
    "# Print the total count of each category\n",
    "for category, count in category_count.items():\n",
    "    print(f'{category}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "Machine Learning Models\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Parameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': [0.1, 1, 10] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(svm_pipeline, param_grid, cv=4, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_svm_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Accuracy for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters  :: {'svm__C': 1, 'svm__gamma': 0.1}\n",
      "Test Accuracy    :: 0.7162162162162162\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = best_svm_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Best Parameters  ::\", best_params)\n",
    "print(\"Test Accuracy    ::\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "#new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "\n",
    "cm_percent = cm / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "plt.figure(figsize=(8, 5))\n",
    "sn.heatmap(cm_percent, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "\n",
    "ax = plt.gca()\n",
    "for t in ax.texts:\n",
    "    t.set_text(t.get_text() + \"  %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.74        24\n",
      "           1       0.61      0.95      0.75        20\n",
      "           2       0.63      0.63      0.63        19\n",
      "           3       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.72        74\n",
      "   macro avg       0.76      0.72      0.72        74\n",
      "weighted avg       0.77      0.72      0.72        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "Deep Learning Models\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "Basic ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model --- Needs to understand this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44804 (175.02 KB)\n",
      "Trainable params: 44804 (175.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/10 [==>...........................] - ETA: 4s - loss: 70.8732 - accuracy: 0.3125\n",
      "Epoch 1: val_loss improved from inf to 4.52951, saving model to saved_models\\audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oceanvue\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 79ms/step - loss: 60.5340 - accuracy: 0.2432 - val_loss: 4.5295 - val_accuracy: 0.4054\n",
      "Epoch 2/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 53.0916 - accuracy: 0.1562\n",
      "Epoch 2: val_loss did not improve from 4.52951\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.7570 - accuracy: 0.2061 - val_loss: 9.7846 - val_accuracy: 0.1486\n",
      "Epoch 3/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 36.4606 - accuracy: 0.2188\n",
      "Epoch 3: val_loss improved from 4.52951 to 2.99815, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 26.8810 - accuracy: 0.2331 - val_loss: 2.9981 - val_accuracy: 0.1486\n",
      "Epoch 4/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 21.4584 - accuracy: 0.2812\n",
      "Epoch 4: val_loss improved from 2.99815 to 1.60251, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23.2180 - accuracy: 0.2466 - val_loss: 1.6025 - val_accuracy: 0.2838\n",
      "Epoch 5/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.5467 - accuracy: 0.3125\n",
      "Epoch 5: val_loss improved from 1.60251 to 1.54203, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.9026 - accuracy: 0.2635 - val_loss: 1.5420 - val_accuracy: 0.3108\n",
      "Epoch 6/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 25.9840 - accuracy: 0.1562\n",
      "Epoch 6: val_loss did not improve from 1.54203\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 15.8872 - accuracy: 0.2838 - val_loss: 1.6961 - val_accuracy: 0.3243\n",
      "Epoch 7/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.6771 - accuracy: 0.2500\n",
      "Epoch 7: val_loss improved from 1.54203 to 1.35009, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.6722 - accuracy: 0.2162 - val_loss: 1.3501 - val_accuracy: 0.3108\n",
      "Epoch 8/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 9.6643 - accuracy: 0.3438\n",
      "Epoch 8: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.6879 - accuracy: 0.2804 - val_loss: 1.4159 - val_accuracy: 0.2703\n",
      "Epoch 9/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 10.4788 - accuracy: 0.3438\n",
      "Epoch 9: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.5860 - accuracy: 0.2872 - val_loss: 1.3680 - val_accuracy: 0.4459\n",
      "Epoch 10/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.5758 - accuracy: 0.3438\n",
      "Epoch 10: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.9070 - accuracy: 0.2973 - val_loss: 1.3967 - val_accuracy: 0.3514\n",
      "Epoch 11/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 9.0873 - accuracy: 0.2188\n",
      "Epoch 11: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.0243 - accuracy: 0.2365 - val_loss: 1.3970 - val_accuracy: 0.3378\n",
      "Epoch 12/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.4567 - accuracy: 0.2812\n",
      "Epoch 12: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.5864 - accuracy: 0.2703 - val_loss: 1.4068 - val_accuracy: 0.2838\n",
      "Epoch 13/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.2334 - accuracy: 0.3125\n",
      "Epoch 13: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1162 - accuracy: 0.2432 - val_loss: 1.4100 - val_accuracy: 0.1892\n",
      "Epoch 14/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.7447 - accuracy: 0.2188\n",
      "Epoch 14: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1131 - accuracy: 0.2770 - val_loss: 1.4094 - val_accuracy: 0.0946\n",
      "Epoch 15/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.1589 - accuracy: 0.3438\n",
      "Epoch 15: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9023 - accuracy: 0.2939 - val_loss: 1.4027 - val_accuracy: 0.0405\n",
      "Epoch 16/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.1298 - accuracy: 0.2500\n",
      "Epoch 16: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8339 - accuracy: 0.2061 - val_loss: 1.3917 - val_accuracy: 0.2027\n",
      "Epoch 17/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.6751 - accuracy: 0.1250\n",
      "Epoch 17: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0743 - accuracy: 0.2297 - val_loss: 1.3861 - val_accuracy: 0.3378\n",
      "Epoch 18/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.0541 - accuracy: 0.3438\n",
      "Epoch 18: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8475 - accuracy: 0.2568 - val_loss: 1.3856 - val_accuracy: 0.3243\n",
      "Epoch 19/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.0324 - accuracy: 0.1562\n",
      "Epoch 19: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6515 - accuracy: 0.2264 - val_loss: 1.3853 - val_accuracy: 0.2703\n",
      "Epoch 20/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.1385 - accuracy: 0.3438\n",
      "Epoch 20: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3.3360 - accuracy: 0.2162 - val_loss: 1.3850 - val_accuracy: 0.2703\n",
      "Epoch 21/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.6432 - accuracy: 0.2812\n",
      "Epoch 21: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1395 - accuracy: 0.2432 - val_loss: 1.3849 - val_accuracy: 0.2703\n",
      "Epoch 22/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.0601 - accuracy: 0.2500\n",
      "Epoch 22: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8741 - accuracy: 0.2128 - val_loss: 1.3846 - val_accuracy: 0.2703\n",
      "Epoch 23/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.7644 - accuracy: 0.1875\n",
      "Epoch 23: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4881 - accuracy: 0.2838 - val_loss: 1.3842 - val_accuracy: 0.2703\n",
      "Epoch 24/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0052 - accuracy: 0.2188\n",
      "Epoch 24: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4309 - accuracy: 0.2196 - val_loss: 1.3836 - val_accuracy: 0.2703\n",
      "Epoch 25/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9522 - accuracy: 0.2188\n",
      "Epoch 25: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3547 - accuracy: 0.2568 - val_loss: 1.3833 - val_accuracy: 0.2703\n",
      "Epoch 26/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6398 - accuracy: 0.2188\n",
      "Epoch 26: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1206 - accuracy: 0.2399 - val_loss: 1.3829 - val_accuracy: 0.2703\n",
      "Epoch 27/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.5748 - accuracy: 0.2500\n",
      "Epoch 27: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1701 - accuracy: 0.2534 - val_loss: 1.3827 - val_accuracy: 0.2703\n",
      "Epoch 28/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0723 - accuracy: 0.1875\n",
      "Epoch 28: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9594 - accuracy: 0.2230 - val_loss: 1.3825 - val_accuracy: 0.2703\n",
      "Epoch 29/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7123 - accuracy: 0.2812\n",
      "Epoch 29: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0799 - accuracy: 0.2162 - val_loss: 1.3820 - val_accuracy: 0.2703\n",
      "Epoch 30/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0683 - accuracy: 0.3438\n",
      "Epoch 30: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9180 - accuracy: 0.2669 - val_loss: 1.3816 - val_accuracy: 0.2703\n",
      "Epoch 31/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9427 - accuracy: 0.3125\n",
      "Epoch 31: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9257 - accuracy: 0.2399 - val_loss: 1.3812 - val_accuracy: 0.2703\n",
      "Epoch 32/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5535 - accuracy: 0.2500\n",
      "Epoch 32: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7636 - accuracy: 0.2669 - val_loss: 1.3807 - val_accuracy: 0.2703\n",
      "Epoch 33/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.3665 - accuracy: 0.2188\n",
      "Epoch 33: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6631 - accuracy: 0.2804 - val_loss: 1.3802 - val_accuracy: 0.2703\n",
      "Epoch 34/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7746 - accuracy: 0.2500\n",
      "Epoch 34: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6965 - accuracy: 0.2736 - val_loss: 1.3798 - val_accuracy: 0.2703\n",
      "Epoch 35/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8205 - accuracy: 0.3438\n",
      "Epoch 35: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7388 - accuracy: 0.2939 - val_loss: 1.3795 - val_accuracy: 0.2703\n",
      "Epoch 36/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9989 - accuracy: 0.2188\n",
      "Epoch 36: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7342 - accuracy: 0.2770 - val_loss: 1.3791 - val_accuracy: 0.2703\n",
      "Epoch 37/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4804 - accuracy: 0.2812\n",
      "Epoch 37: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7712 - accuracy: 0.2770 - val_loss: 1.3785 - val_accuracy: 0.2703\n",
      "Epoch 38/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7117 - accuracy: 0.1250\n",
      "Epoch 38: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7871 - accuracy: 0.2162 - val_loss: 1.3782 - val_accuracy: 0.2703\n",
      "Epoch 39/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9171 - accuracy: 0.3750\n",
      "Epoch 39: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7191 - accuracy: 0.2635 - val_loss: 1.3780 - val_accuracy: 0.2703\n",
      "Epoch 40/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6849 - accuracy: 0.2500\n",
      "Epoch 40: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6025 - accuracy: 0.2804 - val_loss: 1.3777 - val_accuracy: 0.2703\n",
      "Epoch 41/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4901 - accuracy: 0.2812\n",
      "Epoch 41: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7393 - accuracy: 0.2736 - val_loss: 1.3775 - val_accuracy: 0.2703\n",
      "Epoch 42/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5098 - accuracy: 0.3750\n",
      "Epoch 42: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5793 - accuracy: 0.3041 - val_loss: 1.3772 - val_accuracy: 0.2703\n",
      "Epoch 43/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4429 - accuracy: 0.1875\n",
      "Epoch 43: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5789 - accuracy: 0.2838 - val_loss: 1.3768 - val_accuracy: 0.2703\n",
      "Epoch 44/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5043 - accuracy: 0.2812\n",
      "Epoch 44: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6391 - accuracy: 0.2669 - val_loss: 1.3767 - val_accuracy: 0.2703\n",
      "Epoch 45/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4465 - accuracy: 0.1875\n",
      "Epoch 45: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4943 - accuracy: 0.3108 - val_loss: 1.3767 - val_accuracy: 0.2703\n",
      "Epoch 46/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5833 - accuracy: 0.3750\n",
      "Epoch 46: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5548 - accuracy: 0.2669 - val_loss: 1.3766 - val_accuracy: 0.2703\n",
      "Epoch 47/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6973 - accuracy: 0.2500\n",
      "Epoch 47: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6625 - accuracy: 0.2669 - val_loss: 1.3764 - val_accuracy: 0.2703\n",
      "Epoch 48/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8281 - accuracy: 0.2188\n",
      "Epoch 48: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5368 - accuracy: 0.2534 - val_loss: 1.3761 - val_accuracy: 0.2703\n",
      "Epoch 49/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6580 - accuracy: 0.3125\n",
      "Epoch 49: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4904 - accuracy: 0.2669 - val_loss: 1.3757 - val_accuracy: 0.2703\n",
      "Epoch 50/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3976 - accuracy: 0.1875\n",
      "Epoch 50: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4846 - accuracy: 0.2635 - val_loss: 1.3756 - val_accuracy: 0.2703\n",
      "Epoch 51/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5059 - accuracy: 0.1562\n",
      "Epoch 51: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4736 - accuracy: 0.2466 - val_loss: 1.3754 - val_accuracy: 0.2703\n",
      "Epoch 52/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3574 - accuracy: 0.3125\n",
      "Epoch 52: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5656 - accuracy: 0.2804 - val_loss: 1.3753 - val_accuracy: 0.2703\n",
      "Epoch 53/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4108 - accuracy: 0.3125\n",
      "Epoch 53: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4978 - accuracy: 0.2601 - val_loss: 1.3750 - val_accuracy: 0.2703\n",
      "Epoch 54/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4767 - accuracy: 0.2500\n",
      "Epoch 54: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5000 - accuracy: 0.3007 - val_loss: 1.3750 - val_accuracy: 0.2703\n",
      "Epoch 55/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3564 - accuracy: 0.2812\n",
      "Epoch 55: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4781 - accuracy: 0.2534 - val_loss: 1.3746 - val_accuracy: 0.2703\n",
      "Epoch 56/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4666 - accuracy: 0.2500\n",
      "Epoch 56: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5024 - accuracy: 0.2736 - val_loss: 1.3742 - val_accuracy: 0.2703\n",
      "Epoch 57/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5571 - accuracy: 0.3125\n",
      "Epoch 57: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5066 - accuracy: 0.2804 - val_loss: 1.3741 - val_accuracy: 0.2703\n",
      "Epoch 58/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5972 - accuracy: 0.2188\n",
      "Epoch 58: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4411 - accuracy: 0.2905 - val_loss: 1.3738 - val_accuracy: 0.2703\n",
      "Epoch 59/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3500 - accuracy: 0.2812\n",
      "Epoch 59: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3918 - accuracy: 0.2770 - val_loss: 1.3735 - val_accuracy: 0.2703\n",
      "Epoch 60/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3830 - accuracy: 0.2500\n",
      "Epoch 60: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3954 - accuracy: 0.2973 - val_loss: 1.3734 - val_accuracy: 0.2703\n",
      "Epoch 61/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5686 - accuracy: 0.1875\n",
      "Epoch 61: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4756 - accuracy: 0.2905 - val_loss: 1.3735 - val_accuracy: 0.2703\n",
      "Epoch 62/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6249 - accuracy: 0.3125\n",
      "Epoch 62: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4628 - accuracy: 0.2534 - val_loss: 1.3733 - val_accuracy: 0.2703\n",
      "Epoch 63/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4094 - accuracy: 0.2500\n",
      "Epoch 63: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4628 - accuracy: 0.2770 - val_loss: 1.3732 - val_accuracy: 0.2703\n",
      "Epoch 64/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5113 - accuracy: 0.2188\n",
      "Epoch 64: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4825 - accuracy: 0.2601 - val_loss: 1.3731 - val_accuracy: 0.2703\n",
      "Epoch 65/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5052 - accuracy: 0.2812\n",
      "Epoch 65: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4439 - accuracy: 0.3041 - val_loss: 1.3731 - val_accuracy: 0.2703\n",
      "Epoch 66/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3900 - accuracy: 0.0625\n",
      "Epoch 66: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4436 - accuracy: 0.2500 - val_loss: 1.3728 - val_accuracy: 0.2703\n",
      "Epoch 67/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7835 - accuracy: 0.3125\n",
      "Epoch 67: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4847 - accuracy: 0.3074 - val_loss: 1.3727 - val_accuracy: 0.2703\n",
      "Epoch 68/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4296 - accuracy: 0.3438\n",
      "Epoch 68: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4074 - accuracy: 0.3041 - val_loss: 1.3725 - val_accuracy: 0.2703\n",
      "Epoch 69/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3150 - accuracy: 0.1875\n",
      "Epoch 69: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3877 - accuracy: 0.2804 - val_loss: 1.3723 - val_accuracy: 0.2703\n",
      "Epoch 70/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7685 - accuracy: 0.1875\n",
      "Epoch 70: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4768 - accuracy: 0.2703 - val_loss: 1.3721 - val_accuracy: 0.2703\n",
      "Epoch 71/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3343 - accuracy: 0.3750\n",
      "Epoch 71: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4472 - accuracy: 0.2568 - val_loss: 1.3720 - val_accuracy: 0.2703\n",
      "Epoch 72/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3344 - accuracy: 0.2812\n",
      "Epoch 72: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4654 - accuracy: 0.2601 - val_loss: 1.3719 - val_accuracy: 0.2703\n",
      "Epoch 73/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4387 - accuracy: 0.1562\n",
      "Epoch 73: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4378 - accuracy: 0.2770 - val_loss: 1.3719 - val_accuracy: 0.2703\n",
      "Epoch 74/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4289 - accuracy: 0.2812\n",
      "Epoch 74: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4291 - accuracy: 0.3041 - val_loss: 1.3718 - val_accuracy: 0.2703\n",
      "Epoch 75/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3528 - accuracy: 0.2188\n",
      "Epoch 75: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4420 - accuracy: 0.2872 - val_loss: 1.3719 - val_accuracy: 0.2703\n",
      "Epoch 76/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3977 - accuracy: 0.3438\n",
      "Epoch 76: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4321 - accuracy: 0.2703 - val_loss: 1.3717 - val_accuracy: 0.2703\n",
      "Epoch 77/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6924 - accuracy: 0.3125\n",
      "Epoch 77: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4625 - accuracy: 0.2703 - val_loss: 1.3714 - val_accuracy: 0.2703\n",
      "Epoch 78/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3836 - accuracy: 0.2188\n",
      "Epoch 78: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4554 - accuracy: 0.2669 - val_loss: 1.3714 - val_accuracy: 0.2703\n",
      "Epoch 79/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4493 - accuracy: 0.3750\n",
      "Epoch 79: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4715 - accuracy: 0.2804 - val_loss: 1.3711 - val_accuracy: 0.2703\n",
      "Epoch 80/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3610 - accuracy: 0.4688\n",
      "Epoch 80: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5073 - accuracy: 0.2770 - val_loss: 1.3711 - val_accuracy: 0.2703\n",
      "Epoch 81/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3542 - accuracy: 0.3125\n",
      "Epoch 81: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4569 - accuracy: 0.2838 - val_loss: 1.3708 - val_accuracy: 0.2703\n",
      "Epoch 82/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4634 - accuracy: 0.2812\n",
      "Epoch 82: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4029 - accuracy: 0.2872 - val_loss: 1.3707 - val_accuracy: 0.2703\n",
      "Epoch 83/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3597 - accuracy: 0.3750\n",
      "Epoch 83: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4290 - accuracy: 0.2635 - val_loss: 1.3706 - val_accuracy: 0.2703\n",
      "Epoch 84/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3564 - accuracy: 0.2188\n",
      "Epoch 84: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4221 - accuracy: 0.2500 - val_loss: 1.3705 - val_accuracy: 0.2703\n",
      "Epoch 85/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4203 - accuracy: 0.2812\n",
      "Epoch 85: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4349 - accuracy: 0.2568 - val_loss: 1.3707 - val_accuracy: 0.2703\n",
      "Epoch 86/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4099 - accuracy: 0.1875\n",
      "Epoch 86: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4320 - accuracy: 0.2770 - val_loss: 1.3708 - val_accuracy: 0.2703\n",
      "Epoch 87/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3553 - accuracy: 0.2812\n",
      "Epoch 87: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3885 - accuracy: 0.2770 - val_loss: 1.3706 - val_accuracy: 0.2703\n",
      "Epoch 88/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4667 - accuracy: 0.1562\n",
      "Epoch 88: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4071 - accuracy: 0.2905 - val_loss: 1.3703 - val_accuracy: 0.2703\n",
      "Epoch 89/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3394 - accuracy: 0.2188\n",
      "Epoch 89: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4484 - accuracy: 0.2736 - val_loss: 1.3699 - val_accuracy: 0.2703\n",
      "Epoch 90/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5220 - accuracy: 0.2188\n",
      "Epoch 90: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3956 - accuracy: 0.2534 - val_loss: 1.3698 - val_accuracy: 0.2703\n",
      "Epoch 91/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4335 - accuracy: 0.3125\n",
      "Epoch 91: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4335 - accuracy: 0.2568 - val_loss: 1.3696 - val_accuracy: 0.2703\n",
      "Epoch 92/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4229 - accuracy: 0.2500\n",
      "Epoch 92: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4034 - accuracy: 0.2568 - val_loss: 1.3694 - val_accuracy: 0.2703\n",
      "Epoch 93/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3967 - accuracy: 0.1562\n",
      "Epoch 93: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4201 - accuracy: 0.2770 - val_loss: 1.3692 - val_accuracy: 0.2703\n",
      "Epoch 94/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3821 - accuracy: 0.2188\n",
      "Epoch 94: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3951 - accuracy: 0.2568 - val_loss: 1.3691 - val_accuracy: 0.2703\n",
      "Epoch 95/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3907 - accuracy: 0.0938\n",
      "Epoch 95: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.2770 - val_loss: 1.3690 - val_accuracy: 0.2703\n",
      "Epoch 96/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4212 - accuracy: 0.2500\n",
      "Epoch 96: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4020 - accuracy: 0.2736 - val_loss: 1.3689 - val_accuracy: 0.2703\n",
      "Epoch 97/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3697 - accuracy: 0.2188\n",
      "Epoch 97: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4061 - accuracy: 0.2500 - val_loss: 1.3688 - val_accuracy: 0.2703\n",
      "Epoch 98/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3816 - accuracy: 0.3438\n",
      "Epoch 98: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4261 - accuracy: 0.2635 - val_loss: 1.3688 - val_accuracy: 0.2703\n",
      "Epoch 99/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3444 - accuracy: 0.2188\n",
      "Epoch 99: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4173 - accuracy: 0.2703 - val_loss: 1.3687 - val_accuracy: 0.2703\n",
      "Epoch 100/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5240 - accuracy: 0.2500\n",
      "Epoch 100: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3843 - accuracy: 0.2703 - val_loss: 1.3686 - val_accuracy: 0.2703\n",
      "Epoch 101/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3626 - accuracy: 0.2188\n",
      "Epoch 101: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4089 - accuracy: 0.2703 - val_loss: 1.3687 - val_accuracy: 0.2703\n",
      "Epoch 102/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3815 - accuracy: 0.2500\n",
      "Epoch 102: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4301 - accuracy: 0.2770 - val_loss: 1.3686 - val_accuracy: 0.2703\n",
      "Epoch 103/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6533 - accuracy: 0.2812\n",
      "Epoch 103: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4418 - accuracy: 0.2703 - val_loss: 1.3684 - val_accuracy: 0.2703\n",
      "Epoch 104/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4392 - accuracy: 0.4062\n",
      "Epoch 104: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4060 - accuracy: 0.2736 - val_loss: 1.3684 - val_accuracy: 0.2703\n",
      "Epoch 105/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3662 - accuracy: 0.3125\n",
      "Epoch 105: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3916 - accuracy: 0.2703 - val_loss: 1.3684 - val_accuracy: 0.2703\n",
      "Epoch 106/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3971 - accuracy: 0.4375\n",
      "Epoch 106: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4198 - accuracy: 0.2770 - val_loss: 1.3685 - val_accuracy: 0.2703\n",
      "Epoch 107/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4565 - accuracy: 0.3125\n",
      "Epoch 107: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3940 - accuracy: 0.2905 - val_loss: 1.3684 - val_accuracy: 0.2703\n",
      "Epoch 108/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4649 - accuracy: 0.1875\n",
      "Epoch 108: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3953 - accuracy: 0.2466 - val_loss: 1.3682 - val_accuracy: 0.2703\n",
      "Epoch 109/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3858 - accuracy: 0.2500\n",
      "Epoch 109: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4096 - accuracy: 0.2838 - val_loss: 1.3683 - val_accuracy: 0.2703\n",
      "Epoch 110/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3882 - accuracy: 0.1875\n",
      "Epoch 110: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4166 - accuracy: 0.2736 - val_loss: 1.3682 - val_accuracy: 0.2703\n",
      "Epoch 111/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3952 - accuracy: 0.2812\n",
      "Epoch 111: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4276 - accuracy: 0.2770 - val_loss: 1.3682 - val_accuracy: 0.2703\n",
      "Epoch 112/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4241 - accuracy: 0.3125\n",
      "Epoch 112: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4282 - accuracy: 0.2838 - val_loss: 1.3682 - val_accuracy: 0.2703\n",
      "Epoch 113/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4464 - accuracy: 0.2188\n",
      "Epoch 113: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3999 - accuracy: 0.2736 - val_loss: 1.3681 - val_accuracy: 0.2703\n",
      "Epoch 114/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4110 - accuracy: 0.3125\n",
      "Epoch 114: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3853 - accuracy: 0.2838 - val_loss: 1.3681 - val_accuracy: 0.2703\n",
      "Epoch 115/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3803 - accuracy: 0.1875\n",
      "Epoch 115: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4183 - accuracy: 0.2534 - val_loss: 1.3680 - val_accuracy: 0.2703\n",
      "Epoch 116/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3980 - accuracy: 0.3750\n",
      "Epoch 116: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3961 - accuracy: 0.2973 - val_loss: 1.3681 - val_accuracy: 0.2703\n",
      "Epoch 117/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3398 - accuracy: 0.4375\n",
      "Epoch 117: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4078 - accuracy: 0.2669 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 118/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6155 - accuracy: 0.2812\n",
      "Epoch 118: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3990 - accuracy: 0.2804 - val_loss: 1.3678 - val_accuracy: 0.2703\n",
      "Epoch 119/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4590 - accuracy: 0.3125\n",
      "Epoch 119: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3926 - accuracy: 0.2770 - val_loss: 1.3678 - val_accuracy: 0.2703\n",
      "Epoch 120/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3921 - accuracy: 0.2188\n",
      "Epoch 120: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3956 - accuracy: 0.2669 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 121/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4900 - accuracy: 0.3438\n",
      "Epoch 121: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4061 - accuracy: 0.2770 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 122/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4460 - accuracy: 0.2812\n",
      "Epoch 122: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3869 - accuracy: 0.2736 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 123/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3766 - accuracy: 0.2500\n",
      "Epoch 123: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3894 - accuracy: 0.2500 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 124/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4483 - accuracy: 0.3438\n",
      "Epoch 124: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3718 - accuracy: 0.2669 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 125/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4418 - accuracy: 0.2812\n",
      "Epoch 125: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4172 - accuracy: 0.2703 - val_loss: 1.3679 - val_accuracy: 0.2703\n",
      "Epoch 126/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3589 - accuracy: 0.2812\n",
      "Epoch 126: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3786 - accuracy: 0.2703 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 127/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3336 - accuracy: 0.2812\n",
      "Epoch 127: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3901 - accuracy: 0.2804 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 128/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4047 - accuracy: 0.2500\n",
      "Epoch 128: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4051 - accuracy: 0.2669 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 129/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4049 - accuracy: 0.3125\n",
      "Epoch 129: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3820 - accuracy: 0.2770 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 130/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3283 - accuracy: 0.3438\n",
      "Epoch 130: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3723 - accuracy: 0.2804 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 131/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4622 - accuracy: 0.2188\n",
      "Epoch 131: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4101 - accuracy: 0.2568 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 132/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3409 - accuracy: 0.3438\n",
      "Epoch 132: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4003 - accuracy: 0.2872 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 133/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3833 - accuracy: 0.2812\n",
      "Epoch 133: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4005 - accuracy: 0.2703 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 134/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3495 - accuracy: 0.2500\n",
      "Epoch 134: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3779 - accuracy: 0.2466 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 135/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3928 - accuracy: 0.2812\n",
      "Epoch 135: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3786 - accuracy: 0.2770 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 136/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4009 - accuracy: 0.2188\n",
      "Epoch 136: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.2770 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 137/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3566 - accuracy: 0.2188\n",
      "Epoch 137: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3854 - accuracy: 0.2568 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 138/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4191 - accuracy: 0.1250\n",
      "Epoch 138: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3838 - accuracy: 0.2500 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 139/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3839 - accuracy: 0.2812\n",
      "Epoch 139: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3646 - accuracy: 0.2872 - val_loss: 1.3678 - val_accuracy: 0.2703\n",
      "Epoch 140/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3831 - accuracy: 0.3125\n",
      "Epoch 140: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3896 - accuracy: 0.2669 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 141/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3936 - accuracy: 0.2188\n",
      "Epoch 141: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3661 - accuracy: 0.2804 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 142/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3516 - accuracy: 0.2500\n",
      "Epoch 142: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3927 - accuracy: 0.3041 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 143/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3808 - accuracy: 0.3438\n",
      "Epoch 143: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3720 - accuracy: 0.2736 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 144/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3442 - accuracy: 0.3750\n",
      "Epoch 144: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4019 - accuracy: 0.2804 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 145/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4586 - accuracy: 0.2500\n",
      "Epoch 145: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3906 - accuracy: 0.2872 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 146/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3533 - accuracy: 0.2500\n",
      "Epoch 146: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3795 - accuracy: 0.2669 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 147/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3512 - accuracy: 0.2812\n",
      "Epoch 147: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3907 - accuracy: 0.2770 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 148/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3935 - accuracy: 0.3750\n",
      "Epoch 148: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3993 - accuracy: 0.2872 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 149/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4096 - accuracy: 0.3125\n",
      "Epoch 149: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3887 - accuracy: 0.2500 - val_loss: 1.3673 - val_accuracy: 0.2703\n",
      "Epoch 150/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4024 - accuracy: 0.1875\n",
      "Epoch 150: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3981 - accuracy: 0.2872 - val_loss: 1.3673 - val_accuracy: 0.2703\n",
      "Epoch 151/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3868 - accuracy: 0.3125\n",
      "Epoch 151: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3643 - accuracy: 0.2669 - val_loss: 1.3674 - val_accuracy: 0.2703\n",
      "Epoch 152/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4695 - accuracy: 0.2500\n",
      "Epoch 152: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4003 - accuracy: 0.2770 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 153/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3738 - accuracy: 0.1875\n",
      "Epoch 153: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3808 - accuracy: 0.2635 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 154/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4195 - accuracy: 0.4062\n",
      "Epoch 154: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4024 - accuracy: 0.2669 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 155/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3829 - accuracy: 0.2812\n",
      "Epoch 155: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3968 - accuracy: 0.2770 - val_loss: 1.3674 - val_accuracy: 0.2703\n",
      "Epoch 156/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3596 - accuracy: 0.2812\n",
      "Epoch 156: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3796 - accuracy: 0.2500 - val_loss: 1.3674 - val_accuracy: 0.2703\n",
      "Epoch 157/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3924 - accuracy: 0.3750\n",
      "Epoch 157: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3700 - accuracy: 0.3007 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 158/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3803 - accuracy: 0.2812\n",
      "Epoch 158: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3694 - accuracy: 0.2635 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 159/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3657 - accuracy: 0.2500\n",
      "Epoch 159: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3861 - accuracy: 0.2838 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 160/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4180 - accuracy: 0.1562\n",
      "Epoch 160: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4138 - accuracy: 0.2770 - val_loss: 1.3678 - val_accuracy: 0.2703\n",
      "Epoch 161/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4468 - accuracy: 0.2188\n",
      "Epoch 161: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4050 - accuracy: 0.2534 - val_loss: 1.3678 - val_accuracy: 0.2703\n",
      "Epoch 162/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3641 - accuracy: 0.2812\n",
      "Epoch 162: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3796 - accuracy: 0.2601 - val_loss: 1.3678 - val_accuracy: 0.2703\n",
      "Epoch 163/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4449 - accuracy: 0.2188\n",
      "Epoch 163: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3811 - accuracy: 0.2635 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 164/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4056 - accuracy: 0.2500\n",
      "Epoch 164: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3854 - accuracy: 0.2635 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 165/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4235 - accuracy: 0.2812\n",
      "Epoch 165: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3859 - accuracy: 0.2669 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 166/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3735 - accuracy: 0.2500\n",
      "Epoch 166: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3747 - accuracy: 0.2568 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 167/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3504 - accuracy: 0.3125\n",
      "Epoch 167: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3806 - accuracy: 0.2635 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 168/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3659 - accuracy: 0.2188\n",
      "Epoch 168: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3835 - accuracy: 0.2905 - val_loss: 1.3677 - val_accuracy: 0.2703\n",
      "Epoch 169/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3509 - accuracy: 0.2812\n",
      "Epoch 169: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3728 - accuracy: 0.2534 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 170/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3962 - accuracy: 0.2500\n",
      "Epoch 170: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3802 - accuracy: 0.2669 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 171/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3773 - accuracy: 0.2188\n",
      "Epoch 171: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3789 - accuracy: 0.2804 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 172/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3670 - accuracy: 0.2500\n",
      "Epoch 172: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3738 - accuracy: 0.2568 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 173/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3403 - accuracy: 0.5000\n",
      "Epoch 173: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3864 - accuracy: 0.2905 - val_loss: 1.3674 - val_accuracy: 0.2703\n",
      "Epoch 174/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4875 - accuracy: 0.2188\n",
      "Epoch 174: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3803 - accuracy: 0.2601 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 175/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3680 - accuracy: 0.2188\n",
      "Epoch 175: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4157 - accuracy: 0.2568 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 176/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3842 - accuracy: 0.3125\n",
      "Epoch 176: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3866 - accuracy: 0.2703 - val_loss: 1.3679 - val_accuracy: 0.2568\n",
      "Epoch 177/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3635 - accuracy: 0.3438\n",
      "Epoch 177: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3965 - accuracy: 0.2703 - val_loss: 1.3679 - val_accuracy: 0.2568\n",
      "Epoch 178/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3809 - accuracy: 0.2812\n",
      "Epoch 178: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3951 - accuracy: 0.2872 - val_loss: 1.3680 - val_accuracy: 0.2568\n",
      "Epoch 179/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3538 - accuracy: 0.2500\n",
      "Epoch 179: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4369 - accuracy: 0.2669 - val_loss: 1.3682 - val_accuracy: 0.2568\n",
      "Epoch 180/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3330 - accuracy: 0.3438\n",
      "Epoch 180: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3735 - accuracy: 0.2905 - val_loss: 1.3682 - val_accuracy: 0.2568\n",
      "Epoch 181/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3965 - accuracy: 0.1562\n",
      "Epoch 181: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3730 - accuracy: 0.2804 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 182/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4099 - accuracy: 0.3125\n",
      "Epoch 182: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3908 - accuracy: 0.2669 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 183/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3581 - accuracy: 0.3125\n",
      "Epoch 183: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3964 - accuracy: 0.2838 - val_loss: 1.3683 - val_accuracy: 0.2568\n",
      "Epoch 184/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3475 - accuracy: 0.3750\n",
      "Epoch 184: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3864 - accuracy: 0.2635 - val_loss: 1.3682 - val_accuracy: 0.2568\n",
      "Epoch 185/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4673 - accuracy: 0.2188\n",
      "Epoch 185: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3910 - accuracy: 0.2838 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 186/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4374 - accuracy: 0.2812\n",
      "Epoch 186: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.2905 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 187/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4017 - accuracy: 0.3750\n",
      "Epoch 187: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3927 - accuracy: 0.2331 - val_loss: 1.3681 - val_accuracy: 0.2703\n",
      "Epoch 188/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3664 - accuracy: 0.2188\n",
      "Epoch 188: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3881 - accuracy: 0.2399 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 189/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3691 - accuracy: 0.3438\n",
      "Epoch 189: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3872 - accuracy: 0.2669 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 190/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3449 - accuracy: 0.2812\n",
      "Epoch 190: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3802 - accuracy: 0.2703 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 191/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3149 - accuracy: 0.3438\n",
      "Epoch 191: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3777 - accuracy: 0.2736 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 192/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3409 - accuracy: 0.3125\n",
      "Epoch 192: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3777 - accuracy: 0.2770 - val_loss: 1.3682 - val_accuracy: 0.2568\n",
      "Epoch 193/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4096 - accuracy: 0.1250\n",
      "Epoch 193: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.2635 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 194/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3444 - accuracy: 0.3750\n",
      "Epoch 194: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3735 - accuracy: 0.2872 - val_loss: 1.3678 - val_accuracy: 0.2568\n",
      "Epoch 195/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3548 - accuracy: 0.3750\n",
      "Epoch 195: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3778 - accuracy: 0.2770 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 196/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4674 - accuracy: 0.1562\n",
      "Epoch 196: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3913 - accuracy: 0.2568 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 197/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3772 - accuracy: 0.1562\n",
      "Epoch 197: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3715 - accuracy: 0.2770 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 198/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3795 - accuracy: 0.2500\n",
      "Epoch 198: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3743 - accuracy: 0.2804 - val_loss: 1.3674 - val_accuracy: 0.2568\n",
      "Epoch 199/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3328 - accuracy: 0.2812\n",
      "Epoch 199: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3760 - accuracy: 0.2736 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 200/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4201 - accuracy: 0.2500\n",
      "Epoch 200: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3913 - accuracy: 0.2770 - val_loss: 1.3677 - val_accuracy: 0.2568\n",
      "Epoch 201/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4117 - accuracy: 0.1875\n",
      "Epoch 201: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3732 - accuracy: 0.2838 - val_loss: 1.3679 - val_accuracy: 0.2568\n",
      "Epoch 202/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3630 - accuracy: 0.3750\n",
      "Epoch 202: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3809 - accuracy: 0.2905 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 203/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3711 - accuracy: 0.2188\n",
      "Epoch 203: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3739 - accuracy: 0.2669 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 204/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4086 - accuracy: 0.1875\n",
      "Epoch 204: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3720 - accuracy: 0.2905 - val_loss: 1.3682 - val_accuracy: 0.2568\n",
      "Epoch 205/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3734 - accuracy: 0.3125\n",
      "Epoch 205: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3806 - accuracy: 0.2872 - val_loss: 1.3683 - val_accuracy: 0.2568\n",
      "Epoch 206/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3175 - accuracy: 0.3750\n",
      "Epoch 206: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3892 - accuracy: 0.2872 - val_loss: 1.3684 - val_accuracy: 0.2568\n",
      "Epoch 207/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3759 - accuracy: 0.1875\n",
      "Epoch 207: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3773 - accuracy: 0.2669 - val_loss: 1.3685 - val_accuracy: 0.2568\n",
      "Epoch 208/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4281 - accuracy: 0.1875\n",
      "Epoch 208: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3776 - accuracy: 0.2770 - val_loss: 1.3684 - val_accuracy: 0.2568\n",
      "Epoch 209/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4213 - accuracy: 0.3125\n",
      "Epoch 209: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3721 - accuracy: 0.2872 - val_loss: 1.3685 - val_accuracy: 0.2568\n",
      "Epoch 210/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3521 - accuracy: 0.2188\n",
      "Epoch 210: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4063 - accuracy: 0.2804 - val_loss: 1.3685 - val_accuracy: 0.2568\n",
      "Epoch 211/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4427 - accuracy: 0.4062\n",
      "Epoch 211: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3868 - accuracy: 0.2669 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 212/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4129 - accuracy: 0.2500\n",
      "Epoch 212: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3779 - accuracy: 0.2736 - val_loss: 1.3687 - val_accuracy: 0.2568\n",
      "Epoch 213/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4685 - accuracy: 0.2500\n",
      "Epoch 213: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3966 - accuracy: 0.2736 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 214/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3876 - accuracy: 0.1562\n",
      "Epoch 214: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3835 - accuracy: 0.2770 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 215/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3685 - accuracy: 0.2500\n",
      "Epoch 215: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3761 - accuracy: 0.2939 - val_loss: 1.3687 - val_accuracy: 0.2568\n",
      "Epoch 216/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3890 - accuracy: 0.2812\n",
      "Epoch 216: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3956 - accuracy: 0.2804 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 217/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3910 - accuracy: 0.2812\n",
      "Epoch 217: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3806 - accuracy: 0.2703 - val_loss: 1.3687 - val_accuracy: 0.2568\n",
      "Epoch 218/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4078 - accuracy: 0.2188\n",
      "Epoch 218: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3830 - accuracy: 0.2770 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 219/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3930 - accuracy: 0.3438\n",
      "Epoch 219: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3901 - accuracy: 0.2703 - val_loss: 1.3688 - val_accuracy: 0.2568\n",
      "Epoch 220/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3405 - accuracy: 0.2812\n",
      "Epoch 220: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3785 - accuracy: 0.2736 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 221/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4136 - accuracy: 0.2500\n",
      "Epoch 221: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3875 - accuracy: 0.2736 - val_loss: 1.3687 - val_accuracy: 0.2568\n",
      "Epoch 222/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3583 - accuracy: 0.3750\n",
      "Epoch 222: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3937 - accuracy: 0.2804 - val_loss: 1.3688 - val_accuracy: 0.2568\n",
      "Epoch 223/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3534 - accuracy: 0.1562\n",
      "Epoch 223: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3703 - accuracy: 0.2601 - val_loss: 1.3687 - val_accuracy: 0.2568\n",
      "Epoch 224/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3654 - accuracy: 0.2812\n",
      "Epoch 224: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3686 - accuracy: 0.2872 - val_loss: 1.3688 - val_accuracy: 0.2568\n",
      "Epoch 225/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4533 - accuracy: 0.2500\n",
      "Epoch 225: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3869 - accuracy: 0.2736 - val_loss: 1.3686 - val_accuracy: 0.2568\n",
      "Epoch 226/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3786 - accuracy: 0.3125\n",
      "Epoch 226: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3751 - accuracy: 0.2804 - val_loss: 1.3684 - val_accuracy: 0.2568\n",
      "Epoch 227/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3718 - accuracy: 0.2188\n",
      "Epoch 227: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3796 - accuracy: 0.2804 - val_loss: 1.3684 - val_accuracy: 0.2568\n",
      "Epoch 228/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4008 - accuracy: 0.3125\n",
      "Epoch 228: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3799 - accuracy: 0.2804 - val_loss: 1.3684 - val_accuracy: 0.2568\n",
      "Epoch 229/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4358 - accuracy: 0.1562\n",
      "Epoch 229: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3751 - accuracy: 0.2838 - val_loss: 1.3685 - val_accuracy: 0.2568\n",
      "Epoch 230/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4653 - accuracy: 0.2500\n",
      "Epoch 230: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3795 - accuracy: 0.2703 - val_loss: 1.3683 - val_accuracy: 0.2568\n",
      "Epoch 231/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3684 - accuracy: 0.2500\n",
      "Epoch 231: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3650 - accuracy: 0.2838 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 232/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3560 - accuracy: 0.2188\n",
      "Epoch 232: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3922 - accuracy: 0.2973 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 233/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3993 - accuracy: 0.2188\n",
      "Epoch 233: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3729 - accuracy: 0.2736 - val_loss: 1.3680 - val_accuracy: 0.2568\n",
      "Epoch 234/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3534 - accuracy: 0.3438\n",
      "Epoch 234: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3823 - accuracy: 0.2838 - val_loss: 1.3677 - val_accuracy: 0.2568\n",
      "Epoch 235/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3894 - accuracy: 0.1250\n",
      "Epoch 235: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3864 - accuracy: 0.2432 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 236/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4598 - accuracy: 0.3125\n",
      "Epoch 236: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3780 - accuracy: 0.2939 - val_loss: 1.3677 - val_accuracy: 0.2568\n",
      "Epoch 237/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4059 - accuracy: 0.1875\n",
      "Epoch 237: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3947 - accuracy: 0.2568 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 238/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3839 - accuracy: 0.1562\n",
      "Epoch 238: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3705 - accuracy: 0.2770 - val_loss: 1.3669 - val_accuracy: 0.2568\n",
      "Epoch 239/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3918 - accuracy: 0.2188\n",
      "Epoch 239: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3918 - accuracy: 0.2736 - val_loss: 1.3668 - val_accuracy: 0.2568\n",
      "Epoch 240/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3464 - accuracy: 0.3438\n",
      "Epoch 240: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3851 - accuracy: 0.2804 - val_loss: 1.3674 - val_accuracy: 0.2568\n",
      "Epoch 241/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3333 - accuracy: 0.2812\n",
      "Epoch 241: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3817 - accuracy: 0.2703 - val_loss: 1.3672 - val_accuracy: 0.2568\n",
      "Epoch 242/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4159 - accuracy: 0.1875\n",
      "Epoch 242: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3733 - accuracy: 0.2838 - val_loss: 1.3675 - val_accuracy: 0.2703\n",
      "Epoch 243/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3347 - accuracy: 0.4062\n",
      "Epoch 243: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3699 - accuracy: 0.3007 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 244/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3563 - accuracy: 0.4375\n",
      "Epoch 244: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3718 - accuracy: 0.2905 - val_loss: 1.3675 - val_accuracy: 0.2973\n",
      "Epoch 245/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3724 - accuracy: 0.3125\n",
      "Epoch 245: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3753 - accuracy: 0.2804 - val_loss: 1.3668 - val_accuracy: 0.3378\n",
      "Epoch 246/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3617 - accuracy: 0.3750\n",
      "Epoch 246: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3853 - accuracy: 0.2770 - val_loss: 1.3671 - val_accuracy: 0.3243\n",
      "Epoch 247/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3289 - accuracy: 0.3438\n",
      "Epoch 247: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3886 - accuracy: 0.2973 - val_loss: 1.3669 - val_accuracy: 0.3378\n",
      "Epoch 248/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3699 - accuracy: 0.3438\n",
      "Epoch 248: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3993 - accuracy: 0.3041 - val_loss: 1.3674 - val_accuracy: 0.2973\n",
      "Epoch 249/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4028 - accuracy: 0.3125\n",
      "Epoch 249: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3983 - accuracy: 0.2804 - val_loss: 1.3676 - val_accuracy: 0.2703\n",
      "Epoch 250/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3349 - accuracy: 0.2188\n",
      "Epoch 250: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3779 - accuracy: 0.2804 - val_loss: 1.3674 - val_accuracy: 0.2703\n",
      "Epoch 251/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3802 - accuracy: 0.3750\n",
      "Epoch 251: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3825 - accuracy: 0.3007 - val_loss: 1.3673 - val_accuracy: 0.2703\n",
      "Epoch 252/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4173 - accuracy: 0.3125\n",
      "Epoch 252: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3822 - accuracy: 0.2838 - val_loss: 1.3674 - val_accuracy: 0.2703\n",
      "Epoch 253/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3779 - accuracy: 0.3750\n",
      "Epoch 253: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3816 - accuracy: 0.2838 - val_loss: 1.3673 - val_accuracy: 0.2568\n",
      "Epoch 254/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3471 - accuracy: 0.3438\n",
      "Epoch 254: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3806 - accuracy: 0.2736 - val_loss: 1.3672 - val_accuracy: 0.2568\n",
      "Epoch 255/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3674 - accuracy: 0.2500\n",
      "Epoch 255: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3819 - accuracy: 0.2804 - val_loss: 1.3671 - val_accuracy: 0.2568\n",
      "Epoch 256/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3978 - accuracy: 0.2812\n",
      "Epoch 256: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3793 - accuracy: 0.2703 - val_loss: 1.3670 - val_accuracy: 0.2568\n",
      "Epoch 257/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4049 - accuracy: 0.1250\n",
      "Epoch 257: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3848 - accuracy: 0.2703 - val_loss: 1.3670 - val_accuracy: 0.2568\n",
      "Epoch 258/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4042 - accuracy: 0.2500\n",
      "Epoch 258: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3788 - accuracy: 0.2635 - val_loss: 1.3672 - val_accuracy: 0.2568\n",
      "Epoch 259/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3938 - accuracy: 0.2188\n",
      "Epoch 259: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3875 - accuracy: 0.2703 - val_loss: 1.3674 - val_accuracy: 0.2568\n",
      "Epoch 260/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4855 - accuracy: 0.1875\n",
      "Epoch 260: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3803 - accuracy: 0.2669 - val_loss: 1.3674 - val_accuracy: 0.2568\n",
      "Epoch 261/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3705 - accuracy: 0.2812\n",
      "Epoch 261: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3816 - accuracy: 0.2770 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 262/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3582 - accuracy: 0.2500\n",
      "Epoch 262: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.2872 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 263/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4001 - accuracy: 0.2188\n",
      "Epoch 263: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3882 - accuracy: 0.2601 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 264/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4014 - accuracy: 0.2500\n",
      "Epoch 264: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3888 - accuracy: 0.2872 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 265/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3976 - accuracy: 0.1875\n",
      "Epoch 265: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3756 - accuracy: 0.2466 - val_loss: 1.3677 - val_accuracy: 0.2568\n",
      "Epoch 266/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3960 - accuracy: 0.2500\n",
      "Epoch 266: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3872 - accuracy: 0.2703 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 267/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4114 - accuracy: 0.2500\n",
      "Epoch 267: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4012 - accuracy: 0.2669 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 268/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3816 - accuracy: 0.3125\n",
      "Epoch 268: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3762 - accuracy: 0.2736 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 269/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3601 - accuracy: 0.3750\n",
      "Epoch 269: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3789 - accuracy: 0.2703 - val_loss: 1.3676 - val_accuracy: 0.2568\n",
      "Epoch 270/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3964 - accuracy: 0.2188\n",
      "Epoch 270: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3675 - accuracy: 0.2872 - val_loss: 1.3668 - val_accuracy: 0.2568\n",
      "Epoch 271/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4009 - accuracy: 0.2188\n",
      "Epoch 271: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3751 - accuracy: 0.2736 - val_loss: 1.3625 - val_accuracy: 0.2568\n",
      "Epoch 272/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3880 - accuracy: 0.2812\n",
      "Epoch 272: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3827 - accuracy: 0.2736 - val_loss: 1.3648 - val_accuracy: 0.2568\n",
      "Epoch 273/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3649 - accuracy: 0.2500\n",
      "Epoch 273: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3786 - accuracy: 0.2466 - val_loss: 1.3663 - val_accuracy: 0.3378\n",
      "Epoch 274/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3969 - accuracy: 0.1875\n",
      "Epoch 274: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3762 - accuracy: 0.2399 - val_loss: 1.3677 - val_accuracy: 0.2568\n",
      "Epoch 275/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4025 - accuracy: 0.1875\n",
      "Epoch 275: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3719 - accuracy: 0.2770 - val_loss: 1.3679 - val_accuracy: 0.2568\n",
      "Epoch 276/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3960 - accuracy: 0.2500\n",
      "Epoch 276: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3814 - accuracy: 0.2804 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 277/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3858 - accuracy: 0.1875\n",
      "Epoch 277: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3736 - accuracy: 0.2770 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 278/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3971 - accuracy: 0.3125\n",
      "Epoch 278: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3703 - accuracy: 0.2804 - val_loss: 1.3675 - val_accuracy: 0.2568\n",
      "Epoch 279/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3769 - accuracy: 0.3438\n",
      "Epoch 279: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3886 - accuracy: 0.2804 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 280/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3360 - accuracy: 0.4062\n",
      "Epoch 280: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3689 - accuracy: 0.2703 - val_loss: 1.3680 - val_accuracy: 0.2568\n",
      "Epoch 281/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3670 - accuracy: 0.2812\n",
      "Epoch 281: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3745 - accuracy: 0.2770 - val_loss: 1.3681 - val_accuracy: 0.2568\n",
      "Epoch 282/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4224 - accuracy: 0.2500\n",
      "Epoch 282: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3889 - accuracy: 0.2635 - val_loss: 1.3680 - val_accuracy: 0.2568\n",
      "Epoch 283/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4097 - accuracy: 0.2500\n",
      "Epoch 283: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3697 - accuracy: 0.2736 - val_loss: 1.3674 - val_accuracy: 0.2568\n",
      "Epoch 284/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3760 - accuracy: 0.3438\n",
      "Epoch 284: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3655 - accuracy: 0.2770 - val_loss: 1.3662 - val_accuracy: 0.2568\n",
      "Epoch 285/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3830 - accuracy: 0.3438\n",
      "Epoch 285: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3879 - accuracy: 0.2770 - val_loss: 1.3628 - val_accuracy: 0.2568\n",
      "Epoch 286/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3358 - accuracy: 0.2812\n",
      "Epoch 286: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3765 - accuracy: 0.2770 - val_loss: 1.3629 - val_accuracy: 0.2568\n",
      "Epoch 287/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3826 - accuracy: 0.3125\n",
      "Epoch 287: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3890 - accuracy: 0.3074 - val_loss: 1.3633 - val_accuracy: 0.3919\n",
      "Epoch 288/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3451 - accuracy: 0.2188\n",
      "Epoch 288: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3788 - accuracy: 0.2973 - val_loss: 1.3650 - val_accuracy: 0.3378\n",
      "Epoch 289/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3568 - accuracy: 0.3438\n",
      "Epoch 289: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3818 - accuracy: 0.2872 - val_loss: 1.3670 - val_accuracy: 0.2973\n",
      "Epoch 290/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3821 - accuracy: 0.2500\n",
      "Epoch 290: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3832 - accuracy: 0.2973 - val_loss: 1.3671 - val_accuracy: 0.2838\n",
      "Epoch 291/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3819 - accuracy: 0.3125\n",
      "Epoch 291: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3789 - accuracy: 0.3041 - val_loss: 1.3665 - val_accuracy: 0.2973\n",
      "Epoch 292/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3496 - accuracy: 0.4375\n",
      "Epoch 292: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3698 - accuracy: 0.2939 - val_loss: 1.3641 - val_accuracy: 0.3378\n",
      "Epoch 293/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4083 - accuracy: 0.1250\n",
      "Epoch 293: val_loss did not improve from 1.35009\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3745 - accuracy: 0.2838 - val_loss: 1.3572 - val_accuracy: 0.4324\n",
      "Epoch 294/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3902 - accuracy: 0.3125\n",
      "Epoch 294: val_loss improved from 1.35009 to 1.34968, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.3777 - accuracy: 0.2973 - val_loss: 1.3497 - val_accuracy: 0.4189\n",
      "Epoch 295/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3746 - accuracy: 0.2188\n",
      "Epoch 295: val_loss did not improve from 1.34968\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3775 - accuracy: 0.2770 - val_loss: 1.3591 - val_accuracy: 0.4324\n",
      "Epoch 296/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3506 - accuracy: 0.3125\n",
      "Epoch 296: val_loss improved from 1.34968 to 1.34881, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3565 - accuracy: 0.3446 - val_loss: 1.3488 - val_accuracy: 0.4189\n",
      "Epoch 297/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3493 - accuracy: 0.2812\n",
      "Epoch 297: val_loss improved from 1.34881 to 1.32163, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3640 - accuracy: 0.3041 - val_loss: 1.3216 - val_accuracy: 0.3514\n",
      "Epoch 298/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2523 - accuracy: 0.4062\n",
      "Epoch 298: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3641 - accuracy: 0.2905 - val_loss: 1.3279 - val_accuracy: 0.4189\n",
      "Epoch 299/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4016 - accuracy: 0.2812\n",
      "Epoch 299: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3884 - accuracy: 0.2872 - val_loss: 1.3467 - val_accuracy: 0.4054\n",
      "Epoch 300/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3415 - accuracy: 0.5000\n",
      "Epoch 300: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3632 - accuracy: 0.3142 - val_loss: 1.3420 - val_accuracy: 0.4189\n",
      "Epoch 301/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3391 - accuracy: 0.2812\n",
      "Epoch 301: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3764 - accuracy: 0.3041 - val_loss: 1.3346 - val_accuracy: 0.4324\n",
      "Epoch 302/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4226 - accuracy: 0.2500\n",
      "Epoch 302: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3859 - accuracy: 0.2872 - val_loss: 1.3436 - val_accuracy: 0.4189\n",
      "Epoch 303/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6154 - accuracy: 0.1875\n",
      "Epoch 303: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3992 - accuracy: 0.2736 - val_loss: 1.3480 - val_accuracy: 0.4054\n",
      "Epoch 304/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3711 - accuracy: 0.2500\n",
      "Epoch 304: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3741 - accuracy: 0.3041 - val_loss: 1.3449 - val_accuracy: 0.4189\n",
      "Epoch 305/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3405 - accuracy: 0.2500\n",
      "Epoch 305: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.2872 - val_loss: 1.3398 - val_accuracy: 0.4324\n",
      "Epoch 306/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4421 - accuracy: 0.1562\n",
      "Epoch 306: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3763 - accuracy: 0.2804 - val_loss: 1.3385 - val_accuracy: 0.3919\n",
      "Epoch 307/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3174 - accuracy: 0.2812\n",
      "Epoch 307: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3526 - accuracy: 0.2804 - val_loss: 1.3443 - val_accuracy: 0.4189\n",
      "Epoch 308/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3943 - accuracy: 0.1562\n",
      "Epoch 308: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3742 - accuracy: 0.2770 - val_loss: 1.3500 - val_accuracy: 0.2703\n",
      "Epoch 309/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4222 - accuracy: 0.2500\n",
      "Epoch 309: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3791 - accuracy: 0.2939 - val_loss: 1.3490 - val_accuracy: 0.3919\n",
      "Epoch 310/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3707 - accuracy: 0.1562\n",
      "Epoch 310: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3690 - accuracy: 0.2939 - val_loss: 1.3365 - val_accuracy: 0.4189\n",
      "Epoch 311/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4088 - accuracy: 0.2500\n",
      "Epoch 311: val_loss did not improve from 1.32163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3810 - accuracy: 0.2905 - val_loss: 1.3301 - val_accuracy: 0.4189\n",
      "Epoch 312/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3331 - accuracy: 0.3125\n",
      "Epoch 312: val_loss improved from 1.32163 to 1.32151, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3656 - accuracy: 0.3243 - val_loss: 1.3215 - val_accuracy: 0.3919\n",
      "Epoch 313/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4058 - accuracy: 0.2188\n",
      "Epoch 313: val_loss improved from 1.32151 to 1.31163, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.3629 - accuracy: 0.3041 - val_loss: 1.3116 - val_accuracy: 0.3784\n",
      "Epoch 314/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3093 - accuracy: 0.3750\n",
      "Epoch 314: val_loss did not improve from 1.31163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3689 - accuracy: 0.2872 - val_loss: 1.3274 - val_accuracy: 0.4324\n",
      "Epoch 315/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4145 - accuracy: 0.3125\n",
      "Epoch 315: val_loss did not improve from 1.31163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3694 - accuracy: 0.3041 - val_loss: 1.3333 - val_accuracy: 0.4324\n",
      "Epoch 316/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3819 - accuracy: 0.1875\n",
      "Epoch 316: val_loss did not improve from 1.31163\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3563 - accuracy: 0.3142 - val_loss: 1.3252 - val_accuracy: 0.4189\n",
      "Epoch 317/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4065 - accuracy: 0.1875\n",
      "Epoch 317: val_loss improved from 1.31163 to 1.31052, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3636 - accuracy: 0.3074 - val_loss: 1.3105 - val_accuracy: 0.4189\n",
      "Epoch 318/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4071 - accuracy: 0.2188\n",
      "Epoch 318: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3586 - accuracy: 0.3209 - val_loss: 1.3110 - val_accuracy: 0.4054\n",
      "Epoch 319/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4538 - accuracy: 0.3438\n",
      "Epoch 319: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3795 - accuracy: 0.3209 - val_loss: 1.3139 - val_accuracy: 0.4189\n",
      "Epoch 320/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3298 - accuracy: 0.4062\n",
      "Epoch 320: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3753 - accuracy: 0.2770 - val_loss: 1.3182 - val_accuracy: 0.3649\n",
      "Epoch 321/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4056 - accuracy: 0.1250\n",
      "Epoch 321: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3565 - accuracy: 0.2669 - val_loss: 1.3219 - val_accuracy: 0.3784\n",
      "Epoch 322/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3290 - accuracy: 0.1875\n",
      "Epoch 322: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3458 - accuracy: 0.3142 - val_loss: 1.3185 - val_accuracy: 0.4189\n",
      "Epoch 323/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3733 - accuracy: 0.3125\n",
      "Epoch 323: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3622 - accuracy: 0.3277 - val_loss: 1.3209 - val_accuracy: 0.4189\n",
      "Epoch 324/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4303 - accuracy: 0.3438\n",
      "Epoch 324: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3966 - accuracy: 0.2500 - val_loss: 1.3258 - val_accuracy: 0.4189\n",
      "Epoch 325/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3531 - accuracy: 0.3125\n",
      "Epoch 325: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3732 - accuracy: 0.2973 - val_loss: 1.3239 - val_accuracy: 0.4189\n",
      "Epoch 326/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3720 - accuracy: 0.2500\n",
      "Epoch 326: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3658 - accuracy: 0.3041 - val_loss: 1.3241 - val_accuracy: 0.4189\n",
      "Epoch 327/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4072 - accuracy: 0.1562\n",
      "Epoch 327: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3607 - accuracy: 0.3108 - val_loss: 1.3233 - val_accuracy: 0.4189\n",
      "Epoch 328/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3029 - accuracy: 0.4375\n",
      "Epoch 328: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3619 - accuracy: 0.2939 - val_loss: 1.3112 - val_accuracy: 0.4189\n",
      "Epoch 329/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3821 - accuracy: 0.3750\n",
      "Epoch 329: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3664 - accuracy: 0.2838 - val_loss: 1.3354 - val_accuracy: 0.4324\n",
      "Epoch 330/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4012 - accuracy: 0.3750\n",
      "Epoch 330: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3761 - accuracy: 0.2973 - val_loss: 1.3521 - val_accuracy: 0.3649\n",
      "Epoch 331/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3451 - accuracy: 0.5000\n",
      "Epoch 331: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3648 - accuracy: 0.3108 - val_loss: 1.3474 - val_accuracy: 0.4189\n",
      "Epoch 332/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3160 - accuracy: 0.3438\n",
      "Epoch 332: val_loss did not improve from 1.31052\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3509 - accuracy: 0.3108 - val_loss: 1.3236 - val_accuracy: 0.4459\n",
      "Epoch 333/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3608 - accuracy: 0.3125\n",
      "Epoch 333: val_loss improved from 1.31052 to 1.29907, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3443 - accuracy: 0.3209 - val_loss: 1.2991 - val_accuracy: 0.4189\n",
      "Epoch 334/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4063 - accuracy: 0.3125\n",
      "Epoch 334: val_loss improved from 1.29907 to 1.29757, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3659 - accuracy: 0.2770 - val_loss: 1.2976 - val_accuracy: 0.4054\n",
      "Epoch 335/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3731 - accuracy: 0.3750\n",
      "Epoch 335: val_loss did not improve from 1.29757\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3683 - accuracy: 0.2872 - val_loss: 1.3017 - val_accuracy: 0.4189\n",
      "Epoch 336/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3655 - accuracy: 0.2812\n",
      "Epoch 336: val_loss did not improve from 1.29757\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3840 - accuracy: 0.2939 - val_loss: 1.3124 - val_accuracy: 0.4324\n",
      "Epoch 337/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2801 - accuracy: 0.3750\n",
      "Epoch 337: val_loss did not improve from 1.29757\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3310 - accuracy: 0.3480 - val_loss: 1.3009 - val_accuracy: 0.4324\n",
      "Epoch 338/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3776 - accuracy: 0.2188\n",
      "Epoch 338: val_loss improved from 1.29757 to 1.27302, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.3322 - accuracy: 0.3041 - val_loss: 1.2730 - val_accuracy: 0.4189\n",
      "Epoch 339/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3799 - accuracy: 0.1875\n",
      "Epoch 339: val_loss improved from 1.27302 to 1.25810, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3345 - accuracy: 0.3041 - val_loss: 1.2581 - val_accuracy: 0.4054\n",
      "Epoch 340/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3146 - accuracy: 0.3125\n",
      "Epoch 340: val_loss did not improve from 1.25810\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3518 - accuracy: 0.3007 - val_loss: 1.2707 - val_accuracy: 0.4189\n",
      "Epoch 341/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3932 - accuracy: 0.4375\n",
      "Epoch 341: val_loss did not improve from 1.25810\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3367 - accuracy: 0.3209 - val_loss: 1.2889 - val_accuracy: 0.4324\n",
      "Epoch 342/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3140 - accuracy: 0.2188\n",
      "Epoch 342: val_loss did not improve from 1.25810\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3553 - accuracy: 0.2973 - val_loss: 1.2925 - val_accuracy: 0.4324\n",
      "Epoch 343/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4130 - accuracy: 0.1875\n",
      "Epoch 343: val_loss did not improve from 1.25810\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3397 - accuracy: 0.3345 - val_loss: 1.2856 - val_accuracy: 0.4459\n",
      "Epoch 344/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2779 - accuracy: 0.3438\n",
      "Epoch 344: val_loss did not improve from 1.25810\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3393 - accuracy: 0.3108 - val_loss: 1.2619 - val_accuracy: 0.4189\n",
      "Epoch 345/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3369 - accuracy: 0.3438\n",
      "Epoch 345: val_loss improved from 1.25810 to 1.24509, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3397 - accuracy: 0.3378 - val_loss: 1.2451 - val_accuracy: 0.4324\n",
      "Epoch 346/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2928 - accuracy: 0.4062\n",
      "Epoch 346: val_loss improved from 1.24509 to 1.24199, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.3360 - accuracy: 0.3277 - val_loss: 1.2420 - val_accuracy: 0.4189\n",
      "Epoch 347/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4132 - accuracy: 0.1250\n",
      "Epoch 347: val_loss did not improve from 1.24199\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3398 - accuracy: 0.3142 - val_loss: 1.2737 - val_accuracy: 0.4054\n",
      "Epoch 348/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2730 - accuracy: 0.2188\n",
      "Epoch 348: val_loss did not improve from 1.24199\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3098 - accuracy: 0.3345 - val_loss: 1.2745 - val_accuracy: 0.3649\n",
      "Epoch 349/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3831 - accuracy: 0.2500\n",
      "Epoch 349: val_loss did not improve from 1.24199\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3472 - accuracy: 0.3074 - val_loss: 1.2628 - val_accuracy: 0.3649\n",
      "Epoch 350/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4340 - accuracy: 0.3125\n",
      "Epoch 350: val_loss did not improve from 1.24199\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3504 - accuracy: 0.3277 - val_loss: 1.2547 - val_accuracy: 0.4054\n",
      "Epoch 351/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4143 - accuracy: 0.3125\n",
      "Epoch 351: val_loss improved from 1.24199 to 1.23099, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.3285 - accuracy: 0.3682 - val_loss: 1.2310 - val_accuracy: 0.4324\n",
      "Epoch 352/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3480 - accuracy: 0.3438\n",
      "Epoch 352: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3113 - accuracy: 0.3446 - val_loss: 1.2430 - val_accuracy: 0.4459\n",
      "Epoch 353/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3755 - accuracy: 0.3438\n",
      "Epoch 353: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3688 - accuracy: 0.2804 - val_loss: 1.2622 - val_accuracy: 0.4054\n",
      "Epoch 354/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3458 - accuracy: 0.3125\n",
      "Epoch 354: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3455 - accuracy: 0.3074 - val_loss: 1.2738 - val_accuracy: 0.4189\n",
      "Epoch 355/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3475 - accuracy: 0.4688\n",
      "Epoch 355: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3234 - accuracy: 0.3547 - val_loss: 1.2702 - val_accuracy: 0.4189\n",
      "Epoch 356/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3616 - accuracy: 0.4062\n",
      "Epoch 356: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3475 - accuracy: 0.2905 - val_loss: 1.2476 - val_accuracy: 0.3919\n",
      "Epoch 357/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3277 - accuracy: 0.4688\n",
      "Epoch 357: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3485 - accuracy: 0.3243 - val_loss: 1.2470 - val_accuracy: 0.3784\n",
      "Epoch 358/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2645 - accuracy: 0.4062\n",
      "Epoch 358: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3576 - accuracy: 0.2635 - val_loss: 1.2584 - val_accuracy: 0.3919\n",
      "Epoch 359/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3180 - accuracy: 0.2812\n",
      "Epoch 359: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3281 - accuracy: 0.3108 - val_loss: 1.2646 - val_accuracy: 0.4189\n",
      "Epoch 360/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3383 - accuracy: 0.2812\n",
      "Epoch 360: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3293 - accuracy: 0.3345 - val_loss: 1.2563 - val_accuracy: 0.4054\n",
      "Epoch 361/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3236 - accuracy: 0.4062\n",
      "Epoch 361: val_loss did not improve from 1.23099\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3394 - accuracy: 0.3311 - val_loss: 1.2430 - val_accuracy: 0.4054\n",
      "Epoch 362/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2465 - accuracy: 0.4062\n",
      "Epoch 362: val_loss improved from 1.23099 to 1.22177, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.3184 - accuracy: 0.3514 - val_loss: 1.2218 - val_accuracy: 0.4324\n",
      "Epoch 363/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3004 - accuracy: 0.3125\n",
      "Epoch 363: val_loss improved from 1.22177 to 1.21536, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3119 - accuracy: 0.3277 - val_loss: 1.2154 - val_accuracy: 0.4189\n",
      "Epoch 364/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2404 - accuracy: 0.4062\n",
      "Epoch 364: val_loss improved from 1.21536 to 1.21013, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3138 - accuracy: 0.3480 - val_loss: 1.2101 - val_accuracy: 0.5000\n",
      "Epoch 365/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3767 - accuracy: 0.3438\n",
      "Epoch 365: val_loss improved from 1.21013 to 1.20430, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.3008 - accuracy: 0.3851 - val_loss: 1.2043 - val_accuracy: 0.4865\n",
      "Epoch 366/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2767 - accuracy: 0.2812\n",
      "Epoch 366: val_loss improved from 1.20430 to 1.19306, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.3056 - accuracy: 0.3243 - val_loss: 1.1931 - val_accuracy: 0.4459\n",
      "Epoch 367/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3649 - accuracy: 0.3750\n",
      "Epoch 367: val_loss improved from 1.19306 to 1.18765, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.2912 - accuracy: 0.3480 - val_loss: 1.1876 - val_accuracy: 0.4730\n",
      "Epoch 368/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3094 - accuracy: 0.3750\n",
      "Epoch 368: val_loss improved from 1.18765 to 1.18338, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.2623 - accuracy: 0.3682 - val_loss: 1.1834 - val_accuracy: 0.4730\n",
      "Epoch 369/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2344 - accuracy: 0.3125\n",
      "Epoch 369: val_loss improved from 1.18338 to 1.17476, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2869 - accuracy: 0.3446 - val_loss: 1.1748 - val_accuracy: 0.4189\n",
      "Epoch 370/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2771 - accuracy: 0.2812\n",
      "Epoch 370: val_loss improved from 1.17476 to 1.17189, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.2895 - accuracy: 0.3311 - val_loss: 1.1719 - val_accuracy: 0.4054\n",
      "Epoch 371/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2451 - accuracy: 0.3438\n",
      "Epoch 371: val_loss improved from 1.17189 to 1.15192, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2520 - accuracy: 0.3818 - val_loss: 1.1519 - val_accuracy: 0.4459\n",
      "Epoch 372/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2705 - accuracy: 0.4062\n",
      "Epoch 372: val_loss improved from 1.15192 to 1.15020, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2863 - accuracy: 0.3919 - val_loss: 1.1502 - val_accuracy: 0.4865\n",
      "Epoch 373/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2813 - accuracy: 0.4062\n",
      "Epoch 373: val_loss did not improve from 1.15020\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3020 - accuracy: 0.3615 - val_loss: 1.1934 - val_accuracy: 0.4595\n",
      "Epoch 374/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2812 - accuracy: 0.2500\n",
      "Epoch 374: val_loss did not improve from 1.15020\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2690 - accuracy: 0.3581 - val_loss: 1.1784 - val_accuracy: 0.4324\n",
      "Epoch 375/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3627 - accuracy: 0.3438\n",
      "Epoch 375: val_loss did not improve from 1.15020\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2841 - accuracy: 0.3986 - val_loss: 1.1733 - val_accuracy: 0.5270\n",
      "Epoch 376/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2603 - accuracy: 0.4062\n",
      "Epoch 376: val_loss did not improve from 1.15020\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2807 - accuracy: 0.3547 - val_loss: 1.1504 - val_accuracy: 0.5405\n",
      "Epoch 377/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3529 - accuracy: 0.4375\n",
      "Epoch 377: val_loss improved from 1.15020 to 1.13425, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2788 - accuracy: 0.3682 - val_loss: 1.1342 - val_accuracy: 0.4595\n",
      "Epoch 378/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3952 - accuracy: 0.3750\n",
      "Epoch 378: val_loss did not improve from 1.13425\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2822 - accuracy: 0.3851 - val_loss: 1.1412 - val_accuracy: 0.4865\n",
      "Epoch 379/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3167 - accuracy: 0.5625\n",
      "Epoch 379: val_loss did not improve from 1.13425\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2814 - accuracy: 0.3784 - val_loss: 1.1473 - val_accuracy: 0.4730\n",
      "Epoch 380/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2566 - accuracy: 0.4688\n",
      "Epoch 380: val_loss did not improve from 1.13425\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2575 - accuracy: 0.4020 - val_loss: 1.1627 - val_accuracy: 0.5000\n",
      "Epoch 381/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1733 - accuracy: 0.4688\n",
      "Epoch 381: val_loss did not improve from 1.13425\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2743 - accuracy: 0.3581 - val_loss: 1.1401 - val_accuracy: 0.4865\n",
      "Epoch 382/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2578 - accuracy: 0.3438\n",
      "Epoch 382: val_loss did not improve from 1.13425\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2852 - accuracy: 0.3953 - val_loss: 1.1390 - val_accuracy: 0.5405\n",
      "Epoch 383/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2141 - accuracy: 0.4375\n",
      "Epoch 383: val_loss improved from 1.13425 to 1.13048, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2641 - accuracy: 0.4088 - val_loss: 1.1305 - val_accuracy: 0.5405\n",
      "Epoch 384/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2443 - accuracy: 0.3750\n",
      "Epoch 384: val_loss improved from 1.13048 to 1.12093, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2354 - accuracy: 0.3885 - val_loss: 1.1209 - val_accuracy: 0.5541\n",
      "Epoch 385/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2557 - accuracy: 0.3438\n",
      "Epoch 385: val_loss improved from 1.12093 to 1.11233, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.2491 - accuracy: 0.3919 - val_loss: 1.1123 - val_accuracy: 0.5405\n",
      "Epoch 386/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1186 - accuracy: 0.6562\n",
      "Epoch 386: val_loss did not improve from 1.11233\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2365 - accuracy: 0.4358 - val_loss: 1.1168 - val_accuracy: 0.5270\n",
      "Epoch 387/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3119 - accuracy: 0.2812\n",
      "Epoch 387: val_loss improved from 1.11233 to 1.10687, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.2560 - accuracy: 0.3750 - val_loss: 1.1069 - val_accuracy: 0.5541\n",
      "Epoch 388/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2137 - accuracy: 0.4688\n",
      "Epoch 388: val_loss did not improve from 1.10687\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2787 - accuracy: 0.4020 - val_loss: 1.1140 - val_accuracy: 0.5676\n",
      "Epoch 389/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3268 - accuracy: 0.4688\n",
      "Epoch 389: val_loss did not improve from 1.10687\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2300 - accuracy: 0.4155 - val_loss: 1.1071 - val_accuracy: 0.5000\n",
      "Epoch 390/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3396 - accuracy: 0.3125\n",
      "Epoch 390: val_loss improved from 1.10687 to 1.09955, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2505 - accuracy: 0.4155 - val_loss: 1.0996 - val_accuracy: 0.5270\n",
      "Epoch 391/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1786 - accuracy: 0.4688\n",
      "Epoch 391: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2156 - accuracy: 0.4493 - val_loss: 1.0996 - val_accuracy: 0.5000\n",
      "Epoch 392/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1537 - accuracy: 0.5312\n",
      "Epoch 392: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2534 - accuracy: 0.4088 - val_loss: 1.1048 - val_accuracy: 0.4730\n",
      "Epoch 393/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2625 - accuracy: 0.4062\n",
      "Epoch 393: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2479 - accuracy: 0.3784 - val_loss: 1.1062 - val_accuracy: 0.5135\n",
      "Epoch 394/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0748 - accuracy: 0.4375\n",
      "Epoch 394: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2304 - accuracy: 0.3885 - val_loss: 1.1192 - val_accuracy: 0.4459\n",
      "Epoch 395/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1227 - accuracy: 0.4062\n",
      "Epoch 395: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.4122 - val_loss: 1.1049 - val_accuracy: 0.4595\n",
      "Epoch 396/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3623 - accuracy: 0.2188\n",
      "Epoch 396: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.3378 - val_loss: 1.1124 - val_accuracy: 0.5000\n",
      "Epoch 397/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1380 - accuracy: 0.4375\n",
      "Epoch 397: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2574 - accuracy: 0.3581 - val_loss: 1.1102 - val_accuracy: 0.5270\n",
      "Epoch 398/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2691 - accuracy: 0.3750\n",
      "Epoch 398: val_loss did not improve from 1.09955\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2521 - accuracy: 0.3716 - val_loss: 1.1062 - val_accuracy: 0.5541\n",
      "Epoch 399/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2163 - accuracy: 0.4375\n",
      "Epoch 399: val_loss improved from 1.09955 to 1.09831, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2459 - accuracy: 0.3851 - val_loss: 1.0983 - val_accuracy: 0.5000\n",
      "Epoch 400/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4146 - accuracy: 0.3750\n",
      "Epoch 400: val_loss did not improve from 1.09831\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2685 - accuracy: 0.3649 - val_loss: 1.1125 - val_accuracy: 0.4865\n",
      "Epoch 401/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2068 - accuracy: 0.3438\n",
      "Epoch 401: val_loss did not improve from 1.09831\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2585 - accuracy: 0.3649 - val_loss: 1.1025 - val_accuracy: 0.5135\n",
      "Epoch 402/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2258 - accuracy: 0.3750\n",
      "Epoch 402: val_loss improved from 1.09831 to 1.09018, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2150 - accuracy: 0.4223 - val_loss: 1.0902 - val_accuracy: 0.5135\n",
      "Epoch 403/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2351 - accuracy: 0.2188\n",
      "Epoch 403: val_loss improved from 1.09018 to 1.08588, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2218 - accuracy: 0.4459 - val_loss: 1.0859 - val_accuracy: 0.5135\n",
      "Epoch 404/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2452 - accuracy: 0.3750\n",
      "Epoch 404: val_loss improved from 1.08588 to 1.08390, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.2048 - accuracy: 0.4088 - val_loss: 1.0839 - val_accuracy: 0.5270\n",
      "Epoch 405/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1574 - accuracy: 0.3125\n",
      "Epoch 405: val_loss improved from 1.08390 to 1.07213, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1881 - accuracy: 0.4426 - val_loss: 1.0721 - val_accuracy: 0.5000\n",
      "Epoch 406/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1588 - accuracy: 0.4375\n",
      "Epoch 406: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1935 - accuracy: 0.4189 - val_loss: 1.0739 - val_accuracy: 0.5135\n",
      "Epoch 407/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4810 - accuracy: 0.3125\n",
      "Epoch 407: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2290 - accuracy: 0.4358 - val_loss: 1.0845 - val_accuracy: 0.5000\n",
      "Epoch 408/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1227 - accuracy: 0.4375\n",
      "Epoch 408: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1725 - accuracy: 0.4561 - val_loss: 1.0829 - val_accuracy: 0.4730\n",
      "Epoch 409/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1593 - accuracy: 0.4062\n",
      "Epoch 409: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.4291 - val_loss: 1.0896 - val_accuracy: 0.5270\n",
      "Epoch 410/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1528 - accuracy: 0.3438\n",
      "Epoch 410: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.4358 - val_loss: 1.0976 - val_accuracy: 0.4865\n",
      "Epoch 411/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1867 - accuracy: 0.4688\n",
      "Epoch 411: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1817 - accuracy: 0.4392 - val_loss: 1.0751 - val_accuracy: 0.5270\n",
      "Epoch 412/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2475 - accuracy: 0.4375\n",
      "Epoch 412: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.4257 - val_loss: 1.0731 - val_accuracy: 0.5405\n",
      "Epoch 413/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3236 - accuracy: 0.2188\n",
      "Epoch 413: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2596 - accuracy: 0.4020 - val_loss: 1.0829 - val_accuracy: 0.5405\n",
      "Epoch 414/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2365 - accuracy: 0.3125\n",
      "Epoch 414: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2161 - accuracy: 0.3818 - val_loss: 1.0987 - val_accuracy: 0.5405\n",
      "Epoch 415/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1503 - accuracy: 0.4688\n",
      "Epoch 415: val_loss did not improve from 1.07213\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1746 - accuracy: 0.4764 - val_loss: 1.0825 - val_accuracy: 0.5270\n",
      "Epoch 416/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1726 - accuracy: 0.4375\n",
      "Epoch 416: val_loss improved from 1.07213 to 1.06093, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1777 - accuracy: 0.4662 - val_loss: 1.0609 - val_accuracy: 0.5000\n",
      "Epoch 417/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2107 - accuracy: 0.3750\n",
      "Epoch 417: val_loss did not improve from 1.06093\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1476 - accuracy: 0.4527 - val_loss: 1.0686 - val_accuracy: 0.5000\n",
      "Epoch 418/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1957 - accuracy: 0.4375\n",
      "Epoch 418: val_loss improved from 1.06093 to 1.05221, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1541 - accuracy: 0.4527 - val_loss: 1.0522 - val_accuracy: 0.5405\n",
      "Epoch 419/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1086 - accuracy: 0.4375\n",
      "Epoch 419: val_loss did not improve from 1.05221\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2408 - accuracy: 0.4155 - val_loss: 1.0612 - val_accuracy: 0.5405\n",
      "Epoch 420/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1485 - accuracy: 0.5000\n",
      "Epoch 420: val_loss did not improve from 1.05221\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1708 - accuracy: 0.4459 - val_loss: 1.0719 - val_accuracy: 0.5135\n",
      "Epoch 421/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2047 - accuracy: 0.4062\n",
      "Epoch 421: val_loss did not improve from 1.05221\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2322 - accuracy: 0.4122 - val_loss: 1.0679 - val_accuracy: 0.5000\n",
      "Epoch 422/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1665 - accuracy: 0.3125\n",
      "Epoch 422: val_loss did not improve from 1.05221\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.4155 - val_loss: 1.0924 - val_accuracy: 0.4595\n",
      "Epoch 423/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1870 - accuracy: 0.4688\n",
      "Epoch 423: val_loss did not improve from 1.05221\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1779 - accuracy: 0.4088 - val_loss: 1.0757 - val_accuracy: 0.5541\n",
      "Epoch 424/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1288 - accuracy: 0.5000\n",
      "Epoch 424: val_loss improved from 1.05221 to 1.04453, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.1659 - accuracy: 0.4223 - val_loss: 1.0445 - val_accuracy: 0.5676\n",
      "Epoch 425/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3100 - accuracy: 0.3750\n",
      "Epoch 425: val_loss improved from 1.04453 to 1.03856, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1397 - accuracy: 0.4459 - val_loss: 1.0386 - val_accuracy: 0.5405\n",
      "Epoch 426/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1055 - accuracy: 0.4375\n",
      "Epoch 426: val_loss improved from 1.03856 to 1.03409, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1513 - accuracy: 0.4257 - val_loss: 1.0341 - val_accuracy: 0.4865\n",
      "Epoch 427/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2683 - accuracy: 0.4062\n",
      "Epoch 427: val_loss did not improve from 1.03409\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1869 - accuracy: 0.4257 - val_loss: 1.0507 - val_accuracy: 0.4730\n",
      "Epoch 428/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2657 - accuracy: 0.3750\n",
      "Epoch 428: val_loss did not improve from 1.03409\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2162 - accuracy: 0.4122 - val_loss: 1.0572 - val_accuracy: 0.5270\n",
      "Epoch 429/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2309 - accuracy: 0.4062\n",
      "Epoch 429: val_loss did not improve from 1.03409\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1374 - accuracy: 0.4291 - val_loss: 1.0439 - val_accuracy: 0.5270\n",
      "Epoch 430/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1383 - accuracy: 0.5312\n",
      "Epoch 430: val_loss improved from 1.03409 to 1.03184, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1865 - accuracy: 0.4527 - val_loss: 1.0318 - val_accuracy: 0.5135\n",
      "Epoch 431/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1859 - accuracy: 0.3438\n",
      "Epoch 431: val_loss did not improve from 1.03184\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.3885 - val_loss: 1.0529 - val_accuracy: 0.5270\n",
      "Epoch 432/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2023 - accuracy: 0.4375\n",
      "Epoch 432: val_loss did not improve from 1.03184\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1847 - accuracy: 0.3986 - val_loss: 1.0697 - val_accuracy: 0.5270\n",
      "Epoch 433/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1991 - accuracy: 0.5000\n",
      "Epoch 433: val_loss did not improve from 1.03184\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1652 - accuracy: 0.4426 - val_loss: 1.0465 - val_accuracy: 0.5405\n",
      "Epoch 434/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1542 - accuracy: 0.3125\n",
      "Epoch 434: val_loss did not improve from 1.03184\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1187 - accuracy: 0.4595 - val_loss: 1.0357 - val_accuracy: 0.4865\n",
      "Epoch 435/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2231 - accuracy: 0.5625\n",
      "Epoch 435: val_loss improved from 1.03184 to 1.00945, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2111 - accuracy: 0.4324 - val_loss: 1.0095 - val_accuracy: 0.5135\n",
      "Epoch 436/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3183 - accuracy: 0.4062\n",
      "Epoch 436: val_loss did not improve from 1.00945\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1509 - accuracy: 0.4122 - val_loss: 1.0183 - val_accuracy: 0.5405\n",
      "Epoch 437/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0547 - accuracy: 0.4688\n",
      "Epoch 437: val_loss did not improve from 1.00945\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1372 - accuracy: 0.4392 - val_loss: 1.0357 - val_accuracy: 0.5405\n",
      "Epoch 438/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0583 - accuracy: 0.4062\n",
      "Epoch 438: val_loss did not improve from 1.00945\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1462 - accuracy: 0.4527 - val_loss: 1.0322 - val_accuracy: 0.5270\n",
      "Epoch 439/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0871 - accuracy: 0.4375\n",
      "Epoch 439: val_loss did not improve from 1.00945\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1626 - accuracy: 0.4223 - val_loss: 1.0479 - val_accuracy: 0.5000\n",
      "Epoch 440/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0258 - accuracy: 0.4375\n",
      "Epoch 440: val_loss improved from 1.00945 to 1.00770, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0862 - accuracy: 0.4865 - val_loss: 1.0077 - val_accuracy: 0.5541\n",
      "Epoch 441/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9716 - accuracy: 0.6250\n",
      "Epoch 441: val_loss improved from 1.00770 to 0.98923, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0974 - accuracy: 0.4730 - val_loss: 0.9892 - val_accuracy: 0.5270\n",
      "Epoch 442/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2591 - accuracy: 0.3438\n",
      "Epoch 442: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1762 - accuracy: 0.4291 - val_loss: 1.0092 - val_accuracy: 0.5135\n",
      "Epoch 443/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0343 - accuracy: 0.4062\n",
      "Epoch 443: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1205 - accuracy: 0.4696 - val_loss: 1.0082 - val_accuracy: 0.5270\n",
      "Epoch 444/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1840 - accuracy: 0.5312\n",
      "Epoch 444: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1098 - accuracy: 0.4831 - val_loss: 1.0266 - val_accuracy: 0.5000\n",
      "Epoch 445/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0944 - accuracy: 0.5312\n",
      "Epoch 445: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1057 - accuracy: 0.4730 - val_loss: 1.0189 - val_accuracy: 0.5270\n",
      "Epoch 446/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3620 - accuracy: 0.3125\n",
      "Epoch 446: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1463 - accuracy: 0.4527 - val_loss: 1.0113 - val_accuracy: 0.5405\n",
      "Epoch 447/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1117 - accuracy: 0.4688\n",
      "Epoch 447: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1092 - accuracy: 0.4493 - val_loss: 1.0231 - val_accuracy: 0.5270\n",
      "Epoch 448/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1530 - accuracy: 0.4375\n",
      "Epoch 448: val_loss did not improve from 0.98923\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1084 - accuracy: 0.4628 - val_loss: 1.0057 - val_accuracy: 0.5135\n",
      "Epoch 449/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9455 - accuracy: 0.6562\n",
      "Epoch 449: val_loss improved from 0.98923 to 0.98432, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0960 - accuracy: 0.4831 - val_loss: 0.9843 - val_accuracy: 0.5405\n",
      "Epoch 450/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0290 - accuracy: 0.4688\n",
      "Epoch 450: val_loss did not improve from 0.98432\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0770 - accuracy: 0.4932 - val_loss: 0.9880 - val_accuracy: 0.5270\n",
      "Epoch 451/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0615 - accuracy: 0.5312\n",
      "Epoch 451: val_loss improved from 0.98432 to 0.97852, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.1168 - accuracy: 0.4865 - val_loss: 0.9785 - val_accuracy: 0.5270\n",
      "Epoch 452/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2286 - accuracy: 0.3750\n",
      "Epoch 452: val_loss improved from 0.97852 to 0.97709, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0520 - accuracy: 0.5034 - val_loss: 0.9771 - val_accuracy: 0.5405\n",
      "Epoch 453/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9947 - accuracy: 0.5938\n",
      "Epoch 453: val_loss did not improve from 0.97709\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.5000 - val_loss: 0.9800 - val_accuracy: 0.5541\n",
      "Epoch 454/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2621 - accuracy: 0.4688\n",
      "Epoch 454: val_loss did not improve from 0.97709\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1177 - accuracy: 0.4392 - val_loss: 0.9961 - val_accuracy: 0.5270\n",
      "Epoch 455/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1359 - accuracy: 0.4062\n",
      "Epoch 455: val_loss did not improve from 0.97709\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1025 - accuracy: 0.4764 - val_loss: 1.0021 - val_accuracy: 0.5270\n",
      "Epoch 456/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0283 - accuracy: 0.4375\n",
      "Epoch 456: val_loss improved from 0.97709 to 0.97024, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0503 - accuracy: 0.5000 - val_loss: 0.9702 - val_accuracy: 0.5541\n",
      "Epoch 457/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1188 - accuracy: 0.4062\n",
      "Epoch 457: val_loss did not improve from 0.97024\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0724 - accuracy: 0.4527 - val_loss: 0.9760 - val_accuracy: 0.5541\n",
      "Epoch 458/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8937 - accuracy: 0.7500\n",
      "Epoch 458: val_loss improved from 0.97024 to 0.93439, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0465 - accuracy: 0.5304 - val_loss: 0.9344 - val_accuracy: 0.5541\n",
      "Epoch 459/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2221 - accuracy: 0.3438\n",
      "Epoch 459: val_loss did not improve from 0.93439\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0633 - accuracy: 0.4764 - val_loss: 0.9443 - val_accuracy: 0.5135\n",
      "Epoch 460/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1453 - accuracy: 0.4688\n",
      "Epoch 460: val_loss did not improve from 0.93439\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0455 - accuracy: 0.5304 - val_loss: 0.9348 - val_accuracy: 0.5405\n",
      "Epoch 461/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1170 - accuracy: 0.4688\n",
      "Epoch 461: val_loss did not improve from 0.93439\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0312 - accuracy: 0.4966 - val_loss: 0.9368 - val_accuracy: 0.5405\n",
      "Epoch 462/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1158 - accuracy: 0.3750\n",
      "Epoch 462: val_loss improved from 0.93439 to 0.92846, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0905 - accuracy: 0.4561 - val_loss: 0.9285 - val_accuracy: 0.5676\n",
      "Epoch 463/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1298 - accuracy: 0.3750\n",
      "Epoch 463: val_loss improved from 0.92846 to 0.92563, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0565 - accuracy: 0.4831 - val_loss: 0.9256 - val_accuracy: 0.5405\n",
      "Epoch 464/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1841 - accuracy: 0.4062\n",
      "Epoch 464: val_loss did not improve from 0.92563\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0865 - accuracy: 0.4764 - val_loss: 0.9741 - val_accuracy: 0.5135\n",
      "Epoch 465/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2976 - accuracy: 0.4062\n",
      "Epoch 465: val_loss did not improve from 0.92563\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1195 - accuracy: 0.4628 - val_loss: 1.0003 - val_accuracy: 0.5405\n",
      "Epoch 466/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9091 - accuracy: 0.6562\n",
      "Epoch 466: val_loss did not improve from 0.92563\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0651 - accuracy: 0.5034 - val_loss: 0.9691 - val_accuracy: 0.5135\n",
      "Epoch 467/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0604 - accuracy: 0.5312\n",
      "Epoch 467: val_loss did not improve from 0.92563\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0661 - accuracy: 0.5135 - val_loss: 0.9530 - val_accuracy: 0.5270\n",
      "Epoch 468/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9988 - accuracy: 0.5938\n",
      "Epoch 468: val_loss improved from 0.92563 to 0.91610, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0192 - accuracy: 0.5304 - val_loss: 0.9161 - val_accuracy: 0.5541\n",
      "Epoch 469/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0238 - accuracy: 0.4375\n",
      "Epoch 469: val_loss did not improve from 0.91610\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0744 - accuracy: 0.5135 - val_loss: 0.9302 - val_accuracy: 0.5541\n",
      "Epoch 470/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0295 - accuracy: 0.5625\n",
      "Epoch 470: val_loss did not improve from 0.91610\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0064 - accuracy: 0.5000 - val_loss: 0.9289 - val_accuracy: 0.5270\n",
      "Epoch 471/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9160 - accuracy: 0.7500\n",
      "Epoch 471: val_loss did not improve from 0.91610\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0418 - accuracy: 0.5236 - val_loss: 0.9278 - val_accuracy: 0.5405\n",
      "Epoch 472/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0616 - accuracy: 0.4062\n",
      "Epoch 472: val_loss improved from 0.91610 to 0.90069, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9878 - accuracy: 0.5304 - val_loss: 0.9007 - val_accuracy: 0.5405\n",
      "Epoch 473/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9216 - accuracy: 0.5312\n",
      "Epoch 473: val_loss improved from 0.90069 to 0.88590, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9702 - accuracy: 0.5236 - val_loss: 0.8859 - val_accuracy: 0.5405\n",
      "Epoch 474/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1056 - accuracy: 0.5625\n",
      "Epoch 474: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1061 - accuracy: 0.5034 - val_loss: 0.9255 - val_accuracy: 0.5541\n",
      "Epoch 475/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9467 - accuracy: 0.6250\n",
      "Epoch 475: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0301 - accuracy: 0.5101 - val_loss: 0.9431 - val_accuracy: 0.5405\n",
      "Epoch 476/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0884 - accuracy: 0.3750\n",
      "Epoch 476: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0367 - accuracy: 0.5000 - val_loss: 0.9405 - val_accuracy: 0.5676\n",
      "Epoch 477/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1792 - accuracy: 0.3750\n",
      "Epoch 477: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0908 - accuracy: 0.5101 - val_loss: 0.9089 - val_accuracy: 0.5946\n",
      "Epoch 478/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0010 - accuracy: 0.5938\n",
      "Epoch 478: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0588 - accuracy: 0.4932 - val_loss: 0.9361 - val_accuracy: 0.4730\n",
      "Epoch 479/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9661 - accuracy: 0.5000\n",
      "Epoch 479: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0046 - accuracy: 0.5236 - val_loss: 0.9208 - val_accuracy: 0.5135\n",
      "Epoch 480/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9688 - accuracy: 0.4688\n",
      "Epoch 480: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0336 - accuracy: 0.5405 - val_loss: 0.8927 - val_accuracy: 0.5541\n",
      "Epoch 481/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9176 - accuracy: 0.6562\n",
      "Epoch 481: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0058 - accuracy: 0.5338 - val_loss: 0.9400 - val_accuracy: 0.5676\n",
      "Epoch 482/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1195 - accuracy: 0.3438\n",
      "Epoch 482: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0589 - accuracy: 0.4865 - val_loss: 0.9725 - val_accuracy: 0.5541\n",
      "Epoch 483/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0131 - accuracy: 0.5312\n",
      "Epoch 483: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0872 - accuracy: 0.4696 - val_loss: 0.9683 - val_accuracy: 0.5270\n",
      "Epoch 484/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2868 - accuracy: 0.4062\n",
      "Epoch 484: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0533 - accuracy: 0.4899 - val_loss: 0.9614 - val_accuracy: 0.5405\n",
      "Epoch 485/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0341 - accuracy: 0.3438\n",
      "Epoch 485: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0757 - accuracy: 0.4865 - val_loss: 0.9227 - val_accuracy: 0.5270\n",
      "Epoch 486/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9574 - accuracy: 0.6562\n",
      "Epoch 486: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0102 - accuracy: 0.5236 - val_loss: 0.9032 - val_accuracy: 0.5676\n",
      "Epoch 487/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1315 - accuracy: 0.3125\n",
      "Epoch 487: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0637 - accuracy: 0.4831 - val_loss: 0.9327 - val_accuracy: 0.5676\n",
      "Epoch 488/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9162 - accuracy: 0.5312\n",
      "Epoch 488: val_loss did not improve from 0.88590\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0371 - accuracy: 0.5236 - val_loss: 0.9031 - val_accuracy: 0.5541\n",
      "Epoch 489/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8807 - accuracy: 0.5625\n",
      "Epoch 489: val_loss improved from 0.88590 to 0.87720, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0097 - accuracy: 0.5405 - val_loss: 0.8772 - val_accuracy: 0.5676\n",
      "Epoch 490/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1238 - accuracy: 0.4375\n",
      "Epoch 490: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0514 - accuracy: 0.5304 - val_loss: 0.9194 - val_accuracy: 0.5405\n",
      "Epoch 491/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1577 - accuracy: 0.5000\n",
      "Epoch 491: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9974 - accuracy: 0.5304 - val_loss: 0.9175 - val_accuracy: 0.5676\n",
      "Epoch 492/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8880 - accuracy: 0.6562\n",
      "Epoch 492: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9662 - accuracy: 0.5473 - val_loss: 0.9156 - val_accuracy: 0.5541\n",
      "Epoch 493/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8945 - accuracy: 0.6250\n",
      "Epoch 493: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0418 - accuracy: 0.5236 - val_loss: 0.9170 - val_accuracy: 0.5405\n",
      "Epoch 494/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9801 - accuracy: 0.4062\n",
      "Epoch 494: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9894 - accuracy: 0.5541 - val_loss: 0.8984 - val_accuracy: 0.5811\n",
      "Epoch 495/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9580 - accuracy: 0.7188\n",
      "Epoch 495: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0336 - accuracy: 0.5338 - val_loss: 0.9202 - val_accuracy: 0.5676\n",
      "Epoch 496/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9039 - accuracy: 0.6250\n",
      "Epoch 496: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9800 - accuracy: 0.5405 - val_loss: 0.9228 - val_accuracy: 0.5541\n",
      "Epoch 497/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9629 - accuracy: 0.5938\n",
      "Epoch 497: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9398 - accuracy: 0.5541 - val_loss: 0.9207 - val_accuracy: 0.5135\n",
      "Epoch 498/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1354 - accuracy: 0.5312\n",
      "Epoch 498: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0181 - accuracy: 0.5236 - val_loss: 0.9440 - val_accuracy: 0.5541\n",
      "Epoch 499/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0085 - accuracy: 0.4062\n",
      "Epoch 499: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0782 - accuracy: 0.4527 - val_loss: 0.9350 - val_accuracy: 0.5270\n",
      "Epoch 500/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0774 - accuracy: 0.4375\n",
      "Epoch 500: val_loss did not improve from 0.87720\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0012 - accuracy: 0.5507 - val_loss: 0.9472 - val_accuracy: 0.5541\n",
      "Training completed in time:  0:00:25.878794\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Cargo       1.00      0.08      0.15        24\n",
      "   Passenger       0.55      0.80      0.65        20\n",
      "      Tanker       0.42      0.68      0.52        19\n",
      "         Tug       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.55        74\n",
      "   macro avg       0.70      0.62      0.55        74\n",
      "weighted avg       0.70      0.55      0.49        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Decode labels\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5540540814399719\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded)\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
