{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "Model Pre Work\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Libraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = pd.read_csv(r'./100_files_mfcc.csv')\n",
    "ex_data['Features'] = ex_data['Features'].apply(lambda x: list(map(float, x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-351.6251220703125, 86.87262725830078, -14.98...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-433.6374816894531, 102.78813934326172, 4.263...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-459.4378967285156, 118.9866714477539, 14.566...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-503.5106201171875, 129.89466857910156, 12.60...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-290.6701965332031, 115.29109191894531, -9.09...</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>[-497.34600830078125, 64.05010986328125, -9.53...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>[-507.68927001953125, 109.86592102050781, 2.85...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>[-408.8243408203125, 100.6327133178711, -5.617...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>[-433.462646484375, 86.5696029663086, -6.83201...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>[-443.96453857421875, 85.13563537597656, -11.1...</td>\n",
       "      <td>Tug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Features  Class\n",
       "0    [-351.6251220703125, 86.87262725830078, -14.98...  Cargo\n",
       "1    [-433.6374816894531, 102.78813934326172, 4.263...  Cargo\n",
       "2    [-459.4378967285156, 118.9866714477539, 14.566...  Cargo\n",
       "3    [-503.5106201171875, 129.89466857910156, 12.60...  Cargo\n",
       "4    [-290.6701965332031, 115.29109191894531, -9.09...  Cargo\n",
       "..                                                 ...    ...\n",
       "365  [-497.34600830078125, 64.05010986328125, -9.53...    Tug\n",
       "366  [-507.68927001953125, 109.86592102050781, 2.85...    Tug\n",
       "367  [-408.8243408203125, 100.6327133178711, -5.617...    Tug\n",
       "368  [-433.462646484375, 86.5696029663086, -6.83201...    Tug\n",
       "369  [-443.96453857421875, 85.13563537597656, -11.1...    Tug\n",
       "\n",
       "[370 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(ex_data['Features'].tolist())\n",
    "y=np.array(ex_data['Class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc Features       :  (370, 40)\n",
      "Class Labels shape  :  (370,)\n"
     ]
    }
   ],
   "source": [
    "print('mfcc Features       : ',X.shape)\n",
    "print('Class Labels shape  : ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy_1 = X\n",
    "y_copy_1 = y\n",
    "\n",
    "X_copy_2 = X\n",
    "y_copy_2 = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding the class labels of y_copy_1\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_copy_1 = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_copy_1,y_copy_1,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total count for all audio files loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo: 100\n",
      "Passenger: 100\n",
      "Tanker: 101\n",
      "Tug: 69\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each category\n",
    "category_count = Counter(y)\n",
    "\n",
    "# Print the total count of each category\n",
    "for category, count in category_count.items():\n",
    "    print(f'{category}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total count for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 58\n",
      "0: 76\n",
      "2: 82\n",
      "1: 80\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each category\n",
    "category_count = Counter(y_train)\n",
    "\n",
    "# Print the total count of each category\n",
    "for category, count in category_count.items():\n",
    "    print(f'{category}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "Machine Learning Models\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Parameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': [0.1, 1, 10] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(svm_pipeline, param_grid, cv=4, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_svm_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Accuracy for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters  :: {'svm__C': 1, 'svm__gamma': 0.1}\n",
      "Test Accuracy    :: 0.7162162162162162\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = best_svm_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Best Parameters  ::\", best_params)\n",
    "print(\"Test Accuracy    ::\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth') \n",
    "#new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.35552612e+02,  9.07027435e+01, -7.27298212e+00, ...,\n",
       "         2.51303864e+00,  1.20482337e+00,  2.68149996e+00],\n",
       "       [-4.04413757e+02,  9.77079697e+01, -5.01113558e+00, ...,\n",
       "         2.90905857e+00,  1.93504894e+00,  2.03778458e+00],\n",
       "       [-5.36053650e+02,  8.17501450e+01, -3.60933989e-01, ...,\n",
       "         2.62656093e+00,  4.41035318e+00,  2.99083757e+00],\n",
       "       ...,\n",
       "       [-4.31704163e+02,  9.08808136e+01, -1.98757231e+00, ...,\n",
       "         2.48214459e+00,  4.40991354e+00,  3.42045212e+00],\n",
       "       [-4.23589966e+02,  1.17420769e+02, -1.51836610e+00, ...,\n",
       "         2.78379250e+00,  5.76640844e+00,  3.93944144e+00],\n",
       "       [-3.52753784e+02,  8.63352737e+01,  1.41406417e+00, ...,\n",
       "         1.61775100e+00,  2.86210513e+00,  2.73233318e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn0AAAHACAYAAADXz977AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZZklEQVR4nO3dd1gUVxcG8HdpSwcBqSIdG6AoRsGuUWOMJfYSS+xRE7vGEIOaCJZoNPauKZbEFhNLRBOxYEOxYUHpCkgVkM6y3x98WbMRdBcXVpn3l2eeuHdm7pxhC4dz586KpFKpFERERERUo2moOwAiIiIiqnpM+oiIiIgEgEkfERERkQAw6SMiIiISACZ9RERERALApI+IiIhIAJj0EREREQkAkz4iIiIiAWDSR0RERCQAWuoOoCo4rQ1RdwhUjW6Nk6g7BKpGf8QXqTsEqkZ9nCzUHQJVIx0NH7UdW6/uYJX2lx+/W6X9qUKNTPqIiIiIlCES1fzBz5p/hkRERETESh8RERGRSAB1MCZ9REREJHgc3iUiIiKiGoGVPiIiIhI8IVT6mPQRERGR4IlEInWHUOVqflpLRERERKz0EREREQmhDsakj4iIiARPCNf01fwzJCIiIiJW+oiIiIiEUOlj0kdERESCJ4Rv5Kj5Z0hERERErPQRERERcXiXiIiISACEkPTV/DMkIiIiIlb6iIiIiIRQ6WPSR0RERIInAr97l4iIiIhqAFb6iIiISPA4vEtEREQkAEJI+mr+GRIRERERK31EREREQqj0MekjIiIiEsDgZ80/QyIiIiJipY+IiIiIw7tEREREAiCEpK/mnyERERERsdJHREREJBJAHYxJHxEREQkeh3eJiIiIqEZgpY+IiIgETyQSqTuEKsekj4iIiASPw7tEREREVCOw0kdERESCx9m7RERERALA4V0iIiIiqhFY6SMiIiLBE0Klj0kfERERCZ4Qrumr+WdIRERERKz0VZcpzR0w9R1HubbUvCK8s/2C7LG+tgbmtHRGZ2cL1NLVwqPsAuy4+Rg/RyRV2G9XZwtMbFYXjiZ60NIQITYrH1vCE3AwMkWp+PxbuaBffSvkFkuwODQafzxMla3r7lobH7pbYczR20r1Sc+VlEiwad0fOHbkCtLTsmFR2xgf9PLFmPHdoKFR/t9e4dceYvWKg4iNeYKCgiJY25qhb/82GDq8k1LH/mF7MH7cHgwAGDmmq9z+t27GYPE3u/HD7s+hqcm/ASvrzN5g3A29gbRHKdDW0YZ9Ayd0HtUDFnWsZNs8y8xG8PbfEXXtHgpy8+Hg4YL3J/SFuZ1lhf2GHQ/FjVNXkBJX9hlg62qPTiM+QJ16DkrFd3zTQVw/eRk6ejroPKoXPNs1la27fSYcN/66gqHzxyl51lSeLZt+w6rvfsFHw97DnC+GVbjdyRNXsHfPSdy/F4eiomK4uNbBxMl90aq1l1LH27HtCLZv+wMAMHpMTwwf2U227uaNh/hm4Xbs/uVrvr8VweFdUqX76bn46PAN2ePSUvn181q5omUdU0wLvotHOQVoa2+Ghe3ckJJXhOCY9HL7fFpQjLVhcYh6mo9iSSk6Oppjaaf6SM8vxpmETIXi6uRojl7ulhh++CYcTfWwrFM9nEvIxNPCEhjpaGJGC0d89NvNSp83ATu3nsC+X85iwaIRcHG1xZ2IOCz48gcYGuphyLCO5e6jpyfGgCHt4eZuBz09Ma5fe4hFC3dBT08Hffq3Uei4DyIfY8Pa37Fy7URACkydtA4tfOvD1c0OxcUSBC3cBf+AofyF8Jribj/EOx+0gZ17XZRKSnFq5x/4wX89Jm+cCx1dMaRSKXZ/vRWampoY/NUYiPV1EXrwNHZ+sU62TXlibz6EZ7umsG/gBC0dbZzfdwo/frkek9Z/DmMLU4Viu3/pNm6FXMWwbz5BRmIqDn23Cy7e9aBvbID8Z3k49cMfGBE4SYU/DeG6fSsK+375G+716r5y26th9+Dr54Ep0wbAyMgAhw6GYPLEb7Frz0I0aOio0PEiI+OxdvU+rFk/E1KpFJM/+Ra+fh5wc7dHcXEJvl6wDQELRvP9rSAhXNNX88/wDSKRSpGWVyxbMgqK5dZ7WxvjwL1kXErMwuOcQuy+k4S7ac/gWduowj4vJWbhREw6ojLzEP//yuC99GfwsTFROC7XWvq4+PgpbqU+w+8PUvGsSIK6JnoAgLl+zvjpdiISnxVW7qQJAHDzRjTad2iMNu08YWtnjne7NEVLvwa4GxFX4T71G9jjvfebw8XVFrZ25ni/Rwv4+jVE+NWHCh83JjoZbu52eKdFfbzTsj5c3e0QE50MAPhx+wl4N3NDI0/H1z09wRv29Sfw7twClg42sHa2Q+/pQ5GVmonEBwkAgPTHqXh0LxYfTO4PO3cHWNSxwgcT+6OooBC3Tl+rsN9+s4fjnQ/awMalDmrbW6HnZ4MgLS1F9I1IhWNLjX8CR09X2LnXhWf7ZhDri5GZnAYACN52GM27t4appdnr/QAIebkF+HzWOgQsHANjY4NXbj/ni2EYNaYHPDxd4OBojSnTBsKhrjVO/13x6+G/oqMS4e5ujxYtG6Glrwfc69VFdHQigLIKYDOf+vDwdKn0OVHNw6SvGjma6OHiyJY4M+wdfN+lAeyNdeXWhyVloZOjOawMdAAALe1M4WSqhzMJGQofw6+OKZxN9XE5MUvhfe6mPYOnpRGMxVrwqG0IsZYGYrPy4WNjjEa1jbDj5mOF+6LyNWnqisuX7iEu9gkAIPLeI1y/FoVWbT0U7uPe3QTcvB6Npj5uCu/j5maL+NgUJCVlICkxHfFxT+DqaouE+BT8/ttFTPysp9LnQq9WkJsPANAz0gcASIpLAABaOtqybTQ0NaCppYX4O9EK91tcWASJpBR6hvoK72PtbIvEBwnIz8lD4oMElBQWw8ymNuIiopD08BFa9myncF9UsUVf70Cbdk3g66f4e/rfSktLkZtXABNTQ4X3cXe3R2xcMpIS05D4OBWxsUlwc6uD+Lhk/HbwDD6d0r9SsQiVSCRS6fImUuvw7qNHj7B+/XqEhoYiOTkZIpEIVlZW8PPzw4QJE2Bvb6/O8FTq+pMczDh5DzFP82Ghr43JPg7Y39cbXXZdwdPCsl8IC84+RFAHd1wc6YtiSSlKAcz96z7CkrJf2reRjiYujPSFjoYIpVJg3pkHOPdIsaFdADiTkIlD95/gt/5NUVAiwcyT95BfLMHX7dww69R9fORhixGedsgoKMYXpyPxICPvdX4UgjRydBc8y8lH3x4LoKEpQqlEiomf9cR77zd/5b7dOs1FZsYzSCQSjJv4AT7s11rh4zq52GDSlF6YNHYVAGDylN5wcrHBJ2NW4rPpH+LC+TvYtO4PaGlpYubnA5RKKKl8UqkUf24+hLqNnGHlaAsAsLC3gqmlGU5u/x09Ph0IbV0dXDj4N55lZiMn4+Xv738L3v47jM1N4OxdT+F9XJs1gFcHH2yauhxaOtr4cMZQaOvq4I81v+LD6UNx5eg5XDp8FvrGBuj52UBYOtgofc5Cd+zIBdy5E4M9v35d6T52bj+K/LxCdH2vhcL7OLvYYcrUARg3ejEAYOq0gXB2scOYjwMxbeZgnD93E+vXHICWtibmzB0Gn+YNKh2fEAhh9q7akr5z586hW7dusLe3R5cuXdClSxdIpVKkpKTg0KFDWL16NY4dO4ZWrVq9tJ/CwkIUFsoPPUqLiyDS1qnK8JUWEv+8Wnc/A7iWnI2QYS3Qt741tt54BAAY6WUHbytjjDlyG49zCvCOrYnsmr7zj55W2PezIgm67w2DvrYmWtWphS9buSA+Kx+XlKj2rboSh1VXng81TmnugPMJT1FSKsVkHwe8tzsMHR3NsLxTffT8VfHhBypz4lgYjv1xGYuWfAxnV1tE3nuE5Ut+RW1LE/To5fvSfbfsnIG8vELcuhmDNd8dgn3d2goli//oN7At+g1sK3t8+NAF6OvrwquxM/r0mI8f93yOJ08yMXfWVvz+59fQ+Vc1ipR3ZN0+PIlJxKhvp8jaNLU0MdB/FH5btRuLB86FhoYGnL3d4eaj+C/hc7+ewu2Qaxi5ZDK0lXyOOnzUDR0+en6B/98/HYOztzs0tDRwZs8JTFz3OSIv3caB5T9hwvezlOpb6JKT0rE46Ads2vI5xOLK/d45eiQU69cewKo102FurvilOQAwYNC7GDDoXdnjQwdDYGCgh8ZN3NDz/ZnY/cvXePIkHbNnrMHxkyv5/hY4tSV906ZNw5gxY/Ddd99VuH7q1Km4cuXKS/sJCgrCggUL5NpMuo1Are4fqyzWqpBfUor76blwNC27dk6sqYGZLZ0w4VgE/o4rSxDvpeeioYUhxjaxf2nSJwUQl1UAALiblgvXWvqY2KwuLiXeqlRszqZ66OVuiQ9+uYoBDWxwOfEpMgqKceRhKpZ1qg9DbU08K5ZUqm+hWrX8IEaO6YKu/0/W3NztkJSUju1b/nxl0mdXx0K2T0Z6Njat+0OppO/fMjOfYcuGI9i8YwZu34qBg4Ml6v5/KSmRIC42BW7udpXqm4Aj6/fh/qXbGLX0M5j8Z6KFrZs9PlkzGwW5+ZCUSGBgYohNU1fA1u3VIxrn9/+Fs78EY/iiibB2er3nJzXhCW6eDsOE1bMRfuIiHBq5wMDEEI3aeuPQyt0oyCuArr7uqzsiAEBERAwy0rMxsN+XsjaJpBRXw+5h964TuHpj50snUhw/egEBX27G8u8+q/TQ8D8yM3OwYd1B7PhxHm7dfAgHR2vZUlIiQWxsEtzdXz3JRKiEMJFDbUnf7du38dNPP1W4fvz48diwYcMr+5k7dy6mT58u1+a17dJrx1fVdDREcKn1/No7bQ0RdDQ1UCqV304ilUKjEpcG6LzGbK2gDu4IPB+NvOJSaIgArf/fUkTr/4G8oZcqvNEKCopeuMZDQ0MD0v8+4a8glQJFRSWVjmP54l8xZFgnWFnXQsTtOJSUPE/eJRIJSv87pZwUIpVKcXT9fty9cBMfL56MWtbmFW6ra1D2h1764xQkPoxHx+Hvv7Tvc/tO4cyeExj2zSewe81f2FKpFL9/vxddx/SGWE+M0tJSSCRlrwHJ/18LUr4GlNLStxEO/LZYrm2e/yY4Odlg1JgeL034jh4JxVf+m7Dk28lo2977tWNZEvQjho3oBmtrc0TcipZ7f5dIJCiV8Ll9KQH8clNb0mdjY4PQ0FDUq1f+tSkXLlyAjc2rry0Ri8UQi+Vvd/CmDe0CwBd+zjgVm47HOYVl1/Q1c4ChjiYO3C+bSfmsWIKLj59irp8zCkokeJxTiBZ2JuhTzwrfnIuS9bO8Uz0k5xZh2cUYAMAnTe1xK+UZ4rLzoa0hQgcHc/SpZ4V5IQ8qFefghjZIzyvGydiyW8RcTcrGlOaOaGJlhPYOZojMyEVOEat8ymrT3hPbNh+HtY0ZXFxtce9uAn7+4RR6fegn22b1d4eQmvIUC4NGAgB+2X0a1jZmcHSyBgBcv/YQP+4IxqAh7SsVw8XQu4iPT8HCoBEAAA9PR8TGPMH5s7fxJDkTGhoacHC0ekUvVJ4j637FrdPXMPirMdDR05Vdp6droAvt/w/5RZwNh76JIUxq10JKbBKObTyA+i094dq0vqyfA9/+BCNzE3T+uAeAsiHdv348gn6zh8PU0kzWr46eGGK98m/z8jJXj1+Agakh6rf0BADUbeiM0z8fR8K9WDwIu4Pada2VmiRCgIGBHtzc5au1enpimJoaybWvXLEHKU8yEbjkEwBlCZ//5xswZ+4wNG7sirTUpwAAsa4OjIyUfw5Cz99CfFwyAhdPAAB4eLkgJjoRZ89cR3JyBjQ1NODoZFvJs6SaQm1J38yZMzFhwgRcvXoVnTt3hpWVFUQiEZKTkxEcHIwtW7Zg5cqV6gpP5awNxVjVpQFq6WojI78Y4U+y0WdfOB7nPL8e8dMTdzC7pTNWdm4AU10tPM4pxLcXY+VuzmxrpCtXDdTX1sTCdq6wMRSjoKQUUZl5mHbyHo786+bKirLQ08bEZnXRd3+4rO1GSg62XH+EbR94Ij2vCDNP3a/cD0DgZn8xEOtXH8bib/YgMyMHFrVN0Ld/a4z9pLtsm7S0LCQnPb/2s7RUijUrD+Hx43Roamqgjn1tfDq1N/oOUOweff9WUFCEpYF7EPTtGNnNoC2tTDFr7gAs+PJHaOtoYcGiEdDVffP+YHobXDlyHgCwfc5qufbe04bAu3PZhfk5Gdk4vvkQcp/mwLCWMRp3ao52g7vKbZ+VmgnRv0r7V46cg6REgr2B2+W2az/kPblr9BTxLDMbZ/cGY/TyqbK2OvUc4NenA34O2AgDUyN8OH2oUn2S4lJTnyIp6fn9Vn/d+xdKSiRY9PUOLPp6h6y9Z+82WBQ0Qam+CwqKEPTNTixbMVn2/rayMsNc/xGY578JOtpaWBQ0ge/vV6n5o7sQSaVS5caXVGjv3r347rvvcPXqVdkQg6amJpo1a4bp06djwIABlerXaW2IKsOkN9ytcaw8Cskf8UXqDoGqUR8nC3WHQNVIR8NHbcd2912v0v4iL3yi0v5UQa23bBk4cCAGDhyI4uJipKWV3SzUwsIC2tqcXURERESkSm/E17Bpa2srdP0eERERUZXgRA4iIiIiARDANX0COEUiIiKiN1NJSQm+/PJLODk5QU9PD87Ozli4cKHcLbSkUinmz58PW1tb6OnpoX379oiIiFD6WEz6iIiISPCkIpFKF0UtWbIEGzZswJo1a3D37l0sXboUy5Ytw+rVz+8GsHTpUqxYsQJr1qzBlStXYG1tjc6dOyMnJ0epc2TSR0RERCRS8aKgCxcuoFevXujevTscHR3Rr18/dOnSBWFhYQDKqnwrV66Ev78/+vTpAw8PD+zcuRN5eXnYtWuXUqfIpI+IiIhITVq3bo1Tp04hMjISAHDjxg2cO3cO779f9m09MTExSE5ORpcuXWT7iMVitGvXDqGhoUodixM5iIiIiCrznacvUVhYiMLCQrm28r5FbM6cOcjKykL9+vWhqakJiUSCRYsWYfDgwQCA5OSyb+6yspL/xiQrKyvExcUpFRMrfUREREQikUqXoKAgmJiYyC1BQUEvHHbv3r346aefsGvXLly7dg07d+7Et99+i507d/4nPPmkVCqVvtD2Kqz0EREREanY3LlzMX36dLm2/1b5AGDWrFn4/PPPMWjQIACAp6cn4uLiEBQUhBEjRsDauuz715OTk+XuaZySkvJC9e9VWOkjIiIiUvFEDrFYDGNjY7mlvKQvLy9P9p3J/9DU1JTdssXJyQnW1tYIDg6WrS8qKkJISAj8/PyUOkVW+oiIiIhUfE2fonr06IFFixahbt26aNSoEcLDw7FixQqMGjUKQNmw7tSpUxEYGAg3Nze4ubkhMDAQ+vr6GDJkiFLHYtJHREREpCarV6/GvHnzMHHiRKSkpMDW1hbjx4/HV199Jdtm9uzZyM/Px8SJE5GZmYkWLVrgxIkTMDIyUupYIqlUKlX1Caib09oQdYdA1ejWOIm6Q6Bq9Ed8kbpDoGrUx8lC3SFQNdLR8FHbsd06b1Vpfw+CR6u0P1VgpY+IiIhIPaO71YoTOYiIiIgEgJU+IiIiIjVN5KhOTPqIiIiIan7Ox+FdIiIiIiFgpY+IiIgET6rkV5q9jZj0EREREQngmj4O7xIREREJACt9RERERDW/0Mekj4iIiAgCuKaPw7tEREREAsBKHxEREZEAJnIw6SMiIiKq+Tkfh3eJiIiIhICVPiIiIiIBTORg0kdEREQkgKSPw7tEREREAsBKHxEREZEAymBM+oiIiIg4vEtERERENQErfUREREQ1v9DHpI+IiIhIKoBv5ODwLhEREZEAsNJHREREJICJHEz6iIiIiGp+zsfhXSIiIiIhYKWPiIiISAATOZj0EREREQngmj4O7xIREREJQI2s9MVMslF3CFSN9OoGqDsEqkb58QvUHQJVo0LJU3WHQEJR8wt9NTPpIyIiIlKKAK7p4/AuERERkQCw0kdEREQkgEofkz4iIiISPGnNz/k4vEtEREQkBKz0EREREXF4l4iIiEgAeHNmIiIiIqoJWOkjIiIi4vAuERERkQAIYOxTAKdIRERERKz0EREREXEiBxERERHVBKz0EREREXEiBxEREVHNJ+XwLhERERHVBKz0EREREQmgDMakj4iIiEgA1/QJIK8lIiIiIlb6iIiIiAQwkYNJHxERERGHd4mIiIioJmClj4iIiKjmF/qY9BERERFJObxLRERERDUBK31EREREAqj0MekjIiIiEsAtWzi8S0RERCQArPQRERERCaAMxqSPiIiIiMO7RERERFQTsNJHRERExNm7RERERAIggKSPw7tEREREAsBKHxEREQmeVAATOZj0EREREQlg7FMAp0hERERErPQRERERcXiXiIiISAA4e5eIiIiIagImfUREREQaItUuSnj8+DE++ugjmJubQ19fH02aNMHVq1dl66VSKebPnw9bW1vo6emhffv2iIiIUP4Uld6DVObnn4+gY8fR8PTsgz59piIs7NVP4OXLt9Cnz1R4evZBp05jsHv3MaWPu3XrAfj5DYOf3zDs2HFIbt2NG/fRp89USCQSpful5wwNdLEsYDjuh36PjMid+PvAAjTzcpbbZtPyCciP3y23hBxa+Mq+e3d7B9dOLcPTBz/g2qll6NnVR+n4lsz7CI9vbkbkhdXo38NXbl3fD1pi37aZSvdJ8vj+Fo51aw7Aq+EwuaVDm8mv3C/syl0M7DcPPk1GoVuX6fhlzymlj71j2xG0bzMJ7dtMwo875V8vN288xMB+8yCRlCrdryCJVLwoKDMzE61atYK2tjaOHTuGO3fuYPny5TA1NZVts3TpUqxYsQJr1qzBlStXYG1tjc6dOyMnJ0epU+Q1fWpy9OhZBAVtQUDABDRt2hB79hzH2LHzceTIWtjaWpa7T0JCMsaNW4D+/bti2bIZuHbtDhYs2AAzM2N07dpKoePevx+L77//GRs2fAUAGD9+Ifz8vOHu7oDi4hIEBKzDwoWToKmpqbJzFaL1S8ehYT17jJq6DklPMjG4T2sc2eWPpp1mIvFJpmy7P/++jvEzN8geFxWVvLTfFk3d8OPaz7Bg+a84fPwKer7XHD+tm4JOfefjyvUohWJ7/92mGNCrFXp8FARXR2tsXD4Bp87eQsbTZzAx1sf8WQPw/uBFlTtxAsD3txC5uNph89bPZY81NF9eU3n0KAUTJ3yLvv06IGjJBISHP8CihTtQy8wYnbs0V+iYkZEJWLfmAFavmw6pFPh04nK09POAm5s9iotL8M2CHfhqwShoviIWUq8lS5bA3t4e27dvl7U5OjrK/i2VSrFy5Ur4+/ujT58+AICdO3fCysoKu3btwvjx4xU+Fl8JarJ9+yH07dsZ/ft3hYuLPfz9x8La2uKlf9nv2XMcNja14e8/Fi4u9ujfvyv69HkX27YdVPi4UVEJqFfPCb6+jeHr2xj16jkiKioBQFmFwMenEby83F/7/IRMV6yN3t3egX/gLpy/fA/RcU+w6Lv9iE1IwdhhneW2LSoqxpPULNmSmZX70r4nj+6GU2dv4du1vyEyKhHfrv0Nf5+PwOTR7yscX31XO5y9eAfXbkbjl8OhyM7Jh1PdskRk0RdDsOmHYCQkpit/4iTD97fwaGlqwqK2qWwxMzN+6fa/7v0LNjYWmDP3Izi72KFvv/b4sE877Nx+VOFjxkQlws3dHi1aNkJL30Zwc7dHTFQiAGDHtqNo6lMPHp7Or+iF/iHVEKl0UdThw4fh4+OD/v37w9LSEt7e3ti8ebNsfUxMDJKTk9GlSxdZm1gsRrt27RAaGqrUOTLpU4OiomJERDxE69becu2tWnkjPPxuhftdv34PrVrJ79OmTVPcvv0QxcUvrxD9o149R8TGPkZiYgoeP05BbOxjuLs7IC4uEQcPnsLUqR8pf0IkR0tLE1pamigoLJJrLygogl/zenJtbVo2RNy1Dbh5egXWLhmL2uYv/0XRoqkbTp25Kdd2MuQGWjZzUzi+m3fi0NTLGaYmBvD2dIKerjai4p7Ar3k9NPFwwtrtxxXui17E97cwxcUno1O7T/Fe52mYPWMNHiWkvHT7G9cfwtfPQ67Nr7Un7kTEKPx8u7nXQVxsMpIS05D4OA1xcclwdauD+LgnOHzoLD6d0q/S5yNIIpFKl8LCQmRnZ8sthYWFLxw2Ojoa69evh5ubG/78809MmDABn332GX744QcAQHJyMgDAyspKbj8rKyvZOkVxeFcNMjOzIZGUwtzcVK7dwsIUqalPK9wvLS0TFhby+5ibm6KkRILMzGxYWpq98tguLvaYNm04Pv64bPhn+vQRcHGxx8iRX2LWrJE4dy4ca9bsgpaWFvz9x6J5c49X9Ej/9Sy3ABfDIjH3sz64/zART1KfYkCvVmju7YqHMc/foCdOX8eBI5cQ/ygVjnUt8dWM/ji250v4df+iwmFeq9qmSEnLkmtLScuCVW1TheM7eeYmdh88h3O/f4P8giKMnb4euXkFWLVoFMbN2IBxwzrjk5FdkZ6Zg0mfb8HdyEeV+jkIFd/fwuPp5YJFQRPg4GiNjLQsbNr4G4YNWYiDvwfB1NSo3H3S07Jgbm4i12ZuboySEgmePn2G2gq8p51d7PDZ1P4YN2YJAGDK1AFwdrHD2FGLMW3GQJw/dwvr1x6AtpYWZn/xEXx86r/2uZLigoKCsGDBArm2gIAAzJ8/X66ttLQUPj4+CAwMBAB4e3sjIiIC69evx/Dhw2Xbif5zH0GpVPpC26u80UlfQkICAgICsG3btgq3KSwsfCFzFouLIBbrVHV4r638J1D5fcprf5nBg7th8OBusscHDpyEgYEemjSpj/fe+wT79q1AcnIapk1bhr/+2gIdHW2F+6Yyo6atxcZlExB9ZR1KSiS4fjsGew+Foomno2ybfb9flP37TuQjXLsZjfuhq9Gtozd+O36lwr7//5TLiEQi2etAUYu+249F3+2XPfaf1hd/n7uN4mIJ5nz6IZp3mY1unZpiy3efoFV3f6X6pjJ8fwtHm7aNnz9wt4dXE1d07zoThw+dw/CR3Src779P6z9vY2V+jQ8Y1AkDBnWSPf7t4BkYGOiicRM39Ow+G7v2LsCTJxmYM2MtjgWv4PP9Miq+T9/cuXMxffp0uTaxWPzCdjY2NmjYsKFcW4MGDbB/f9lntLW1NYCyip+NjY1sm5SUlBeqf6/yRg/vZmRkYOfOnS/dJigoCCYmJnJLUNDGaoqwcmrVMoampgbS0jLl2tPTs174S//fLCxqITVVfp+MjCxoaWlW+Nfkq2RkZGHt2j2YN288btyIhKOjLRwdbdGypRdKSkoQE/O4Uv0KXUxcCroMWAjzeiPh1nIy2vScB21tTcTGp1a4T3LKU8Q/ToWrk3WF2zxJfQqr2vLVgdrmxi9U/5Th7mKLQb1bYcG3v6CtbwOcv3wPaRk52P/HRTT1dIaRoV6l+xYivr9JX1+3bOg1ruKhN3MLE6T9532bkZENLS1NmJgaVuq4mZk52LD+ED73H46bN6Pg4GgNB0drvNOiIUpKJIiNVW4oUHBUPHtXLBbD2NhYbikv6WvVqhXu378v1xYZGQkHBwcAgJOTE6ytrREcHCxbX1RUhJCQEPj5+Sl1imqt9B0+fPil66Ojo1/ZR/mZdPxrxVXVdHS00aiRK86fD0fnzs9vlxEaeh2dOrWocL8mTerj778vy7WdOxcODw9XaGtX7qkMDNyCkSN7wdraArduPUBJyfNbOUgkEpSWcqr/68jLL0RefiFMTQzwblsv+AftqnBbM1ND1LExR1LK0wq3uXTtATq28cTqrc8nBHRq64WLVx9UOsa1i8fg829+Rm5eITQ1NKCtVTazU1u77P8aArhLvSrx/U1FRcWIjk5E02b1KtymcRNXhPwdLtcWev4WGjZyqvTzvTToJwwb/h6src0QcTsaJcXPn+8SiQSlvHXLG2natGnw8/NDYGAgBgwYgMuXL2PTpk3YtGkTgLJK/9SpUxEYGAg3Nze4ubkhMDAQ+vr6GDJkiFLHUmvS17t371cOTb1qWEMsFpeTOb/5Q7sff9wbs2evgIeHG7y962Pv3uNISkrFoEHPhwKWL9+JJ0/SsXRpWVI7aNB7+PnnPxAUtAUDBnRFePg97N8fjOXLK3dPtfPnwxEXl4ilS6cBALy83BEd/QghIWFITk6DhoYGnJzsXv9kBejdtl4QiUSIjE6Ei6M1Ar8YggfRSfjhlxAAgIG+GF9O64dDxy4jKSUTDnVqY+HsQUjPzMHhfw3tbvnuEyQmZ+KrJXsAAGu3HUPwrwGY8UkP/H7iKnp0aYaOrT3Qqe/8SsU5akhHpKZn40hw2U1AL4RFwn9aP7zj7YouHZrgTuQjZGXnvd4PQ4D4/haWb5fuQvsO3rC2MUdGejY2bfwNuc/y0bNXG9k2q1bsxZOUTAQungAA6D+wI3bvCsayJT+jb7/2uHH9IQ7uD8GSbydVKoYLobcQF5eMRYvLbt/h4emMmJhEnD1zA0+S06GpoQFHJ5tX9CJsGmoa+2zevDkOHjyIuXPnYuHChXBycsLKlSsxdOhQ2TazZ89Gfn4+Jk6ciMzMTLRo0QInTpyAkZFyowBqTfpsbGywdu1a9O7du9z1169fR7Nmzao3qGry/vttkJmZjXXr9iAlJQPu7g7YtCkAdnbP7+GVmpqBpKTnw4H29tbYtCkAQUFb8PPPR2BpaQZ//3EK38Pr3woKCrFw4UasXDkbGv9/pVtZmWPevHH44otV0NHRxpIl06Cr+2Ipml7NxFgfC+cMgp21GTKynuG3o5cRsGyvrNIikZSiUX17DOnbBqbGBkhOyUTIhTsYNmkVnuUWyPqxt7VAaenzP4ouXn2A4ZO/R8DMAfhqxgBExz3BsEnfK3yPvn+ztDDB7Em90aFPgKwt7EYUVm0+ggM7ZiM1LRtjp69/jZ+CcPH9LSwpTzIwZ+Y6ZGbmwMzMGJ6NXfDT7vmwtbOQbZOa9hTJSc9vhVSnjiXWbZiJpYt/xp5dJ1Hb0hSffzFM4Xv0/VtBQRECv/kBy5ZP/tfzbYbP/YfjK//N0NHRwjdB46Gr++YXRNRJyTkRKvXBBx/ggw8+qHC9SCTC/PnzX5gEoiyRVNkrwFWoZ8+eaNKkCRYuLP9bCG7cuAFvb+9KDEFEvn5w9NbQqxvw6o2oxsiPX/DqjajGKJQ8VXcIVI3Emu+o7dhOa0NU2l/MpHYq7U8V1FrpmzVrFnJzK74ZraurK/7+++9qjIiIiIiESJ2Vvuqi1qSvTZs2L11vYGCAdu3evEyZiIiIahZl73n3Nnqjb9lCRERERKrxRt+cmYiIiKg6CKDQx6SPiIiISAhJH4d3iYiIiASAlT4iIiISPJEAymBM+oiIiEjwOLxLRERERDUCK31EREQkeBoCqPQx6SMiIiLB4/AuEREREdUIrPQRERGR4Amh0sekj4iIiASP371LRERERDUCK31EREQkeLw5MxEREZEACGB0l8O7RERERELASh8REREJnhAqfUz6iIiISPCEkPRxeJeIiIhIAFjpIyIiIsHjd+8SERERCQCHd4mIiIioRmClj4iIiARPCJU+Jn1EREQkeCIBXNTH4V0iIiIiAahUpa+0tBQPHz5ESkoKSktL5da1bdtWJYERERERVRcO75bj4sWLGDJkCOLi4iCVSuXWiUQiSCQSlQVHREREVB2Y9JVjwoQJ8PHxwZEjR2BjYwOREH5KRERERG85pZO+Bw8eYN++fXB1da2KeIiIiIiqnRBqWEpP5GjRogUePnxYFbEQERERqYWGSLXLm0ihSt/Nmzdl//70008xY8YMJCcnw9PTE9ra2nLbenl5qTZCIiIiInptCiV9TZo0gUgkkpu4MWrUKNm//1nHiRxERET0NhLC8K5CSV9MTExVx0FERESkNiIB3LlYoaTPwcFB9u8zZ87Az88PWlryu5aUlCA0NFRuWyIiIiJ6Myid13bo0AEZGRkvtGdlZaFDhw4qCYqIiIioOolEql3eRErfsuWfa/f+Kz09HQYGBioJioiIiKg6CeG+wwonfX369AFQ9kMZOXIkxGKxbJ1EIsHNmzfh5+en+giJiIiI6LUpnPSZmJgAKKv0GRkZQU9PT7ZOR0cHLVu2xNixY1UfIREREVEVE0ChT/Gkb/v27QAAR0dHzJw5k0O5REREVGMw6StHQEBAVcRBRERERFVI6aTPycnppRc7RkdHv1ZARERERNWNlb5yTJ06Ve5xcXExwsPDcfz4ccyaNUtVcREpbOqBMeoOgaqR4wLeLF5IYgOc1B0CCcSb+n25qqR00jdlypRy29euXYuwsLDXDoiIiIiIVE9lXzrSrVs37N+/X1XdEREREVUbDZFqlzeR0pW+iuzbtw9mZmaq6o6IiIio2miIpOoOocopnfR5e3vLTeSQSqVITk5Gamoq1q1bp9LgiIiIiEg1lE76evfuLfdYQ0MDtWvXRvv27VG/fn1VxUVERERUbd7UIVlVUirpKykpgaOjI7p27Qpra+uqiomIiIioWqlsksMbTKlz1NLSwieffILCwsKqioeIiIiIqoDSiW2LFi0QHh5eFbEQERERqYWGSKrS5U2k9DV9EydOxIwZM/Do0SM0a9bshe/g9fLyUllwRERERNWB1/T9y6hRo7By5UoMHDgQAPDZZ5/J1olEIkilUohEIkgkEtVHSURERESvReGkb+fOnVi8eDFiYvgVSERERFSzCGEih8JJn1RaNj7t4OBQZcEQERERqYMQhneVSmz/fVNmIiIiInp7KDWRw93d/ZWJX0ZGxmsFRERERFTdRG/ojFtVUirpW7BgAUxMTKoqFiIiIiK1EMLwrlJJ36BBg2BpaVlVsRARERFRFVE46eP1fERERFRTcfbuv/wze5eIiIiopnlTv0VDlRRO+kpLS6syDiIiIiKqQkp/DRsRERFRTcOJHEREREQCIIRr+oRwjkRERESCx0ofERERCR6Hd4mIiIgEQAizdzm8S0RERCQATPqIiIhI8DREql0qKygoCCKRCFOnTpW1SaVSzJ8/H7a2ttDT00P79u0RERGh/DlWPiwiIiKimkFDxUtlXLlyBZs2bYKXl5dc+9KlS7FixQqsWbMGV65cgbW1NTp37oycnBylz5GIiIiI1OjZs2cYOnQoNm/ejFq1asnapVIpVq5cCX9/f/Tp0wceHh7YuXMn8vLysGvXLqWOwaSPiIiIBE9DJFXpoqxJkyahe/fuePfdd+XaY2JikJycjC5dusjaxGIx2rVrh9DQUKWOwdm7REREJHiqvmVLYWEhCgsL5drEYjHEYvEL2+7ZswfXrl3DlStXXliXnJwMALCyspJrt7KyQlxcnFIxsdJHREREpGJBQUEwMTGRW4KCgl7YLiEhAVOmTMFPP/0EXV3dCvsTieSzUqlU+kLbq7DSR0RERIKn6krf3LlzMX36dLm28qp8V69eRUpKCpo1ayZrk0gkOHPmDNasWYP79+8DKKv42djYyLZJSUl5ofr3Kkz6iIiISPBUPfRZ0VDuf3Xq1Am3bt2Sa/v4449Rv359zJkzB87OzrC2tkZwcDC8vb0BAEVFRQgJCcGSJUuUiolJHxEREZGaGBkZwcPDQ67NwMAA5ubmsvapU6ciMDAQbm5ucHNzQ2BgIPT19TFkyBCljsWkj4iIiATvTf4attmzZyM/Px8TJ05EZmYmWrRogRMnTsDIyEipfpj0ERERkeCp+pq+13H69Gm5xyKRCPPnz8f8+fNfq1/O3iUiIiISAFb6iIiISPCEUAVj0kdERESC9yYN71YVISS2RERERILHSh8REREJnugNnr2rKkz6iIiISPCEMLzLpE+Nfv75CLZuPYDU1Ey4udXFF1+MhY9Po5fuc/nyLSxevBUPHsTD0tIMY8b0xeDB3ZQ67tatB7B160EAwLhxfTFyZG/Zuhs37mPBgvX49dfl0NTUVPqcqEz0yTOIPnkGeakZAADjOjao/+H7sG4i//xmP07C7T2HkHb3ASCVwsjOBi0+GwN9C7MK+3547C9EnzqDvLRMiI0MYPdOUzQa2AuaOtoKx3fzp32IO3MRWrpieAz+EPa+PrJ1jy5eRfy5S/CbOVHJsxY2KyMxPn/XHe1dLaCrrYmY9FzMPhyB20nZAICp7VzQw8MaNsa6KJZIcSspG9/+9QDXH2dV2OegpnXQx8sW9SwNAQC3krKx7NQD3EiseJ/yfNmlHvo1sUNuUQkWB0fi94hk2bruDa3woZctxuwJr8RZ0z/4eU5vAyZ9anL06FkEBW1BQMAENG3aEHv2HMfYsfNx5Mha2NpalrtPQkIyxo1bgP79u2LZshm4du0OFizYADMzY3Tt2kqh496/H4vvv/8ZGzZ8BQAYP34h/Py84e7ugOLiEgQErMPChZP4AfGa9MxM4TGoNwysagMA4s9exIUVG9ApcC6M69gCAJ49ScWZhSvg0M4XDft+AG19PWQ/ToKGdsXJW/z5y7i99xCajR0GM3dnPEt6gqsbfwQAeA3rp1BsSdduIiE0DK0//xTPklNwdeOPsPSoD7GRIYpy8xDxy2G0+WLKa/4EhMVYVwv7R7XAhZgMjPz5GtJzC1HXTB/ZBcWybaLT8/DV0buIz8yHrrYGRrd0xA8fNUP71WeRkVdcbr8tHWrh8O0kXEt4isKSUoxv5YgfhzVD53Xn8SSnUKHYOrnXRi9PGwz7MQxO5vpY1ssDZ6PT8TS/GMZiLczs6IahP4Sp5OcgVPw8rxmEMMmBSZ+abN9+CH37dkb//l0BAP7+Y3Hu3DXs3n0MM2aMKHefPXuOw8amNvz9xwIAXFzscevWQ2zbdlDhD4moqATUq+cEX9/GAIB69RwRFZUAd3cHbN16AD4+jeDl5a6CMxQ2m6Zeco8bDeiF6JNnkfEwRpb03fnlMKwaN4LnkD6y7QwsLV7ab8aDGJi7u8C+VfOy7Wubo46vDzKjYxWOLedxMmo3cEMtZwfUcnbAzR/3ITclDWIjQ9zefRDOndu+tNJIL/qklRMSswow6/BtWdujrAK5bQ7fTpJ7/M2f9zCoaR3UtzJCaExGuf1OPSj/fZyf/x6Bbg2t0crJHAduJioUm6uFAS7GZuBWUjZuJWVjXtf6qFtLD0/zi/F5Z3f8FJaAxOyCV3dEFeLnec3wJn8jh6oIIbF94xQVFSMi4iFat/aWa2/Vyhvh4Xcr3O/69Xto1Up+nzZtmuL27YcoLi5R6Nj16jkiNvYxEhNT8PhxCmJjH8Pd3QFxcYk4ePAUpk79SPkTopeSlpYi4UIYJIVFMHN1lrUlX78NQxtLnFu8Gkc+mY2/v1qKxLDrL+3LvJ4LnsbEIyMqFgCQm5KGJzduw7qJx0v3+zcThzrIjIlHUW4eMmPiISkqhqG1JdLuP8TT2AS4du1Q2VMVrHfrWeJWUhbW9muMsJntcWScLwY1rVPh9toaIgxuZo/sgmLcTc5R+Dh62prQ1hDhaX75lcHy3H2SA09bExjrasHDxhi62pqIzciDj70pPGyMsf1SnMJ90Yv4eU5vE7VX+vLz83H16lWYmZmhYcOGcusKCgrwyy+/YPjw4RXuX1hYiMJC+WEOsbgIYrFOlcSrCpmZ2ZBISmFubirXbmFhitTUpxXul5aWCQsL+X3MzU1RUiJBZmY2LC1fXZ1xcbHHtGnD8fHHZcMB06ePgIuLPUaO/BKzZo3EuXPhWLNmF7S0tODvPxbNmyueTJC8rPjHOD3/W5QWF0NLV4yW08bBuI4NAKAwOwclBYWI/P0EGvbvAY9BvfHk5h1cXLkZbfynoHaD8v86t/f1QVF2DkIWLAcghVRSCqd326Bez64Kx2Xl1RD2rZrj73lLoKmtjWYThkNLrIPr2/ag2YThiD55BlEnTkPH0BBNxwyRVSapYnVr6eEjH3tsuRCHdeei0djOBPPfq4+iklK5ilxHt9pY3c8LetqaSMkpxEc/hiFTiQRuzrvuSM4pxPnodIX3OROVjkM3E3F4rC8KiiWYeegW8osk+KZ7Q8z87TY+8qmLEe/URWZeEeb+EYEHqblKnbvQ8fO85uBEjioWGRmJLl26ID4+HiKRCG3atMHu3bthY1P2izErKwsff/zxS5O+oKAgLFiwQK4tIGAy5s//tEpjVwWRSP4VJpVKIXrFi668fcprf5nBg7vJXSx84MBJGBjooUmT+njvvU+wb98KJCenYdq0Zfjrry3QUWKCAD1nZGuFToFzUZyXj8eXwxG24Qe0/XIajOvYyJ43m6ZecOvWCQBg6miP9AfRiDl1rsKkL/VOJO799ieafDwIZi6OePYkFTd//BV3TY+iwYfvKxxbw74foGHfD2SP7+z/A5Ye9aGhqYF7h47j3cX+SAq/jbD1O9Fx0dzX+CkIg0gkwq3ELCz76wEAICI5B261DfGRj71c0nchNgPvb7gAM31tDGpWB2v7NUbvLZeQnlf0ymOM93NETw8bDNpxGYWSUqXiWxkShZUhUbLHU9u54HxMOkokpfi0rTO6rj+PTu61saK3J3psvqhU31SGn+dvPyEkfWod3p0zZw48PT2RkpKC+/fvw9jYGK1atUJ8fLzCfcydOxdZWVlyy9y546sw6tdXq5YxNDU1kJaWKdeenp71wl9+/2ZhUQupqfL7ZGRkQUtLE6amRpWKJSMjC2vX7sG8eeNx40YkHB1t4ehoi5YtvVBSUoKYmMeV6pcADS0tGFpbopazAzwG9YZJXTs8/PNvAIDYyBAiTQ0Y29nI7WNsa428tPKv7wKAO/t+R93W78CpQyuY1LWDXfMmaDSgJyIP/wlpqXKJwD9yEpORcP4KGvb/AKl3HsCivivExkao06IpnsYmoDgvv1L9CklKTuELFbKotFzYmujKteUXSxCXmYfwx1mYczgCJaVSDGxq98r+x/o6YlIbZwz7MQz3Up69Vqwu5gbo5WmD5X89REtHM1yKy0RGXjH+iHgCT1sTGOrwon9l8POc3iZqTfpCQ0MRGBgICwsLuLq64vDhw+jWrRvatGmD6OhohfoQi8UwNjaWW97koV0A0NHRRqNGrjh/Xv4WCaGh1+Ht3aDC/Zo0qY/Q0OtybefOhcPDwxXa2pUr2gYGbsHIkb1gbW2B0tJSlJRIZOskEglKK5lIUPlK/3+tjoaWFmo5OyAn6Ync+pzklJdOopAUFr1QBRBpaEBayeuPpVIprm3ZBc+hfaGlqwuptBSlkrLXwD//l1a2cwG5mvAUzuYGcm1O5vp4nPXyhFkkEkFH8+Ufw+P8HPFpW2eM+Okqbv3/9i+vI7BHQyw6cR95xRJoaoig/f/yxj//11CiykT8PK9JNFW8vInUmvTl5+dDS0v+xb127Vr07NkT7dq1Q2RkpJoiq3off9wb+/YFY9++YERFJSAwcDOSklIxaNDzMv3y5Tsxe/YK2eNBg95DYmIKgoK2ICoqAfv2BWP//mCMGvVhpWI4fz4ccXGJGDq0OwDAy8sd0dGPEBIShr17j0NDQwNOTq+uQtCLbu/9DWn3HiI3NR1Z8Y8R8ctvSL0TKZt1CwBu3Tvj0cWriPnrHJ4lpyDqxGkkX7sF585tZduErd+B23sOyR5bN/VE9MmzSLgQVjaJ49Zd3Nn3B2yaekKkofzbOfbv8xAbG8G2WdlsY3N3F6RG3EfGgxg8PPYXjOxsoGOgX/kfhEBsvRgL7zommNjaCQ619NHTwwaDm9bBD1cSAJRNwJjV0Q3ediawM9FFI2sjLO7RCDbGYhy58/yeect7e2B2JzfZ4/F+jpjRwQ2zD0fg0dN81DbQQW0DHehrV+5XyuCmdZCeW4STkakAgLD4p/B1MoO3nQlG+zogMuUZsgsVm0RAz/HzvGbQEElVuryJ1HpNX/369REWFoYGDeT/Glq9ejWkUil69uyppsiq3vvvt0FmZjbWrduDlJQMuLs7YNOmANjZPb+nU2pqBpKSUmWP7e2tsWlTAIKCtuDnn4/A0tIM/v7jFJ7e/28FBYVYuHAjVq6cDY3/JwtWVuaYN28cvvhiFXR0tLFkyTTo6opf/2QFqDArG2Hrd6DgaTa09XVhbG+HVnMmw8rz+WvdrnkTeI8ajPuH/8SNH36FkY0VWkwZC4t6rrJt8tIzAdHzZK5+724QQYQ7v/6O/IynEBsbwsbbEw0HKP9eKcjKxv3fjqPd/JmyNjMXR7i9/y5Cv10HsbEhmk0o/3YTJO9mYjbG772O2Z3cMKWdCxIy87Hwz/v47VbZbVpKS6VwsTBA38ZNUEtfB0/zi3DzcTb6b78sNyxsZ6InV7Ud1rwuxFoa2DCgidzxVp5+KHeNniIsDHQwqY0z+my9JGu7kZiFLRfisG1IU6TnFmHGodsv6YEqws9zeluIpGocuwkKCsLZs2dx9OjRctdPnDgRGzZsqERJuuZWCOlFc8MS1B0CVaPdR1iJEpLYACd1h0DVSn33FVx8I1il/X3euLNK+1MFtQ7vzp07t8KEDwDWrVvHaxCIiIioymmIVLu8iXhzZiIiIiIBUPvNmYmIiIjUTfMNrc6pEpM+IiIiErw3dUhWlTi8S0RERCQArPQRERGR4L2p99ZTJSZ9REREJHgc3iUiIiKiGoGVPiIiIhK8N/X7clWJSR8REREJHod3iYiIiKhGYKWPiIiIBI+zd4mIiIgEQAjfyMHhXSIiIiIBYKWPiIiIBE8IEzmY9BEREZHgCSHp4/AuERERkQCw0kdERESCJ4RKH5M+IiIiEjxNAdyyhcO7RERERALASh8REREJnhCqYEz6iIiISPCEcE2fEBJbIiIiIsFjpY+IiIgETwiVPiZ9REREJHicvUtERERENQIrfURERCR4HN4lIiIiEgAhJH0c3iUiIiISAFb6iIiISPCEUOlj0kdERESCpymApI/Du0REREQCwEofERERCZ6GAO7Tx6SPiIiIBE8IQ59COEciIiIiwWOlj4iIiASPs3eJiIiIBICzd4mIiIioRmClj4iIiASPs3eJiIiIBEAI1/RxeJeIiIhIAFjpIyIiIsETQqWPSR+99fwsi9QdAlWjoAAXdYdA1chlyFV1h0DVKGqXu9qOLYShTyGcIxEREZHgsdJHREREgifi8C4RERFRzSeAnI/Du0RERERCwEofERERCR6Hd4mIiIgEQAhDn0I4RyIiIiLBY6WPiIiIBE/E794lIiIiqvkEcEkfh3eJiIiIhIBJHxEREQmeSKTaRVFBQUFo3rw5jIyMYGlpid69e+P+/fty20ilUsyfPx+2trbQ09ND+/btERERofQ5MukjIiIiUpOQkBBMmjQJFy9eRHBwMEpKStClSxfk5ubKtlm6dClWrFiBNWvW4MqVK7C2tkbnzp2Rk5Oj1LF4TR8REREJnrqu6Tt+/Ljc4+3bt8PS0hJXr15F27ZtIZVKsXLlSvj7+6NPnz4AgJ07d8LKygq7du3C+PHjFT4WK31EREQkeBoi1S6VlZWVBQAwMzMDAMTExCA5ORldunSRbSMWi9GuXTuEhoYq1TcrfUREREQqVlhYiMLCQrk2sVgMsVhc4T5SqRTTp09H69at4eHhAQBITk4GAFhZWclta2Vlhbi4OKViYqWPiIiIBE+k4iUoKAgmJiZyS1BQ0EtjmDx5Mm7evIndu3e/GN9/ZodIpdIX2l6FlT4iIiISPFV/9+7cuXMxffp0ubaXVfk+/fRTHD58GGfOnEGdOnVk7dbW1gDKKn42Njay9pSUlBeqf6/CSh8RERGRionFYhgbG8st5SV9UqkUkydPxoEDB/DXX3/ByclJbr2TkxOsra0RHBwsaysqKkJISAj8/PyUiomVPiIiIhI8dc3enTRpEnbt2oXffvsNRkZGsmv4TExMoKenB5FIhKlTpyIwMBBubm5wc3NDYGAg9PX1MWTIEKWOxaSPiIiIBE9dSd/69esBAO3bt5dr3759O0aOHAkAmD17NvLz8zFx4kRkZmaiRYsWOHHiBIyMjJQ6FpM+IiIiIjWRSqWv3EYkEmH+/PmYP3/+ax2LSR8REREJ3uvcW+9twaSPiIiIBE8AOR9n7xIREREJASt9REREJHgi0auvrXvbMekjIiIiwePwLhERERHVCKz0ERERkeCp+mvY3kRM+oiIiEjwhDD0KYRzJCIiIhI8VvqIiIhI8Di8S0RERCQAAsj5OLxLREREJASs9BEREZHgcXiXiIiISAAEkPNxeJeIiIhICFjpIyIiIsHTEECpj0kfERERCZ4Acj4O7xIREREJASt9REREJHgikVTdIVQ5Jn1EREQkeBzeJSIiIqIagZU+Nfr55yPYuvUAUlMz4eZWF198MRY+Po1eus/ly7ewePFWPHgQD0tLM4wZ0xeDB3dT6rhbtx7A1q0HAQDjxvXFyJG9Zetu3LiPBQvW49dfl0NTU1Ppc6Iyp3YH49a5m0hNSIGWWBuODR3RfUwPWNpbybaZ2Xlquft2H9sTHQZ0LHfdrbM3cGr3SaQlpkIiKUVtWwu069cBzTo3Vyq+wxsO4sqJKxDr6qD72J7w7tBUtu56SDiungzD6K/HKtUnyeP7u+YKWdUDdWobvtD+44lIzN9xFVqaIkzv74X2TWxhb2mInPwihN5+gqW7byDlaX6F/f78ZUe0bGj1Qvvf4Y8xZtkZheP74iNv9G3rhLyCEizZfR1/XIiXrXu/hT16t3HCuG8V708oeHNmqjJHj55FUNAWBARMQNOmDbFnz3GMHTsfR46sha2tZbn7JCQkY9y4BejfvyuWLZuBa9fuYMGCDTAzM0bXrq0UOu79+7H4/vufsWHDVwCA8eMXws/PG+7uDiguLkFAwDosXDiJvxBeU/TNKLTq2Rr29eqiVFKKY9uPYNPnGzBry+cQ64kBAF/tXSi3z73Ld/Hrij3wauNVYb96xvroNKQzLO0toamthbsXI7D3290wNDVEveYNFIot4sJthP91DeOCJiDtcSr2frsb7s3qwcDYAPnP8nB82xGMXzap8idPfH/XcB9+eQIa/7q/h7u9CX78oiOOXUoAAOjqaKGRkxnWHLyNu/FPYWKggy+HNcWmmW3Q+8sTFfY78btz0NZ6PgBXy1AHfyzuJutXER2b2qKnnwNGBp2Go7URloxvgXO3kvH0WRGM9LUxY2BjfLTor0qcdc0ngJyPw7vqsn37IfTt2xn9+3eFi4s9/P3HwtraArt3H6twnz17jsPGpjb8/cfCxcUe/ft3RZ8+72LbtoMKHzcqKgH16jnB17cxfH0bo149R0RFlX2gbN16AD4+jeDl5f7a5yd0Y4MmoHnXFrB2tIGtix0GzhyCpymZePTgkWwbYzNjuSXiwi24NHaFuY1Fhf26NnaDZ2svWDlYw8LWAm36tIONsy1iImIUji0l/glcGrvCvl5deHdsBl19MdKT0gEAf2z+HX49W6OWZa3Knzzx/V3DZeQUIi2rQLZ09LZDXHIOLt1NAQA8yy/GiKC/cfRSAmKScnD9YToW7LwKT2dz2JjrV9hvVm6RXL+tPG2QXyjB0UvxFe7zX662Jrh0NwW3YjLw+4U4PMsvgb1lWVXy8yFN8FPwAySl573eD4DeWkz61KCoqBgREQ/RurW3XHurVt4ID79b4X7Xr99Dq1by+7Rp0xS3bz9EcXGJQseuV88RsbGPkZiYgsePUxAb+xju7g6Ii0vEwYOnMHXqR8qfEL1SQW7ZkI6+Ufkf+DmZObh76Q7e6dZS4T6lUikeXItEyqMUOHu6KLyfrbMtEiITkJeTh0eRCSguKoaFrQVibkfj8YNHaN27rcJ90Yv4/hYWbU0N9GrtiF9Dol+6nZG+NkpLpcjJK1K47wHtnXHkYhzyCyUK73M3PhOeTmYwNtCGh1MtiLU1EfckB83qWaCRYy3sPB6pcF9Co6Hi5U2k9uHdu3fv4uLFi/D19UX9+vVx7949rFq1CoWFhfjoo4/QsWP51za9zTIzsyGRlMLc3FSu3cLCFKmpTyvcLy0tExYW8vuYm5uipESCzMxsWFqavfLYLi72mDZtOD7+uGz4Z/r0EXBxscfIkV9i1qyROHcuHGvW7IKWlhb8/ceieXMPZU+P/kMqleLwhkNw8nCGjZNNuduEnbgMsb4uPFtXPLT7j/zcfHw9KAAlxSXQ0NBAn8/6wb1ZPYXjqde8AZp2aoZVk1dAW0cbg2YNhY6uDvav+hWDZg1B6O/ncf63MzAwNkS/aQNg7Vh+zFQ+vr+FpbOPHYz1tbE/pOJqu462BmYPaozDoWWVN0V4uZihXl1TfL75klLxnL2ZjEPnY3Ho664oKJJg9oaLyC+Q4OuPm2P2xosY2tkVw7u4IzOnEP5bLuPB42yl+q/JeE1fFTt+/Dh69eoFQ0ND5OXl4eDBgxg+fDgaN24MqVSKrl274s8//3xp4ldYWIjCwkK5NrG4CGKxTlWH/9pE/3mFSaXSV77oytunvPaXGTy4m9zF4QcOnISBgR6aNKmP9977BPv2rUBychqmTVuGv/7aAh0dbYX7phcdXL0fSTGJmPTdlAq3ufznJTTt2AzaCvysxXpiTN8wC4X5hXgQ/gCHNxyCmY05XBu7KRxT1+Hd0HX489fAnz8cg1tTd2hoaeLUrhOYsWkO7lyMwO6lP2PaupkK90vP8f0tDP07uCDkRlKFEzS0NEX4/tNWEIlECNh+ReF+B7R3wf34p7gZlaF0TN/vv43v99+WPf6srwfO305GcYkUk3o3wvtzjqFDU1t8O9EXvfz/VLp/enuptQK5cOFCzJo1C+np6di+fTuGDBmCsWPHIjg4GCdPnsTs2bOxePHil/YRFBQEExMTuSUoaGM1nUHl1KplDE1NDaSlZcq1p6dnvfCX/r9ZWNRCaqr8PhkZWdDS0oSpqVGlYsnIyMLatXswb9543LgRCUdHWzg62qJlSy+UlJQgJuZxpfqlMgfX7EfExduYsGwyTGublrtN9K0opCakoIWCQ7saGhqwsKsNO9c6aN+/A7zaNMFfu09WOsaU+CcIP3UV7418H1E3HsDJ0wWGpoZo3K4JHj94hILcgkr3LUR8fwuHrYU+WnlY4Ze/o8pdr6UpwurPWqFObQOMCPpb4Sqfro4mPvCti19Ol9+vMpxtjdCrlSO++/UWWja0xOV7qcjIKcTRi/HwcDKDoZ7aB/zeICIVL28etSZ9ERERGDlyJABgwIAByMnJQd++fWXrBw8ejJs3b760j7lz5yIrK0tumTt3fFWG/dp0dLTRqJErzp8Pl2sPDb0Ob++KZ2A2aVIfoaHX5drOnQuHh4crtLUr98YNDNyCkSN7wdraAqWlpSgpeX7tiEQiQWlpaaX6FTqpVIoDq/fh1rmbmLB0EsxtzCvc9vKxi6jjZg9bF7vKHg0lCl7zVV6cv67cix7je0OsJ4a0VIpSSdlr4J//S6V8DSiD72/h6NfOGelZhfg7PPGFdf8kfI7WRhge+DeePlP8Wr7uLetCR0sTh87FvnaMi0a/g8CfwpFXWAINDRG0NUX/j6/s178yVeSaTqTi/95Eb8y1hhoaGtDV1YWpqamszcjICFlZWS/dTywWw9jYWG55G4Z2P/64N/btC8a+fcGIikpAYOBmJCWlYtCg58Myy5fvxOzZK2SPBw16D4mJKQgK2oKoqATs2xeM/fuDMWrUh5WK4fz5cMTFJWLo0O4AAC8vd0RHP0JISBj27j0ODQ0NODlVNhERtgOr9+HaqTAMnTsMYn0xsjOykZ2RjeJC+Q/+gtwC3Dh7o8IJHLuX/ISjW3+XPT61OxiRV+8jPSkNKfFPELLvb4QFX0GzTj6VivPS0QswNDVCI7+ya7scGznhYfgDxN2JxZn9IbBysIaeYcWzDal8fH/XfCIR0K+tMw6cjYGkVP7ruzQ1RFgzpTU8nc0wbe0FaGiIYGGiCwsTXWhrPv+1++0nLTFzYOMX+u7f3hnBVx8plSiWZ1BHF6RnF+DUtbKK7tXIVPg2skITV3OM6lYPkY+ykJNX/FrHoLeLWuu6jo6OePjwIVxdXQEAFy5cQN26dWXrExISYGNTMy8if//9NsjMzMa6dXuQkpIBd3cHbNoUADu75/fwSk3NQFJSquyxvb01Nm0KQFDQFvz88xFYWprB33+cwvfw+reCgkIsXLgRK1fOhoZG2YeQlZU55s0bhy++WAUdHW0sWTINurri1z9ZAbrw+3kAwPqZa+TaB84cjOZdW8geXz99DZBK4d2xKcqTmZIp95d4UUERDnz/K56mZUFbrA1Le0sM+fwjNGlf/v4vk5OZg1O7gzF55VRZW936Dmjbrz22frkJhqaGGDR7qNL9Et/fQtDKwxp2tQ3w6+kXZ+1am+mjs08dAMCRxfI31x7y9SnZrV1szPVR+p+E0dHaCM3rW2J44N+vFZ+5sS4+6dUQ/QOeX/pxMyoDW47cw5ZZ7ZCeXYBZGy6+1jFqGpHojamDVRmR9J8rhdVgw4YNsLe3R/fu3ctd7+/vjydPnmDLli1K9swp6ULye/zrX/dCb48edRW/PQ29/VyGXFV3CFSNonYNVtuxnxZVfB/NyjDVUe7bdKqDWit9EyZMeOn6RYsWVVMkRERERDUbp+0QERGR4L2pky9UiUkfERERkQCSvpp/1SIRERERsdJHREREJITZu0z6iIiIiDi8S0REREQ1ASt9REREJHicvUtEREQkAEJI+ji8S0RERCQArPQRERERCaAOxqSPiIiIBE8k4vAuEREREdUArPQRERERCWAiB5M+IiIiEjzO3iUiIiKiGoGVPiIiIiIB1MGY9BEREZHgcXiXiIiIiGoEVvqIiIhI8IRwnz4mfUREREQc3iUiIiKimoCVPiIiIhI8kQDqYEz6iIiIiDi8S0REREQ1ASt9REREJHicvUtEREQkCDU/6ePwLhEREZEAsNJHREREgsfZu0RERESCwOFdIiIiIqoBWOkjIiIiwRMJoNLHpI+IiIgETwi3bOHwLhEREZEAsNJHREREJIA6GJM+IiIiEjwhXNNX89NaIiIiImKlj4iIiIj36SMiIiISAJFIpNJFWevWrYOTkxN0dXXRrFkznD17VuXnyKSPiIiISI327t2LqVOnwt/fH+Hh4WjTpg26deuG+Ph4lR6HSR8RERERNFS8KG7FihUYPXo0xowZgwYNGmDlypWwt7fH+vXrVXFiMkz6iIiISPBEKv5PUUVFRbh69Sq6dOki196lSxeEhoaq9Bw5kYOIiIhIxQoLC1FYWCjXJhaLIRaL5drS0tIgkUhgZWUl125lZYXk5GSVxlRDkz53dQdQ7QoLCxEUFIS5c+e+8IKq6XrU5fNNNZuQn++oXXx/U3VR7WstKGg+FixYINcWEBCA+fPnl7v9fyd/SKVSlX81nEgqlUpV2iOpRXZ2NkxMTJCVlQVjY2N1h0NVjM+3sPD5FhY+3zWDopW+oqIi6Ovr49dff8WHH34oa58yZQquX7+OkJAQlcXEa/qIiIiIVEwsFsPY2FhuKa9yq6Ojg2bNmiE4OFiuPTg4GH5+fiqNqYYO7xIRERG9HaZPn45hw4bBx8cHvr6+2LRpE+Lj4zFhwgSVHodJHxEREZEaDRw4EOnp6Vi4cCGSkpLg4eGBo0ePwsHBQaXHYdJXQ4jFYgQEBPCiX4Hg8y0sfL6Fhc+3ME2cOBETJ06s0mNwIgcRERGRAHAiBxEREZEAMOkjIiIiEgAmfUREREQCwKSPiIiISACY9NUQ69atg5OTE3R1ddGsWTOcPXtW3SFRFThz5gx69OgBW1tbiEQiHDp0SN0hURUKCgpC8+bNYWRkBEtLS/Tu3Rv3799Xd1hURdavXw8vLy/ZjXx9fX1x7NgxdYdFNQiTvhpg7969mDp1Kvz9/REeHo42bdqgW7duiI+PV3dopGK5ublo3Lgx1qxZo+5QqBqEhIRg0qRJuHjxIoKDg1FSUoIuXbogNzdX3aFRFahTpw4WL16MsLAwhIWFoWPHjujVqxciIiLUHRrVELxlSw3QokULNG3aFOvXr5e1NWjQAL1790ZQUJAaI6OqJBKJcPDgQfTu3VvdoVA1SU1NhaWlJUJCQtC2bVt1h0PVwMzMDMuWLcPo0aPVHQrVAKz0veWKiopw9epVdOnSRa69S5cuCA0NVVNURFQVsrKyAJQlAlSzSSQS7NmzB7m5ufD19VV3OFRD8Bs53nJpaWmQSCSwsrKSa7eyskJycrKaoiIiVZNKpZg+fTpat24NDw8PdYdDVeTWrVvw9fVFQUEBDA0NcfDgQTRs2FDdYVENwaSvhhCJRHKPpVLpC21E9PaaPHkybt68iXPnzqk7FKpC9erVw/Xr1/H06VPs378fI0aMQEhICBM/UgkmfW85CwsLaGpqvlDVS0lJeaH6R0Rvp08//RSHDx/GmTNnUKdOHXWHQ1VIR0cHrq6uAAAfHx9cuXIFq1atwsaNG9UcGdUEvKbvLaejo4NmzZohODhYrj04OBh+fn5qioqIVEEqlWLy5Mk4cOAA/vrrLzg5Oak7JKpmUqkUhYWF6g6DaghW+mqA6dOnY9iwYfDx8YGvry82bdqE+Ph4TJgwQd2hkYo9e/YMDx8+lD2OiYnB9evXYWZmhrp166oxMqoKkyZNwq5du/Dbb7/ByMhIVtE3MTGBnp6emqMjVfviiy/QrVs32NvbIycnB3v27MHp06dx/PhxdYdGNQRv2VJDrFu3DkuXLkVSUhI8PDzw3Xff8ZYONdDp06fRoUOHF9pHjBiBHTt2VH9AVKUqui53+/btGDlyZPUGQ1Vu9OjROHXqFJKSkmBiYgIvLy/MmTMHnTt3VndoVEMw6SMiIiISAF7TR0RERCQATPqIiIiIBIBJHxEREZEAMOkjIiIiEgAmfUREREQCwKSPiIiISACY9BEREREJAJM+InpjzZ8/H02aNJE9HjlyJHr37l3tccTGxkIkEuH69evVfmwiIlVh0kdEShs5ciREIhFEIhG0tbXh7OyMmTNnIjc3t0qPu2rVKoW/eYSJGhGRPH73LhFVynvvvYft27ejuLgYZ8+exZgxY5Cbm4v169fLbVdcXAxtbW2VHNPExEQl/RARCRErfURUKWKxGNbW1rC3t8eQIUMwdOhQHDp0SDYku23bNjg7O0MsFkMqlSIrKwvjxo2DpaUljI2N0bFjR9y4cUOuz8WLF8PKygpGRkYYPXo0CgoK5Nb/d3i3tLQUS5YsgaurK8RiMerWrYtFixYBAJycnAAA3t7eEIlEaN++vWy/7du3o0GDBtDV1UX9+vWxbt06ueNcvnwZ3t7e0NXVhY+PD8LDw1X4kyMiUg9W+ohIJfT09FBcXAwAePjwIX755Rfs378fmpqaAIDu3bvDzMwMR48ehYmJCTZu3IhOnTohMjISZmZm+OWXXxAQEIC1a9eiTZs2+PHHH/H999/D2dm5wmPOnTsXmzdvxnfffYfWrVsjKSkJ9+7dA1CWuL3zzjs4efIkGjVqBB0dHQDA5s2bERAQgDVr1sDb2xvh4eEYO3YsDAwMMGLECOTm5uKDDz5Ax44d8dNPPyEmJgZTpkyp4p8eEVE1kBIRKWnEiBHSXr16yR5funRJam5uLh0wYIA0ICBAqq2tLU1JSZGtP3XqlNTY2FhaUFAg14+Li4t048aNUqlUKvX19ZVOmDBBbn2LFi2kjRs3Lve42dnZUrFYLN28eXO5McbExEgBSMPDw+Xa7e3tpbt27ZJr+/rrr6W+vr5SqVQq3bhxo9TMzEyam5srW79+/fpy+yIieptweJeIKuWPP/6AoaEhdHV14evri7Zt22L16tUAAAcHB9SuXVu27dWrV/Hs2TOYm5vD0NBQtsTExCAqKgoAcPfuXfj6+sod47+P/+3u3bsoLCxEp06dFI45NTUVCQkJGD16tFwc33zzjVwcjRs3hr6+vkJxEBG9LTi8S0SV0qFDB6xfvx7a2tqwtbWVm6xhYGAgt21paSlsbGxw+vTpF/oxNTWt1PH19PSU3qe0tBRA2RBvixYt5Nb9MwwtlUorFQ8R0ZuOSR8RVYqBgQFcXV0V2rZp06ZITk6GlpYWHB0dy92mQYMGuHjxIoYPHy5ru3jxYoV9urm5QU9PD6dOncKYMWNeWP/PNXwSiUTWZmVlBTs7O0RHR2Po0KHl9tuwYUP8+OOPyM/PlyWWL4uDiOhtweFdIqpy7777Lnx9fdG7d2/8+eefiI2NRWhoKL788kuEhYUBAKZMmYJt27Zh27ZtiIyMREBAACIiIirsU1dXF3PmzMHs2bPxww8/ICoqChcvXsTWrVsBAJaWltDT08Px48fx5MkTZGVlASi74XNQUBBWrVqFyMhI3Lp1C9u3b8eKFSsAAEOGDIGGhgZGjx6NO3fu4OjRo/j222+r+CdERFT1mPQRUZUTiUQ4evQo2rZti1GjRsHd3R2DBg1CbGwsrKysAAADBw7EV199hTlz5qBZs2aIi4vDJ5988tJ+582bhxkzZuCrr75CgwYNMHDgQKSkpAAAtLS08P3332Pjxo2wtbVFr169AABjxozBli1bsGPHDnh6eqJdu3bYsWOH7BYvhoaG+P3333Hnzh14e3vD398fS5YsqcKfDhFR9RBJeQELERERUY3HSh8RERGRADDpIyIiIhIAJn1EREREAsCkj4iIiEgAmPQRERERCQCTPiIiIiIBYNJHREREJABM+oiIiIgEgEkfERERkQAw6SMiIiISACZ9RERERALApI+IiIhIAP4HkHOPnKyPuiQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "\n",
    "cm_percent = cm / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "plt.figure(figsize=(8, 5))\n",
    "sn.heatmap(cm_percent, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "\n",
    "ax = plt.gca()\n",
    "for t in ax.texts:\n",
    "    t.set_text(t.get_text() + \"  %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.74        24\n",
      "           1       0.61      0.95      0.75        20\n",
      "           2       0.63      0.63      0.63        19\n",
      "           3       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.72        74\n",
      "   macro avg       0.76      0.72      0.72        74\n",
      "weighted avg       0.77      0.72      0.72        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "Deep Learning Models\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "Basic ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model --- Needs to understand this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44804 (175.02 KB)\n",
      "Trainable params: 44804 (175.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1900 - accuracy: 0.5000\n",
      "Epoch 1: val_loss improved from inf to 1.12183, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.2127 - accuracy: 0.4020 - val_loss: 1.1218 - val_accuracy: 0.4595\n",
      "Epoch 2/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2482 - accuracy: 0.3750\n",
      "Epoch 2: val_loss improved from 1.12183 to 1.10178, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2308 - accuracy: 0.4054 - val_loss: 1.1018 - val_accuracy: 0.4730\n",
      "Epoch 3/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1448 - accuracy: 0.4688\n",
      "Epoch 3: val_loss improved from 1.10178 to 1.09434, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2439 - accuracy: 0.4155 - val_loss: 1.0943 - val_accuracy: 0.4865\n",
      "Epoch 4/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1486 - accuracy: 0.3750\n",
      "Epoch 4: val_loss improved from 1.09434 to 1.09274, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2245 - accuracy: 0.3851 - val_loss: 1.0927 - val_accuracy: 0.4189\n",
      "Epoch 5/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0886 - accuracy: 0.5000\n",
      "Epoch 5: val_loss did not improve from 1.09274\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1978 - accuracy: 0.3953 - val_loss: 1.1075 - val_accuracy: 0.4730\n",
      "Epoch 6/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2419 - accuracy: 0.3750\n",
      "Epoch 6: val_loss did not improve from 1.09274\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2465 - accuracy: 0.4020 - val_loss: 1.1162 - val_accuracy: 0.4459\n",
      "Epoch 7/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1121 - accuracy: 0.3750\n",
      "Epoch 7: val_loss did not improve from 1.09274\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2555 - accuracy: 0.3919 - val_loss: 1.1075 - val_accuracy: 0.4324\n",
      "Epoch 8/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1765 - accuracy: 0.4375\n",
      "Epoch 8: val_loss did not improve from 1.09274\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2278 - accuracy: 0.3784 - val_loss: 1.0929 - val_accuracy: 0.4459\n",
      "Epoch 9/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2018 - accuracy: 0.4375\n",
      "Epoch 9: val_loss improved from 1.09274 to 1.08952, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2558 - accuracy: 0.3919 - val_loss: 1.0895 - val_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3762 - accuracy: 0.3438\n",
      "Epoch 10: val_loss improved from 1.08952 to 1.07925, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.2086 - accuracy: 0.3953 - val_loss: 1.0792 - val_accuracy: 0.5135\n",
      "Epoch 11/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2960 - accuracy: 0.4688\n",
      "Epoch 11: val_loss did not improve from 1.07925\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2307 - accuracy: 0.4223 - val_loss: 1.0854 - val_accuracy: 0.4324\n",
      "Epoch 12/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1997 - accuracy: 0.4375\n",
      "Epoch 12: val_loss did not improve from 1.07925\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2458 - accuracy: 0.3885 - val_loss: 1.1118 - val_accuracy: 0.4324\n",
      "Epoch 13/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0949 - accuracy: 0.5312\n",
      "Epoch 13: val_loss did not improve from 1.07925\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2377 - accuracy: 0.4088 - val_loss: 1.1025 - val_accuracy: 0.3919\n",
      "Epoch 14/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2756 - accuracy: 0.3438\n",
      "Epoch 14: val_loss did not improve from 1.07925\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2147 - accuracy: 0.4561 - val_loss: 1.0966 - val_accuracy: 0.4324\n",
      "Epoch 15/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1753 - accuracy: 0.4062\n",
      "Epoch 15: val_loss improved from 1.07925 to 1.05475, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.1914 - accuracy: 0.4088 - val_loss: 1.0548 - val_accuracy: 0.5135\n",
      "Epoch 16/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2469 - accuracy: 0.2188\n",
      "Epoch 16: val_loss improved from 1.05475 to 1.02286, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1355 - accuracy: 0.4628 - val_loss: 1.0229 - val_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0750 - accuracy: 0.6250\n",
      "Epoch 17: val_loss improved from 1.02286 to 1.01668, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1450 - accuracy: 0.4392 - val_loss: 1.0167 - val_accuracy: 0.5135\n",
      "Epoch 18/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4161 - accuracy: 0.2500\n",
      "Epoch 18: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1913 - accuracy: 0.4527 - val_loss: 1.0457 - val_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1243 - accuracy: 0.4062\n",
      "Epoch 19: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2075 - accuracy: 0.3986 - val_loss: 1.0843 - val_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2686 - accuracy: 0.4375\n",
      "Epoch 20: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2393 - accuracy: 0.3649 - val_loss: 1.0843 - val_accuracy: 0.4730\n",
      "Epoch 21/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0466 - accuracy: 0.5000\n",
      "Epoch 21: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2031 - accuracy: 0.4392 - val_loss: 1.0945 - val_accuracy: 0.5405\n",
      "Epoch 22/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1770 - accuracy: 0.3750\n",
      "Epoch 22: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1737 - accuracy: 0.4392 - val_loss: 1.0687 - val_accuracy: 0.5135\n",
      "Epoch 23/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1578 - accuracy: 0.4062\n",
      "Epoch 23: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1651 - accuracy: 0.4527 - val_loss: 1.0399 - val_accuracy: 0.5270\n",
      "Epoch 24/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2690 - accuracy: 0.2812\n",
      "Epoch 24: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1699 - accuracy: 0.4324 - val_loss: 1.0557 - val_accuracy: 0.4730\n",
      "Epoch 25/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0131 - accuracy: 0.6562\n",
      "Epoch 25: val_loss did not improve from 1.01668\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1307 - accuracy: 0.4662 - val_loss: 1.0253 - val_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2697 - accuracy: 0.4688\n",
      "Epoch 26: val_loss improved from 1.01668 to 1.01619, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.1042 - accuracy: 0.4324 - val_loss: 1.0162 - val_accuracy: 0.4730\n",
      "Epoch 27/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2279 - accuracy: 0.2812\n",
      "Epoch 27: val_loss did not improve from 1.01619\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1605 - accuracy: 0.4358 - val_loss: 1.0164 - val_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1036 - accuracy: 0.4688\n",
      "Epoch 28: val_loss did not improve from 1.01619\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.4797 - val_loss: 1.0274 - val_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2389 - accuracy: 0.5000\n",
      "Epoch 29: val_loss did not improve from 1.01619\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1529 - accuracy: 0.4797 - val_loss: 1.0279 - val_accuracy: 0.5270\n",
      "Epoch 30/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0428 - accuracy: 0.4688\n",
      "Epoch 30: val_loss did not improve from 1.01619\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1394 - accuracy: 0.4595 - val_loss: 1.0208 - val_accuracy: 0.4730\n",
      "Epoch 31/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0004 - accuracy: 0.5625\n",
      "Epoch 31: val_loss improved from 1.01619 to 0.99742, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1528 - accuracy: 0.4257 - val_loss: 0.9974 - val_accuracy: 0.5135\n",
      "Epoch 32/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1172 - accuracy: 0.4688\n",
      "Epoch 32: val_loss did not improve from 0.99742\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1820 - accuracy: 0.4324 - val_loss: 0.9981 - val_accuracy: 0.5270\n",
      "Epoch 33/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2181 - accuracy: 0.4688\n",
      "Epoch 33: val_loss did not improve from 0.99742\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1527 - accuracy: 0.4426 - val_loss: 1.0280 - val_accuracy: 0.5135\n",
      "Epoch 34/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2174 - accuracy: 0.5000\n",
      "Epoch 34: val_loss did not improve from 0.99742\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1558 - accuracy: 0.4662 - val_loss: 1.0300 - val_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0437 - accuracy: 0.3750\n",
      "Epoch 35: val_loss did not improve from 0.99742\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0705 - accuracy: 0.4865 - val_loss: 1.0599 - val_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1182 - accuracy: 0.3750\n",
      "Epoch 36: val_loss improved from 0.99742 to 0.98273, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.1538 - accuracy: 0.4831 - val_loss: 0.9827 - val_accuracy: 0.5135\n",
      "Epoch 37/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1562 - accuracy: 0.4062\n",
      "Epoch 37: val_loss improved from 0.98273 to 0.97263, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0574 - accuracy: 0.4831 - val_loss: 0.9726 - val_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0630 - accuracy: 0.5625\n",
      "Epoch 38: val_loss improved from 0.97263 to 0.96819, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0875 - accuracy: 0.5203 - val_loss: 0.9682 - val_accuracy: 0.5541\n",
      "Epoch 39/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0574 - accuracy: 0.4062\n",
      "Epoch 39: val_loss improved from 0.96819 to 0.96078, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1263 - accuracy: 0.4899 - val_loss: 0.9608 - val_accuracy: 0.5676\n",
      "Epoch 40/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2042 - accuracy: 0.3750\n",
      "Epoch 40: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1185 - accuracy: 0.4291 - val_loss: 0.9963 - val_accuracy: 0.5135\n",
      "Epoch 41/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0991 - accuracy: 0.3125\n",
      "Epoch 41: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1280 - accuracy: 0.4527 - val_loss: 0.9909 - val_accuracy: 0.5270\n",
      "Epoch 42/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1744 - accuracy: 0.3750\n",
      "Epoch 42: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1125 - accuracy: 0.4527 - val_loss: 0.9887 - val_accuracy: 0.4865\n",
      "Epoch 43/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2070 - accuracy: 0.4375\n",
      "Epoch 43: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0863 - accuracy: 0.5135 - val_loss: 0.9900 - val_accuracy: 0.5135\n",
      "Epoch 44/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2234 - accuracy: 0.3750\n",
      "Epoch 44: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.5203 - val_loss: 0.9883 - val_accuracy: 0.5135\n",
      "Epoch 45/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1672 - accuracy: 0.4375\n",
      "Epoch 45: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0513 - accuracy: 0.5101 - val_loss: 0.9920 - val_accuracy: 0.5135\n",
      "Epoch 46/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1317 - accuracy: 0.5312\n",
      "Epoch 46: val_loss did not improve from 0.96078\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0243 - accuracy: 0.5034 - val_loss: 1.0133 - val_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0775 - accuracy: 0.6562\n",
      "Epoch 47: val_loss improved from 0.96078 to 0.94183, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0786 - accuracy: 0.4865 - val_loss: 0.9418 - val_accuracy: 0.5541\n",
      "Epoch 48/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9517 - accuracy: 0.5000\n",
      "Epoch 48: val_loss did not improve from 0.94183\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0663 - accuracy: 0.4764 - val_loss: 0.9603 - val_accuracy: 0.5270\n",
      "Epoch 49/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0079 - accuracy: 0.5625\n",
      "Epoch 49: val_loss did not improve from 0.94183\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1185 - accuracy: 0.4831 - val_loss: 0.9664 - val_accuracy: 0.5676\n",
      "Epoch 50/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0262 - accuracy: 0.4375\n",
      "Epoch 50: val_loss did not improve from 0.94183\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0590 - accuracy: 0.4932 - val_loss: 0.9521 - val_accuracy: 0.5270\n",
      "Epoch 51/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9215 - accuracy: 0.5000\n",
      "Epoch 51: val_loss did not improve from 0.94183\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1072 - accuracy: 0.4865 - val_loss: 0.9707 - val_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1193 - accuracy: 0.4688\n",
      "Epoch 52: val_loss did not improve from 0.94183\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0736 - accuracy: 0.5135 - val_loss: 0.9980 - val_accuracy: 0.5135\n",
      "Epoch 53/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9701 - accuracy: 0.6250\n",
      "Epoch 53: val_loss improved from 0.94183 to 0.91698, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0768 - accuracy: 0.5169 - val_loss: 0.9170 - val_accuracy: 0.5405\n",
      "Epoch 54/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2340 - accuracy: 0.5000\n",
      "Epoch 54: val_loss did not improve from 0.91698\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0646 - accuracy: 0.4764 - val_loss: 0.9296 - val_accuracy: 0.4730\n",
      "Epoch 55/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0028 - accuracy: 0.5938\n",
      "Epoch 55: val_loss did not improve from 0.91698\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0519 - accuracy: 0.5068 - val_loss: 0.9193 - val_accuracy: 0.5270\n",
      "Epoch 56/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0117 - accuracy: 0.6250\n",
      "Epoch 56: val_loss improved from 0.91698 to 0.91479, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0757 - accuracy: 0.5101 - val_loss: 0.9148 - val_accuracy: 0.5541\n",
      "Epoch 57/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9832 - accuracy: 0.4688\n",
      "Epoch 57: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0400 - accuracy: 0.5169 - val_loss: 0.9635 - val_accuracy: 0.5811\n",
      "Epoch 58/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1119 - accuracy: 0.4062\n",
      "Epoch 58: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0477 - accuracy: 0.4764 - val_loss: 0.9579 - val_accuracy: 0.5676\n",
      "Epoch 59/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0378 - accuracy: 0.5000\n",
      "Epoch 59: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0202 - accuracy: 0.5270 - val_loss: 0.9451 - val_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8880 - accuracy: 0.5312\n",
      "Epoch 60: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9972 - accuracy: 0.5169 - val_loss: 0.9339 - val_accuracy: 0.5405\n",
      "Epoch 61/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8074 - accuracy: 0.5938\n",
      "Epoch 61: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0005 - accuracy: 0.5169 - val_loss: 0.9165 - val_accuracy: 0.5676\n",
      "Epoch 62/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0976 - accuracy: 0.4688\n",
      "Epoch 62: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0247 - accuracy: 0.5338 - val_loss: 0.9746 - val_accuracy: 0.5270\n",
      "Epoch 63/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9851 - accuracy: 0.4688\n",
      "Epoch 63: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0023 - accuracy: 0.5000 - val_loss: 0.9327 - val_accuracy: 0.5405\n",
      "Epoch 64/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8975 - accuracy: 0.6875\n",
      "Epoch 64: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0415 - accuracy: 0.5203 - val_loss: 0.9326 - val_accuracy: 0.5541\n",
      "Epoch 65/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8886 - accuracy: 0.5625\n",
      "Epoch 65: val_loss did not improve from 0.91479\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0454 - accuracy: 0.4966 - val_loss: 0.9251 - val_accuracy: 0.5676\n",
      "Epoch 66/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9825 - accuracy: 0.4688\n",
      "Epoch 66: val_loss improved from 0.91479 to 0.90688, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9958 - accuracy: 0.5372 - val_loss: 0.9069 - val_accuracy: 0.5405\n",
      "Epoch 67/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9358 - accuracy: 0.5000\n",
      "Epoch 67: val_loss improved from 0.90688 to 0.90003, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9913 - accuracy: 0.5372 - val_loss: 0.9000 - val_accuracy: 0.5405\n",
      "Epoch 68/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8453 - accuracy: 0.6562\n",
      "Epoch 68: val_loss improved from 0.90003 to 0.89501, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9945 - accuracy: 0.5304 - val_loss: 0.8950 - val_accuracy: 0.5135\n",
      "Epoch 69/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0277 - accuracy: 0.5000\n",
      "Epoch 69: val_loss improved from 0.89501 to 0.88398, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9774 - accuracy: 0.5270 - val_loss: 0.8840 - val_accuracy: 0.5270\n",
      "Epoch 70/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9056 - accuracy: 0.5625\n",
      "Epoch 70: val_loss did not improve from 0.88398\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0196 - accuracy: 0.4797 - val_loss: 0.9358 - val_accuracy: 0.5270\n",
      "Epoch 71/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9507 - accuracy: 0.4375\n",
      "Epoch 71: val_loss did not improve from 0.88398\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9861 - accuracy: 0.5439 - val_loss: 0.9138 - val_accuracy: 0.5541\n",
      "Epoch 72/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8849 - accuracy: 0.6250\n",
      "Epoch 72: val_loss did not improve from 0.88398\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9709 - accuracy: 0.5270 - val_loss: 0.9212 - val_accuracy: 0.5405\n",
      "Epoch 73/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0336 - accuracy: 0.5312\n",
      "Epoch 73: val_loss did not improve from 0.88398\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0367 - accuracy: 0.4966 - val_loss: 0.9206 - val_accuracy: 0.5405\n",
      "Epoch 74/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1163 - accuracy: 0.5625\n",
      "Epoch 74: val_loss did not improve from 0.88398\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9891 - accuracy: 0.5743 - val_loss: 0.8936 - val_accuracy: 0.5405\n",
      "Epoch 75/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9539 - accuracy: 0.5625\n",
      "Epoch 75: val_loss improved from 0.88398 to 0.87644, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9606 - accuracy: 0.5304 - val_loss: 0.8764 - val_accuracy: 0.5405\n",
      "Epoch 76/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9045 - accuracy: 0.5938\n",
      "Epoch 76: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0105 - accuracy: 0.5473 - val_loss: 0.8766 - val_accuracy: 0.5405\n",
      "Epoch 77/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.5938\n",
      "Epoch 77: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9601 - accuracy: 0.5270 - val_loss: 0.8989 - val_accuracy: 0.5270\n",
      "Epoch 78/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8252 - accuracy: 0.5312\n",
      "Epoch 78: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9153 - accuracy: 0.5541 - val_loss: 0.8982 - val_accuracy: 0.5541\n",
      "Epoch 79/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9866 - accuracy: 0.5312\n",
      "Epoch 79: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0049 - accuracy: 0.5270 - val_loss: 0.9045 - val_accuracy: 0.5405\n",
      "Epoch 80/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9221 - accuracy: 0.6875\n",
      "Epoch 80: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9137 - accuracy: 0.5743 - val_loss: 0.9098 - val_accuracy: 0.5270\n",
      "Epoch 81/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1244 - accuracy: 0.4375\n",
      "Epoch 81: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0276 - accuracy: 0.5135 - val_loss: 0.9097 - val_accuracy: 0.5405\n",
      "Epoch 82/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9899 - accuracy: 0.5625\n",
      "Epoch 82: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9462 - accuracy: 0.5709 - val_loss: 0.9102 - val_accuracy: 0.5270\n",
      "Epoch 83/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0132 - accuracy: 0.4688\n",
      "Epoch 83: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9680 - accuracy: 0.5473 - val_loss: 0.9581 - val_accuracy: 0.5405\n",
      "Epoch 84/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7081 - accuracy: 0.7188\n",
      "Epoch 84: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9416 - accuracy: 0.5743 - val_loss: 0.9192 - val_accuracy: 0.5270\n",
      "Epoch 85/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9016 - accuracy: 0.6250\n",
      "Epoch 85: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9700 - accuracy: 0.5811 - val_loss: 0.8911 - val_accuracy: 0.5405\n",
      "Epoch 86/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9135 - accuracy: 0.5312\n",
      "Epoch 86: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9168 - accuracy: 0.5642 - val_loss: 0.8783 - val_accuracy: 0.5405\n",
      "Epoch 87/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0655 - accuracy: 0.5000\n",
      "Epoch 87: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.5743 - val_loss: 0.9043 - val_accuracy: 0.5541\n",
      "Epoch 88/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9053 - accuracy: 0.6250\n",
      "Epoch 88: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9734 - accuracy: 0.5507 - val_loss: 0.9011 - val_accuracy: 0.5541\n",
      "Epoch 89/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9428 - accuracy: 0.5625\n",
      "Epoch 89: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9674 - accuracy: 0.5372 - val_loss: 0.9142 - val_accuracy: 0.5405\n",
      "Epoch 90/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9033 - accuracy: 0.5625\n",
      "Epoch 90: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9487 - accuracy: 0.5642 - val_loss: 0.9062 - val_accuracy: 0.5541\n",
      "Epoch 91/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8857 - accuracy: 0.6250\n",
      "Epoch 91: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0047 - accuracy: 0.5507 - val_loss: 0.9518 - val_accuracy: 0.5135\n",
      "Epoch 92/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1915 - accuracy: 0.4688\n",
      "Epoch 92: val_loss did not improve from 0.87644\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9843 - accuracy: 0.5608 - val_loss: 0.9474 - val_accuracy: 0.5405\n",
      "Epoch 93/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1133 - accuracy: 0.5000\n",
      "Epoch 93: val_loss improved from 0.87644 to 0.86519, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0158 - accuracy: 0.5372 - val_loss: 0.8652 - val_accuracy: 0.5541\n",
      "Epoch 94/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9621 - accuracy: 0.5312\n",
      "Epoch 94: val_loss improved from 0.86519 to 0.85568, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9322 - accuracy: 0.5439 - val_loss: 0.8557 - val_accuracy: 0.5405\n",
      "Epoch 95/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9641 - accuracy: 0.5938\n",
      "Epoch 95: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9166 - accuracy: 0.5709 - val_loss: 0.8862 - val_accuracy: 0.5270\n",
      "Epoch 96/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7866 - accuracy: 0.6875\n",
      "Epoch 96: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9489 - accuracy: 0.5608 - val_loss: 0.9126 - val_accuracy: 0.5270\n",
      "Epoch 97/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9099 - accuracy: 0.5312\n",
      "Epoch 97: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8956 - accuracy: 0.5405 - val_loss: 0.9217 - val_accuracy: 0.5541\n",
      "Epoch 98/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0027 - accuracy: 0.5000\n",
      "Epoch 98: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0233 - accuracy: 0.5608 - val_loss: 0.9026 - val_accuracy: 0.4865\n",
      "Epoch 99/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7299 - accuracy: 0.6875\n",
      "Epoch 99: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9765 - accuracy: 0.5236 - val_loss: 0.9138 - val_accuracy: 0.5135\n",
      "Epoch 100/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0404 - accuracy: 0.4062\n",
      "Epoch 100: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9598 - accuracy: 0.5574 - val_loss: 0.9227 - val_accuracy: 0.5541\n",
      "Epoch 101/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9958 - accuracy: 0.6562\n",
      "Epoch 101: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0192 - accuracy: 0.5439 - val_loss: 0.9081 - val_accuracy: 0.5000\n",
      "Epoch 102/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9304 - accuracy: 0.4375\n",
      "Epoch 102: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9588 - accuracy: 0.5338 - val_loss: 0.9134 - val_accuracy: 0.5405\n",
      "Epoch 103/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2526 - accuracy: 0.3750\n",
      "Epoch 103: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9913 - accuracy: 0.5473 - val_loss: 0.9175 - val_accuracy: 0.5541\n",
      "Epoch 104/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9101 - accuracy: 0.5938\n",
      "Epoch 104: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9457 - accuracy: 0.5743 - val_loss: 0.9929 - val_accuracy: 0.5676\n",
      "Epoch 105/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0449 - accuracy: 0.5000\n",
      "Epoch 105: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9918 - accuracy: 0.5405 - val_loss: 0.9248 - val_accuracy: 0.5405\n",
      "Epoch 106/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9018 - accuracy: 0.4688\n",
      "Epoch 106: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9515 - accuracy: 0.5338 - val_loss: 0.9225 - val_accuracy: 0.5135\n",
      "Epoch 107/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9606 - accuracy: 0.6250\n",
      "Epoch 107: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9588 - accuracy: 0.5541 - val_loss: 0.9155 - val_accuracy: 0.5541\n",
      "Epoch 108/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9952 - accuracy: 0.5312\n",
      "Epoch 108: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9766 - accuracy: 0.5811 - val_loss: 0.9052 - val_accuracy: 0.5541\n",
      "Epoch 109/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7364 - accuracy: 0.8438\n",
      "Epoch 109: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9300 - accuracy: 0.5507 - val_loss: 0.9252 - val_accuracy: 0.5405\n",
      "Epoch 110/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7614 - accuracy: 0.6562\n",
      "Epoch 110: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9675 - accuracy: 0.5845 - val_loss: 0.9330 - val_accuracy: 0.5405\n",
      "Epoch 111/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8249 - accuracy: 0.6250\n",
      "Epoch 111: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9554 - accuracy: 0.5608 - val_loss: 0.9235 - val_accuracy: 0.5676\n",
      "Epoch 112/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0996 - accuracy: 0.5000\n",
      "Epoch 112: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9453 - accuracy: 0.5541 - val_loss: 0.9360 - val_accuracy: 0.5270\n",
      "Epoch 113/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0456 - accuracy: 0.5938\n",
      "Epoch 113: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0344 - accuracy: 0.5270 - val_loss: 0.9173 - val_accuracy: 0.5270\n",
      "Epoch 114/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7842 - accuracy: 0.5938\n",
      "Epoch 114: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9530 - accuracy: 0.5507 - val_loss: 0.9844 - val_accuracy: 0.5000\n",
      "Epoch 115/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7676 - accuracy: 0.7500\n",
      "Epoch 115: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9518 - accuracy: 0.5574 - val_loss: 0.9236 - val_accuracy: 0.5541\n",
      "Epoch 116/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0950 - accuracy: 0.5625\n",
      "Epoch 116: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9189 - accuracy: 0.5777 - val_loss: 0.9160 - val_accuracy: 0.5676\n",
      "Epoch 117/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6692 - accuracy: 0.8125\n",
      "Epoch 117: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9073 - accuracy: 0.5811 - val_loss: 0.9254 - val_accuracy: 0.5676\n",
      "Epoch 118/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8896 - accuracy: 0.4375\n",
      "Epoch 118: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9295 - accuracy: 0.5608 - val_loss: 0.8939 - val_accuracy: 0.5676\n",
      "Epoch 119/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9669 - accuracy: 0.4688\n",
      "Epoch 119: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9436 - accuracy: 0.5811 - val_loss: 0.9216 - val_accuracy: 0.5405\n",
      "Epoch 120/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8742 - accuracy: 0.5312\n",
      "Epoch 120: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9478 - accuracy: 0.5642 - val_loss: 1.0045 - val_accuracy: 0.5405\n",
      "Epoch 121/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0003 - accuracy: 0.4688\n",
      "Epoch 121: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9810 - accuracy: 0.5338 - val_loss: 0.9623 - val_accuracy: 0.5135\n",
      "Epoch 122/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8513 - accuracy: 0.6875\n",
      "Epoch 122: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9573 - accuracy: 0.5743 - val_loss: 0.9390 - val_accuracy: 0.5405\n",
      "Epoch 123/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7873 - accuracy: 0.6562\n",
      "Epoch 123: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9662 - accuracy: 0.5270 - val_loss: 0.9920 - val_accuracy: 0.5135\n",
      "Epoch 124/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8753 - accuracy: 0.5938\n",
      "Epoch 124: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9647 - accuracy: 0.5811 - val_loss: 0.9394 - val_accuracy: 0.4459\n",
      "Epoch 125/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0212 - accuracy: 0.4062\n",
      "Epoch 125: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9739 - accuracy: 0.5608 - val_loss: 0.9354 - val_accuracy: 0.5405\n",
      "Epoch 126/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0122 - accuracy: 0.6250\n",
      "Epoch 126: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0414 - accuracy: 0.5338 - val_loss: 0.9405 - val_accuracy: 0.5541\n",
      "Epoch 127/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9741 - accuracy: 0.6250\n",
      "Epoch 127: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9642 - accuracy: 0.5642 - val_loss: 0.9187 - val_accuracy: 0.5676\n",
      "Epoch 128/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8036 - accuracy: 0.7500\n",
      "Epoch 128: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8725 - accuracy: 0.6014 - val_loss: 0.9213 - val_accuracy: 0.5811\n",
      "Epoch 129/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0869 - accuracy: 0.5625\n",
      "Epoch 129: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0021 - accuracy: 0.5405 - val_loss: 0.9068 - val_accuracy: 0.5135\n",
      "Epoch 130/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0594 - accuracy: 0.5938\n",
      "Epoch 130: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0024 - accuracy: 0.5372 - val_loss: 0.9415 - val_accuracy: 0.5135\n",
      "Epoch 131/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9395 - accuracy: 0.5625\n",
      "Epoch 131: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9411 - accuracy: 0.5439 - val_loss: 0.9256 - val_accuracy: 0.5270\n",
      "Epoch 132/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8381 - accuracy: 0.6250\n",
      "Epoch 132: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9153 - accuracy: 0.5608 - val_loss: 0.8964 - val_accuracy: 0.5405\n",
      "Epoch 133/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8278 - accuracy: 0.5938\n",
      "Epoch 133: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9850 - accuracy: 0.5338 - val_loss: 0.9023 - val_accuracy: 0.5270\n",
      "Epoch 134/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8152 - accuracy: 0.6875\n",
      "Epoch 134: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8782 - accuracy: 0.5946 - val_loss: 0.9329 - val_accuracy: 0.5541\n",
      "Epoch 135/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6785 - accuracy: 0.6562\n",
      "Epoch 135: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9206 - accuracy: 0.5845 - val_loss: 0.9318 - val_accuracy: 0.5270\n",
      "Epoch 136/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9079 - accuracy: 0.5625\n",
      "Epoch 136: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9069 - accuracy: 0.5946 - val_loss: 0.9051 - val_accuracy: 0.5405\n",
      "Epoch 137/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8965 - accuracy: 0.6250\n",
      "Epoch 137: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.5946 - val_loss: 0.9178 - val_accuracy: 0.5270\n",
      "Epoch 138/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7754 - accuracy: 0.6562\n",
      "Epoch 138: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9237 - accuracy: 0.5980 - val_loss: 0.9226 - val_accuracy: 0.5270\n",
      "Epoch 139/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7630 - accuracy: 0.6250\n",
      "Epoch 139: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8917 - accuracy: 0.5676 - val_loss: 0.9120 - val_accuracy: 0.5405\n",
      "Epoch 140/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0420 - accuracy: 0.4688\n",
      "Epoch 140: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9152 - accuracy: 0.5642 - val_loss: 0.9181 - val_accuracy: 0.5405\n",
      "Epoch 141/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0009 - accuracy: 0.5312\n",
      "Epoch 141: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9015 - accuracy: 0.5608 - val_loss: 0.9161 - val_accuracy: 0.5000\n",
      "Epoch 142/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8877 - accuracy: 0.5312\n",
      "Epoch 142: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8622 - accuracy: 0.5743 - val_loss: 0.9304 - val_accuracy: 0.5405\n",
      "Epoch 143/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9279 - accuracy: 0.5000\n",
      "Epoch 143: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8615 - accuracy: 0.5946 - val_loss: 0.8982 - val_accuracy: 0.5405\n",
      "Epoch 144/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8567 - accuracy: 0.6250\n",
      "Epoch 144: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8685 - accuracy: 0.6047 - val_loss: 0.9041 - val_accuracy: 0.5135\n",
      "Epoch 145/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7407 - accuracy: 0.6875\n",
      "Epoch 145: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8887 - accuracy: 0.5777 - val_loss: 0.8978 - val_accuracy: 0.5135\n",
      "Epoch 146/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8671 - accuracy: 0.6250\n",
      "Epoch 146: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8979 - accuracy: 0.6047 - val_loss: 0.9524 - val_accuracy: 0.5270\n",
      "Epoch 147/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0117 - accuracy: 0.5625\n",
      "Epoch 147: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9930 - accuracy: 0.5743 - val_loss: 0.9392 - val_accuracy: 0.5270\n",
      "Epoch 148/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9944 - accuracy: 0.4688\n",
      "Epoch 148: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9001 - accuracy: 0.5709 - val_loss: 0.8939 - val_accuracy: 0.5135\n",
      "Epoch 149/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9115 - accuracy: 0.5000\n",
      "Epoch 149: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9040 - accuracy: 0.5574 - val_loss: 0.9006 - val_accuracy: 0.5270\n",
      "Epoch 150/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1049 - accuracy: 0.4375\n",
      "Epoch 150: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9167 - accuracy: 0.5473 - val_loss: 0.9111 - val_accuracy: 0.5000\n",
      "Epoch 151/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8594 - accuracy: 0.6250\n",
      "Epoch 151: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9181 - accuracy: 0.5541 - val_loss: 0.8880 - val_accuracy: 0.5135\n",
      "Epoch 152/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8370 - accuracy: 0.7188\n",
      "Epoch 152: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9239 - accuracy: 0.5912 - val_loss: 0.8841 - val_accuracy: 0.5135\n",
      "Epoch 153/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6261 - accuracy: 0.8125\n",
      "Epoch 153: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9429 - accuracy: 0.6149 - val_loss: 0.8959 - val_accuracy: 0.5000\n",
      "Epoch 154/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8405 - accuracy: 0.6250\n",
      "Epoch 154: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9371 - accuracy: 0.5845 - val_loss: 0.9197 - val_accuracy: 0.5135\n",
      "Epoch 155/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8346 - accuracy: 0.6250\n",
      "Epoch 155: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8558 - accuracy: 0.6115 - val_loss: 0.9323 - val_accuracy: 0.5270\n",
      "Epoch 156/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1552 - accuracy: 0.4375\n",
      "Epoch 156: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9953 - accuracy: 0.5473 - val_loss: 0.9090 - val_accuracy: 0.5135\n",
      "Epoch 157/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9246 - accuracy: 0.5938\n",
      "Epoch 157: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.5642 - val_loss: 0.9119 - val_accuracy: 0.5270\n",
      "Epoch 158/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0683 - accuracy: 0.6562\n",
      "Epoch 158: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9614 - accuracy: 0.5980 - val_loss: 0.8806 - val_accuracy: 0.5270\n",
      "Epoch 159/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9322 - accuracy: 0.5000\n",
      "Epoch 159: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9625 - accuracy: 0.5203 - val_loss: 0.9013 - val_accuracy: 0.5405\n",
      "Epoch 160/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7636 - accuracy: 0.5312\n",
      "Epoch 160: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8598 - accuracy: 0.6014 - val_loss: 0.8822 - val_accuracy: 0.5405\n",
      "Epoch 161/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7019 - accuracy: 0.6562\n",
      "Epoch 161: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9017 - accuracy: 0.5878 - val_loss: 0.9075 - val_accuracy: 0.5000\n",
      "Epoch 162/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8763 - accuracy: 0.5000\n",
      "Epoch 162: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8975 - accuracy: 0.5980 - val_loss: 0.9038 - val_accuracy: 0.5000\n",
      "Epoch 163/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9427 - accuracy: 0.5312\n",
      "Epoch 163: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9214 - accuracy: 0.5541 - val_loss: 0.9114 - val_accuracy: 0.5270\n",
      "Epoch 164/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9504 - accuracy: 0.4688\n",
      "Epoch 164: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9064 - accuracy: 0.5980 - val_loss: 0.8942 - val_accuracy: 0.5270\n",
      "Epoch 165/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9075 - accuracy: 0.6250\n",
      "Epoch 165: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9127 - accuracy: 0.5980 - val_loss: 0.9091 - val_accuracy: 0.5135\n",
      "Epoch 166/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8422 - accuracy: 0.6562\n",
      "Epoch 166: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9157 - accuracy: 0.5811 - val_loss: 0.9657 - val_accuracy: 0.5405\n",
      "Epoch 167/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8040 - accuracy: 0.5312\n",
      "Epoch 167: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9361 - accuracy: 0.5439 - val_loss: 0.9107 - val_accuracy: 0.5270\n",
      "Epoch 168/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8283 - accuracy: 0.5312\n",
      "Epoch 168: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9153 - accuracy: 0.5642 - val_loss: 0.9029 - val_accuracy: 0.5405\n",
      "Epoch 169/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9396 - accuracy: 0.5938\n",
      "Epoch 169: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8818 - accuracy: 0.5878 - val_loss: 0.8898 - val_accuracy: 0.5541\n",
      "Epoch 170/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9151 - accuracy: 0.5625\n",
      "Epoch 170: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8896 - accuracy: 0.5574 - val_loss: 0.9415 - val_accuracy: 0.4865\n",
      "Epoch 171/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2184 - accuracy: 0.5312\n",
      "Epoch 171: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8820 - accuracy: 0.5709 - val_loss: 0.9144 - val_accuracy: 0.5541\n",
      "Epoch 172/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8186 - accuracy: 0.5625\n",
      "Epoch 172: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8814 - accuracy: 0.5878 - val_loss: 0.9131 - val_accuracy: 0.5135\n",
      "Epoch 173/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9249 - accuracy: 0.6250\n",
      "Epoch 173: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9142 - accuracy: 0.5878 - val_loss: 0.9276 - val_accuracy: 0.5135\n",
      "Epoch 174/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9913 - accuracy: 0.5000\n",
      "Epoch 174: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8674 - accuracy: 0.5811 - val_loss: 0.8836 - val_accuracy: 0.5270\n",
      "Epoch 175/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1568 - accuracy: 0.4688\n",
      "Epoch 175: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9057 - accuracy: 0.5878 - val_loss: 0.9022 - val_accuracy: 0.5270\n",
      "Epoch 176/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7834 - accuracy: 0.5625\n",
      "Epoch 176: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8415 - accuracy: 0.6081 - val_loss: 0.8772 - val_accuracy: 0.5270\n",
      "Epoch 177/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6351 - accuracy: 0.7500\n",
      "Epoch 177: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8259 - accuracy: 0.6250 - val_loss: 0.9141 - val_accuracy: 0.5270\n",
      "Epoch 178/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8256 - accuracy: 0.6875\n",
      "Epoch 178: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8486 - accuracy: 0.6047 - val_loss: 0.8673 - val_accuracy: 0.5541\n",
      "Epoch 179/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9456 - accuracy: 0.6250\n",
      "Epoch 179: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8426 - accuracy: 0.6149 - val_loss: 0.8705 - val_accuracy: 0.5405\n",
      "Epoch 180/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0114 - accuracy: 0.6250\n",
      "Epoch 180: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8998 - accuracy: 0.6081 - val_loss: 0.9166 - val_accuracy: 0.5270\n",
      "Epoch 181/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7910 - accuracy: 0.6562\n",
      "Epoch 181: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8980 - accuracy: 0.5878 - val_loss: 0.9243 - val_accuracy: 0.5270\n",
      "Epoch 182/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9555 - accuracy: 0.5938\n",
      "Epoch 182: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8805 - accuracy: 0.6182 - val_loss: 0.9100 - val_accuracy: 0.5000\n",
      "Epoch 183/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7071 - accuracy: 0.6250\n",
      "Epoch 183: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9030 - accuracy: 0.5777 - val_loss: 0.9295 - val_accuracy: 0.5405\n",
      "Epoch 184/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1543 - accuracy: 0.4688\n",
      "Epoch 184: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9026 - accuracy: 0.5845 - val_loss: 0.9444 - val_accuracy: 0.5811\n",
      "Epoch 185/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1505 - accuracy: 0.6250\n",
      "Epoch 185: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9230 - accuracy: 0.5980 - val_loss: 0.9223 - val_accuracy: 0.5541\n",
      "Epoch 186/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9707 - accuracy: 0.6875\n",
      "Epoch 186: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9027 - accuracy: 0.5980 - val_loss: 0.8815 - val_accuracy: 0.5270\n",
      "Epoch 187/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7303 - accuracy: 0.6250\n",
      "Epoch 187: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8841 - accuracy: 0.5777 - val_loss: 0.8932 - val_accuracy: 0.5135\n",
      "Epoch 188/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8045 - accuracy: 0.6250\n",
      "Epoch 188: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8688 - accuracy: 0.5912 - val_loss: 0.8772 - val_accuracy: 0.5270\n",
      "Epoch 189/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7070 - accuracy: 0.6250\n",
      "Epoch 189: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8725 - accuracy: 0.6014 - val_loss: 0.8871 - val_accuracy: 0.5000\n",
      "Epoch 190/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7982 - accuracy: 0.5938\n",
      "Epoch 190: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.5980 - val_loss: 0.8614 - val_accuracy: 0.5000\n",
      "Epoch 191/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7615 - accuracy: 0.6562\n",
      "Epoch 191: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8311 - accuracy: 0.5912 - val_loss: 1.0205 - val_accuracy: 0.5270\n",
      "Epoch 192/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9932 - accuracy: 0.5938\n",
      "Epoch 192: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9489 - accuracy: 0.5912 - val_loss: 0.9316 - val_accuracy: 0.5270\n",
      "Epoch 193/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7444 - accuracy: 0.6562\n",
      "Epoch 193: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9710 - accuracy: 0.5405 - val_loss: 0.9194 - val_accuracy: 0.5135\n",
      "Epoch 194/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0226 - accuracy: 0.5000\n",
      "Epoch 194: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9695 - accuracy: 0.5743 - val_loss: 0.9414 - val_accuracy: 0.4595\n",
      "Epoch 195/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0617 - accuracy: 0.4688\n",
      "Epoch 195: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9498 - accuracy: 0.5439 - val_loss: 0.9756 - val_accuracy: 0.4459\n",
      "Epoch 196/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7363 - accuracy: 0.6250\n",
      "Epoch 196: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9209 - accuracy: 0.5845 - val_loss: 0.9467 - val_accuracy: 0.5135\n",
      "Epoch 197/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1971 - accuracy: 0.3438\n",
      "Epoch 197: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9154 - accuracy: 0.5541 - val_loss: 0.8841 - val_accuracy: 0.5000\n",
      "Epoch 198/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9120 - accuracy: 0.6250\n",
      "Epoch 198: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9015 - accuracy: 0.6115 - val_loss: 0.8888 - val_accuracy: 0.5405\n",
      "Epoch 199/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9880 - accuracy: 0.5625\n",
      "Epoch 199: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.5811 - val_loss: 0.9009 - val_accuracy: 0.5000\n",
      "Epoch 200/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7523 - accuracy: 0.6250\n",
      "Epoch 200: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8728 - accuracy: 0.6216 - val_loss: 0.9137 - val_accuracy: 0.4865\n",
      "Epoch 201/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0031 - accuracy: 0.4688\n",
      "Epoch 201: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9147 - accuracy: 0.5642 - val_loss: 0.9909 - val_accuracy: 0.5000\n",
      "Epoch 202/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9147 - accuracy: 0.6250\n",
      "Epoch 202: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9193 - accuracy: 0.5845 - val_loss: 0.9356 - val_accuracy: 0.5270\n",
      "Epoch 203/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7760 - accuracy: 0.6250\n",
      "Epoch 203: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8533 - accuracy: 0.6014 - val_loss: 0.9113 - val_accuracy: 0.5000\n",
      "Epoch 204/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8750 - accuracy: 0.5312\n",
      "Epoch 204: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9020 - accuracy: 0.5777 - val_loss: 0.9285 - val_accuracy: 0.5405\n",
      "Epoch 205/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7911 - accuracy: 0.5625\n",
      "Epoch 205: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9046 - accuracy: 0.6081 - val_loss: 0.8960 - val_accuracy: 0.5270\n",
      "Epoch 206/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0195 - accuracy: 0.5312\n",
      "Epoch 206: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9406 - accuracy: 0.5743 - val_loss: 0.9053 - val_accuracy: 0.5676\n",
      "Epoch 207/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6395 - accuracy: 0.6875\n",
      "Epoch 207: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8678 - accuracy: 0.6081 - val_loss: 0.9277 - val_accuracy: 0.5676\n",
      "Epoch 208/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9053 - accuracy: 0.6562\n",
      "Epoch 208: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8944 - accuracy: 0.5946 - val_loss: 0.9033 - val_accuracy: 0.5135\n",
      "Epoch 209/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8807 - accuracy: 0.6250\n",
      "Epoch 209: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8513 - accuracy: 0.6149 - val_loss: 0.8987 - val_accuracy: 0.5405\n",
      "Epoch 210/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6642 - accuracy: 0.6875\n",
      "Epoch 210: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8830 - accuracy: 0.5439 - val_loss: 0.8875 - val_accuracy: 0.5405\n",
      "Epoch 211/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8085 - accuracy: 0.5938\n",
      "Epoch 211: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8648 - accuracy: 0.5980 - val_loss: 0.9014 - val_accuracy: 0.5135\n",
      "Epoch 212/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9890 - accuracy: 0.5312\n",
      "Epoch 212: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9314 - accuracy: 0.5574 - val_loss: 0.8994 - val_accuracy: 0.5135\n",
      "Epoch 213/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7283 - accuracy: 0.6562\n",
      "Epoch 213: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8648 - accuracy: 0.6149 - val_loss: 0.9044 - val_accuracy: 0.5541\n",
      "Epoch 214/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7629 - accuracy: 0.6562\n",
      "Epoch 214: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8511 - accuracy: 0.6149 - val_loss: 0.8954 - val_accuracy: 0.5270\n",
      "Epoch 215/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8406 - accuracy: 0.6875\n",
      "Epoch 215: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8662 - accuracy: 0.5743 - val_loss: 0.9335 - val_accuracy: 0.5541\n",
      "Epoch 216/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8974 - accuracy: 0.5938\n",
      "Epoch 216: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9000 - accuracy: 0.5912 - val_loss: 0.9436 - val_accuracy: 0.5270\n",
      "Epoch 217/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9207 - accuracy: 0.5625\n",
      "Epoch 217: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9344 - accuracy: 0.5676 - val_loss: 0.9225 - val_accuracy: 0.5405\n",
      "Epoch 218/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9901 - accuracy: 0.6562\n",
      "Epoch 218: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9280 - accuracy: 0.5676 - val_loss: 0.8796 - val_accuracy: 0.5676\n",
      "Epoch 219/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0444 - accuracy: 0.4688\n",
      "Epoch 219: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8794 - accuracy: 0.5946 - val_loss: 0.8928 - val_accuracy: 0.5405\n",
      "Epoch 220/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0188 - accuracy: 0.6875\n",
      "Epoch 220: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9054 - accuracy: 0.6014 - val_loss: 0.8912 - val_accuracy: 0.5270\n",
      "Epoch 221/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7942 - accuracy: 0.6562\n",
      "Epoch 221: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8651 - accuracy: 0.6149 - val_loss: 0.8785 - val_accuracy: 0.5135\n",
      "Epoch 222/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8325 - accuracy: 0.6250\n",
      "Epoch 222: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.6081 - val_loss: 0.8782 - val_accuracy: 0.5270\n",
      "Epoch 223/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9023 - accuracy: 0.6562\n",
      "Epoch 223: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8869 - accuracy: 0.5980 - val_loss: 0.8732 - val_accuracy: 0.5000\n",
      "Epoch 224/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8096 - accuracy: 0.7188\n",
      "Epoch 224: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8509 - accuracy: 0.5980 - val_loss: 0.8968 - val_accuracy: 0.5270\n",
      "Epoch 225/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6981 - accuracy: 0.7188\n",
      "Epoch 225: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8718 - accuracy: 0.5946 - val_loss: 0.9618 - val_accuracy: 0.5135\n",
      "Epoch 226/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7615 - accuracy: 0.6562\n",
      "Epoch 226: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8763 - accuracy: 0.6081 - val_loss: 0.8912 - val_accuracy: 0.5000\n",
      "Epoch 227/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8901 - accuracy: 0.5625\n",
      "Epoch 227: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8463 - accuracy: 0.5878 - val_loss: 0.8914 - val_accuracy: 0.5270\n",
      "Epoch 228/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0220 - accuracy: 0.4688\n",
      "Epoch 228: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8588 - accuracy: 0.5946 - val_loss: 0.9031 - val_accuracy: 0.5270\n",
      "Epoch 229/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9033 - accuracy: 0.5625\n",
      "Epoch 229: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8567 - accuracy: 0.6081 - val_loss: 0.8903 - val_accuracy: 0.5135\n",
      "Epoch 230/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8997 - accuracy: 0.5312\n",
      "Epoch 230: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8928 - accuracy: 0.5980 - val_loss: 0.9241 - val_accuracy: 0.5405\n",
      "Epoch 231/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1445 - accuracy: 0.4062\n",
      "Epoch 231: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8551 - accuracy: 0.6115 - val_loss: 0.9229 - val_accuracy: 0.5541\n",
      "Epoch 232/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8017 - accuracy: 0.5938\n",
      "Epoch 232: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8487 - accuracy: 0.5912 - val_loss: 0.9327 - val_accuracy: 0.5135\n",
      "Epoch 233/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6633 - accuracy: 0.7500\n",
      "Epoch 233: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8567 - accuracy: 0.6250 - val_loss: 0.9639 - val_accuracy: 0.5000\n",
      "Epoch 234/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9009 - accuracy: 0.4688\n",
      "Epoch 234: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8715 - accuracy: 0.5777 - val_loss: 0.9379 - val_accuracy: 0.5135\n",
      "Epoch 235/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9616 - accuracy: 0.4688\n",
      "Epoch 235: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9242 - accuracy: 0.5405 - val_loss: 0.8890 - val_accuracy: 0.5405\n",
      "Epoch 236/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9486 - accuracy: 0.5938\n",
      "Epoch 236: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8974 - accuracy: 0.5743 - val_loss: 0.8672 - val_accuracy: 0.5405\n",
      "Epoch 237/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7973 - accuracy: 0.6250\n",
      "Epoch 237: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8603 - accuracy: 0.6047 - val_loss: 0.9115 - val_accuracy: 0.5405\n",
      "Epoch 238/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8106 - accuracy: 0.6250\n",
      "Epoch 238: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8883 - accuracy: 0.5878 - val_loss: 0.9088 - val_accuracy: 0.5405\n",
      "Epoch 239/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8064 - accuracy: 0.6250\n",
      "Epoch 239: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8660 - accuracy: 0.5777 - val_loss: 0.9060 - val_accuracy: 0.5270\n",
      "Epoch 240/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8590 - accuracy: 0.5625\n",
      "Epoch 240: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8604 - accuracy: 0.5845 - val_loss: 0.9450 - val_accuracy: 0.5541\n",
      "Epoch 241/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9565 - accuracy: 0.4375\n",
      "Epoch 241: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9461 - accuracy: 0.5845 - val_loss: 0.9459 - val_accuracy: 0.5270\n",
      "Epoch 242/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9413 - accuracy: 0.5312\n",
      "Epoch 242: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8734 - accuracy: 0.5946 - val_loss: 0.9574 - val_accuracy: 0.5135\n",
      "Epoch 243/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8494 - accuracy: 0.5625\n",
      "Epoch 243: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8819 - accuracy: 0.5709 - val_loss: 0.9564 - val_accuracy: 0.5405\n",
      "Epoch 244/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8588 - accuracy: 0.5625\n",
      "Epoch 244: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8660 - accuracy: 0.5980 - val_loss: 0.8942 - val_accuracy: 0.5270\n",
      "Epoch 245/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0516 - accuracy: 0.4062\n",
      "Epoch 245: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8646 - accuracy: 0.5777 - val_loss: 0.9351 - val_accuracy: 0.5000\n",
      "Epoch 246/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.5938\n",
      "Epoch 246: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8289 - accuracy: 0.6318 - val_loss: 0.8974 - val_accuracy: 0.5000\n",
      "Epoch 247/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8435 - accuracy: 0.5312\n",
      "Epoch 247: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9658 - accuracy: 0.5372 - val_loss: 0.9245 - val_accuracy: 0.5405\n",
      "Epoch 248/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1086 - accuracy: 0.5312\n",
      "Epoch 248: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9579 - accuracy: 0.5541 - val_loss: 0.9138 - val_accuracy: 0.5270\n",
      "Epoch 249/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0537 - accuracy: 0.4375\n",
      "Epoch 249: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8853 - accuracy: 0.5743 - val_loss: 0.9322 - val_accuracy: 0.5405\n",
      "Epoch 250/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9281 - accuracy: 0.6250\n",
      "Epoch 250: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8848 - accuracy: 0.5912 - val_loss: 0.9239 - val_accuracy: 0.5405\n",
      "Epoch 251/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2526 - accuracy: 0.4062\n",
      "Epoch 251: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8972 - accuracy: 0.5946 - val_loss: 0.8877 - val_accuracy: 0.5135\n",
      "Epoch 252/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9744 - accuracy: 0.5625\n",
      "Epoch 252: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9111 - accuracy: 0.5878 - val_loss: 0.8759 - val_accuracy: 0.5270\n",
      "Epoch 253/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0039 - accuracy: 0.4375\n",
      "Epoch 253: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8903 - accuracy: 0.5811 - val_loss: 0.9187 - val_accuracy: 0.5405\n",
      "Epoch 254/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1789 - accuracy: 0.3438\n",
      "Epoch 254: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9185 - accuracy: 0.5743 - val_loss: 0.9059 - val_accuracy: 0.5135\n",
      "Epoch 255/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8557 - accuracy: 0.5938\n",
      "Epoch 255: val_loss did not improve from 0.85568\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8652 - accuracy: 0.5878 - val_loss: 0.8651 - val_accuracy: 0.5270\n",
      "Epoch 256/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1236 - accuracy: 0.4375\n",
      "Epoch 256: val_loss improved from 0.85568 to 0.85441, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8707 - accuracy: 0.5912 - val_loss: 0.8544 - val_accuracy: 0.5135\n",
      "Epoch 257/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9357 - accuracy: 0.5312\n",
      "Epoch 257: val_loss improved from 0.85441 to 0.84636, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8935 - accuracy: 0.5912 - val_loss: 0.8464 - val_accuracy: 0.5270\n",
      "Epoch 258/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9145 - accuracy: 0.5938\n",
      "Epoch 258: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8396 - accuracy: 0.5845 - val_loss: 0.8879 - val_accuracy: 0.5541\n",
      "Epoch 259/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7670 - accuracy: 0.6562\n",
      "Epoch 259: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8652 - accuracy: 0.5980 - val_loss: 0.9071 - val_accuracy: 0.5270\n",
      "Epoch 260/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9694 - accuracy: 0.4375\n",
      "Epoch 260: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8975 - accuracy: 0.5811 - val_loss: 0.8709 - val_accuracy: 0.5270\n",
      "Epoch 261/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9360 - accuracy: 0.6250\n",
      "Epoch 261: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8647 - accuracy: 0.5777 - val_loss: 0.8770 - val_accuracy: 0.5135\n",
      "Epoch 262/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8904 - accuracy: 0.5625\n",
      "Epoch 262: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8896 - accuracy: 0.5507 - val_loss: 0.8670 - val_accuracy: 0.5135\n",
      "Epoch 263/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9407 - accuracy: 0.5312\n",
      "Epoch 263: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9056 - accuracy: 0.5676 - val_loss: 0.8850 - val_accuracy: 0.5270\n",
      "Epoch 264/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8956 - accuracy: 0.6562\n",
      "Epoch 264: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8756 - accuracy: 0.6047 - val_loss: 0.8931 - val_accuracy: 0.5270\n",
      "Epoch 265/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9374 - accuracy: 0.5312\n",
      "Epoch 265: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.6216 - val_loss: 0.8653 - val_accuracy: 0.5135\n",
      "Epoch 266/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6297 - accuracy: 0.6562\n",
      "Epoch 266: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8869 - accuracy: 0.5878 - val_loss: 0.8903 - val_accuracy: 0.5270\n",
      "Epoch 267/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7517 - accuracy: 0.7188\n",
      "Epoch 267: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8608 - accuracy: 0.6182 - val_loss: 0.9306 - val_accuracy: 0.5270\n",
      "Epoch 268/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8593 - accuracy: 0.5312\n",
      "Epoch 268: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8178 - accuracy: 0.5777 - val_loss: 0.9780 - val_accuracy: 0.5270\n",
      "Epoch 269/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0102 - accuracy: 0.5000\n",
      "Epoch 269: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8981 - accuracy: 0.5541 - val_loss: 0.9367 - val_accuracy: 0.4865\n",
      "Epoch 270/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9626 - accuracy: 0.5938\n",
      "Epoch 270: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8355 - accuracy: 0.6250 - val_loss: 0.9351 - val_accuracy: 0.5541\n",
      "Epoch 271/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7157 - accuracy: 0.6875\n",
      "Epoch 271: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8925 - accuracy: 0.6216 - val_loss: 0.9464 - val_accuracy: 0.5405\n",
      "Epoch 272/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7235 - accuracy: 0.7188\n",
      "Epoch 272: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8459 - accuracy: 0.5912 - val_loss: 0.9222 - val_accuracy: 0.5135\n",
      "Epoch 273/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7195 - accuracy: 0.6562\n",
      "Epoch 273: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8667 - accuracy: 0.5980 - val_loss: 0.9272 - val_accuracy: 0.5270\n",
      "Epoch 274/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2253 - accuracy: 0.4062\n",
      "Epoch 274: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9197 - accuracy: 0.5236 - val_loss: 0.9370 - val_accuracy: 0.5270\n",
      "Epoch 275/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6891 - accuracy: 0.6250\n",
      "Epoch 275: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8856 - accuracy: 0.5642 - val_loss: 0.9396 - val_accuracy: 0.5405\n",
      "Epoch 276/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9028 - accuracy: 0.4688\n",
      "Epoch 276: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9167 - accuracy: 0.5676 - val_loss: 0.9676 - val_accuracy: 0.5000\n",
      "Epoch 277/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7916 - accuracy: 0.6562\n",
      "Epoch 277: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8915 - accuracy: 0.5676 - val_loss: 0.9615 - val_accuracy: 0.5405\n",
      "Epoch 278/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7546 - accuracy: 0.5938\n",
      "Epoch 278: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8912 - accuracy: 0.5878 - val_loss: 0.9245 - val_accuracy: 0.5405\n",
      "Epoch 279/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9101 - accuracy: 0.5938\n",
      "Epoch 279: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8535 - accuracy: 0.5811 - val_loss: 0.9103 - val_accuracy: 0.5270\n",
      "Epoch 280/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8740 - accuracy: 0.6562\n",
      "Epoch 280: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9301 - accuracy: 0.5574 - val_loss: 0.8808 - val_accuracy: 0.5405\n",
      "Epoch 281/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8094 - accuracy: 0.5625\n",
      "Epoch 281: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8629 - accuracy: 0.5845 - val_loss: 0.8978 - val_accuracy: 0.5541\n",
      "Epoch 282/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9743 - accuracy: 0.6562\n",
      "Epoch 282: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9242 - accuracy: 0.5608 - val_loss: 0.8713 - val_accuracy: 0.5270\n",
      "Epoch 283/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9352 - accuracy: 0.5625\n",
      "Epoch 283: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8420 - accuracy: 0.6115 - val_loss: 0.8639 - val_accuracy: 0.5405\n",
      "Epoch 284/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8480 - accuracy: 0.5312\n",
      "Epoch 284: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9232 - accuracy: 0.5845 - val_loss: 0.8827 - val_accuracy: 0.5270\n",
      "Epoch 285/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7972 - accuracy: 0.5938\n",
      "Epoch 285: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8719 - accuracy: 0.6216 - val_loss: 0.8923 - val_accuracy: 0.5135\n",
      "Epoch 286/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7797 - accuracy: 0.6250\n",
      "Epoch 286: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9138 - accuracy: 0.5878 - val_loss: 0.8699 - val_accuracy: 0.5270\n",
      "Epoch 287/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8179 - accuracy: 0.5938\n",
      "Epoch 287: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8575 - accuracy: 0.6014 - val_loss: 0.9016 - val_accuracy: 0.5405\n",
      "Epoch 288/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7811 - accuracy: 0.5938\n",
      "Epoch 288: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8879 - accuracy: 0.5845 - val_loss: 0.9485 - val_accuracy: 0.5541\n",
      "Epoch 289/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9928 - accuracy: 0.4375\n",
      "Epoch 289: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8862 - accuracy: 0.5777 - val_loss: 0.8925 - val_accuracy: 0.5541\n",
      "Epoch 290/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8677 - accuracy: 0.6562\n",
      "Epoch 290: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8618 - accuracy: 0.6115 - val_loss: 0.8929 - val_accuracy: 0.5405\n",
      "Epoch 291/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9668 - accuracy: 0.6250\n",
      "Epoch 291: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8750 - accuracy: 0.6216 - val_loss: 0.9609 - val_accuracy: 0.5541\n",
      "Epoch 292/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8736 - accuracy: 0.7188\n",
      "Epoch 292: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8758 - accuracy: 0.6115 - val_loss: 0.9220 - val_accuracy: 0.5270\n",
      "Epoch 293/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8276 - accuracy: 0.6250\n",
      "Epoch 293: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8732 - accuracy: 0.5946 - val_loss: 0.8898 - val_accuracy: 0.5270\n",
      "Epoch 294/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8161 - accuracy: 0.6250\n",
      "Epoch 294: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8885 - accuracy: 0.5676 - val_loss: 0.8861 - val_accuracy: 0.5405\n",
      "Epoch 295/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9935 - accuracy: 0.5312\n",
      "Epoch 295: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8692 - accuracy: 0.6081 - val_loss: 0.9041 - val_accuracy: 0.5405\n",
      "Epoch 296/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8099 - accuracy: 0.5625\n",
      "Epoch 296: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.5878 - val_loss: 0.9053 - val_accuracy: 0.5541\n",
      "Epoch 297/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0547 - accuracy: 0.5312\n",
      "Epoch 297: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8700 - accuracy: 0.5980 - val_loss: 0.9603 - val_accuracy: 0.5405\n",
      "Epoch 298/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8135 - accuracy: 0.6250\n",
      "Epoch 298: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8914 - accuracy: 0.6014 - val_loss: 0.9048 - val_accuracy: 0.5135\n",
      "Epoch 299/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9209 - accuracy: 0.4688\n",
      "Epoch 299: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8652 - accuracy: 0.5642 - val_loss: 0.8990 - val_accuracy: 0.5405\n",
      "Epoch 300/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6406 - accuracy: 0.7500\n",
      "Epoch 300: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7988 - accuracy: 0.6284 - val_loss: 0.9069 - val_accuracy: 0.4865\n",
      "Epoch 301/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6320 - accuracy: 0.7812\n",
      "Epoch 301: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8375 - accuracy: 0.6351 - val_loss: 0.9125 - val_accuracy: 0.5270\n",
      "Epoch 302/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7370 - accuracy: 0.6875\n",
      "Epoch 302: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7921 - accuracy: 0.6486 - val_loss: 0.9129 - val_accuracy: 0.5405\n",
      "Epoch 303/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6299 - accuracy: 0.6875\n",
      "Epoch 303: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8263 - accuracy: 0.6419 - val_loss: 0.9321 - val_accuracy: 0.5405\n",
      "Epoch 304/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8875 - accuracy: 0.5625\n",
      "Epoch 304: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8949 - accuracy: 0.5845 - val_loss: 0.9153 - val_accuracy: 0.5270\n",
      "Epoch 305/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8014 - accuracy: 0.5938\n",
      "Epoch 305: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8460 - accuracy: 0.6014 - val_loss: 0.9496 - val_accuracy: 0.5405\n",
      "Epoch 306/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8348 - accuracy: 0.6562\n",
      "Epoch 306: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7932 - accuracy: 0.6284 - val_loss: 0.9897 - val_accuracy: 0.5270\n",
      "Epoch 307/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8433 - accuracy: 0.5312\n",
      "Epoch 307: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7976 - accuracy: 0.6115 - val_loss: 0.9398 - val_accuracy: 0.5270\n",
      "Epoch 308/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7532 - accuracy: 0.6250\n",
      "Epoch 308: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8462 - accuracy: 0.6014 - val_loss: 0.9324 - val_accuracy: 0.5270\n",
      "Epoch 309/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9450 - accuracy: 0.5938\n",
      "Epoch 309: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7998 - accuracy: 0.6250 - val_loss: 0.9152 - val_accuracy: 0.5405\n",
      "Epoch 310/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6799 - accuracy: 0.6875\n",
      "Epoch 310: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8350 - accuracy: 0.6318 - val_loss: 0.9005 - val_accuracy: 0.5000\n",
      "Epoch 311/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6194 - accuracy: 0.7500\n",
      "Epoch 311: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8030 - accuracy: 0.6318 - val_loss: 0.9521 - val_accuracy: 0.5541\n",
      "Epoch 312/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6413 - accuracy: 0.7188\n",
      "Epoch 312: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8600 - accuracy: 0.6149 - val_loss: 0.8783 - val_accuracy: 0.5135\n",
      "Epoch 313/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9406 - accuracy: 0.5938\n",
      "Epoch 313: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8774 - accuracy: 0.5946 - val_loss: 0.9074 - val_accuracy: 0.5270\n",
      "Epoch 314/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0500 - accuracy: 0.4688\n",
      "Epoch 314: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8771 - accuracy: 0.5743 - val_loss: 0.8577 - val_accuracy: 0.5135\n",
      "Epoch 315/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7254 - accuracy: 0.6875\n",
      "Epoch 315: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8609 - accuracy: 0.5878 - val_loss: 0.8952 - val_accuracy: 0.5270\n",
      "Epoch 316/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2909 - accuracy: 0.6875\n",
      "Epoch 316: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9007 - accuracy: 0.6182 - val_loss: 0.8596 - val_accuracy: 0.5270\n",
      "Epoch 317/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7932 - accuracy: 0.5625\n",
      "Epoch 317: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8390 - accuracy: 0.6318 - val_loss: 0.9082 - val_accuracy: 0.5405\n",
      "Epoch 318/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8607 - accuracy: 0.5000\n",
      "Epoch 318: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8856 - accuracy: 0.5912 - val_loss: 0.9299 - val_accuracy: 0.5270\n",
      "Epoch 319/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8597 - accuracy: 0.5625\n",
      "Epoch 319: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8381 - accuracy: 0.5946 - val_loss: 0.8661 - val_accuracy: 0.5270\n",
      "Epoch 320/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9094 - accuracy: 0.5312\n",
      "Epoch 320: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8818 - accuracy: 0.6216 - val_loss: 0.8479 - val_accuracy: 0.5541\n",
      "Epoch 321/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8444 - accuracy: 0.5938\n",
      "Epoch 321: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8750 - accuracy: 0.6419 - val_loss: 0.8863 - val_accuracy: 0.5541\n",
      "Epoch 322/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6829 - accuracy: 0.6875\n",
      "Epoch 322: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8832 - accuracy: 0.5980 - val_loss: 0.8808 - val_accuracy: 0.5541\n",
      "Epoch 323/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8515 - accuracy: 0.5625\n",
      "Epoch 323: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8464 - accuracy: 0.6250 - val_loss: 0.9035 - val_accuracy: 0.5135\n",
      "Epoch 324/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7834 - accuracy: 0.6562\n",
      "Epoch 324: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8953 - accuracy: 0.6115 - val_loss: 0.9323 - val_accuracy: 0.5676\n",
      "Epoch 325/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8487 - accuracy: 0.7500\n",
      "Epoch 325: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8475 - accuracy: 0.6115 - val_loss: 0.9560 - val_accuracy: 0.5541\n",
      "Epoch 326/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7907 - accuracy: 0.6250\n",
      "Epoch 326: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8253 - accuracy: 0.6284 - val_loss: 0.9588 - val_accuracy: 0.5541\n",
      "Epoch 327/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8831 - accuracy: 0.5312\n",
      "Epoch 327: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8250 - accuracy: 0.6182 - val_loss: 0.9878 - val_accuracy: 0.5541\n",
      "Epoch 328/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6352 - accuracy: 0.7500\n",
      "Epoch 328: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8137 - accuracy: 0.6385 - val_loss: 0.9118 - val_accuracy: 0.5541\n",
      "Epoch 329/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1432 - accuracy: 0.5312\n",
      "Epoch 329: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.6622 - val_loss: 0.9170 - val_accuracy: 0.5541\n",
      "Epoch 330/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7646 - accuracy: 0.6875\n",
      "Epoch 330: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8563 - accuracy: 0.6182 - val_loss: 0.9124 - val_accuracy: 0.5405\n",
      "Epoch 331/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6418 - accuracy: 0.7500\n",
      "Epoch 331: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8087 - accuracy: 0.6182 - val_loss: 0.8821 - val_accuracy: 0.5541\n",
      "Epoch 332/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8248 - accuracy: 0.5938\n",
      "Epoch 332: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8649 - accuracy: 0.6318 - val_loss: 0.8796 - val_accuracy: 0.5270\n",
      "Epoch 333/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0388 - accuracy: 0.5625\n",
      "Epoch 333: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8214 - accuracy: 0.6351 - val_loss: 0.9535 - val_accuracy: 0.5405\n",
      "Epoch 334/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9138 - accuracy: 0.5938\n",
      "Epoch 334: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8645 - accuracy: 0.6047 - val_loss: 0.9444 - val_accuracy: 0.5270\n",
      "Epoch 335/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9003 - accuracy: 0.5625\n",
      "Epoch 335: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8432 - accuracy: 0.6284 - val_loss: 0.9074 - val_accuracy: 0.5270\n",
      "Epoch 336/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6628 - accuracy: 0.8125\n",
      "Epoch 336: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8203 - accuracy: 0.6419 - val_loss: 0.9084 - val_accuracy: 0.5135\n",
      "Epoch 337/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6607 - accuracy: 0.6875\n",
      "Epoch 337: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8614 - accuracy: 0.5845 - val_loss: 0.9148 - val_accuracy: 0.5405\n",
      "Epoch 338/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8013 - accuracy: 0.5625\n",
      "Epoch 338: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8415 - accuracy: 0.6047 - val_loss: 0.9081 - val_accuracy: 0.5000\n",
      "Epoch 339/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7783 - accuracy: 0.6562\n",
      "Epoch 339: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8964 - accuracy: 0.6149 - val_loss: 0.8962 - val_accuracy: 0.5405\n",
      "Epoch 340/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8531 - accuracy: 0.5312\n",
      "Epoch 340: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8548 - accuracy: 0.6520 - val_loss: 0.9193 - val_accuracy: 0.5270\n",
      "Epoch 341/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9824 - accuracy: 0.5000\n",
      "Epoch 341: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8189 - accuracy: 0.6216 - val_loss: 0.9430 - val_accuracy: 0.5270\n",
      "Epoch 342/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8660 - accuracy: 0.6875\n",
      "Epoch 342: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8254 - accuracy: 0.6284 - val_loss: 0.9082 - val_accuracy: 0.5405\n",
      "Epoch 343/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0159 - accuracy: 0.5625\n",
      "Epoch 343: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8824 - accuracy: 0.6081 - val_loss: 0.9051 - val_accuracy: 0.5541\n",
      "Epoch 344/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8428 - accuracy: 0.6250\n",
      "Epoch 344: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8348 - accuracy: 0.6284 - val_loss: 0.9207 - val_accuracy: 0.5405\n",
      "Epoch 345/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9668 - accuracy: 0.5938\n",
      "Epoch 345: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8959 - accuracy: 0.5912 - val_loss: 0.9090 - val_accuracy: 0.5270\n",
      "Epoch 346/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8381 - accuracy: 0.5938\n",
      "Epoch 346: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8371 - accuracy: 0.5878 - val_loss: 0.9030 - val_accuracy: 0.5135\n",
      "Epoch 347/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8997 - accuracy: 0.5625\n",
      "Epoch 347: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8109 - accuracy: 0.6318 - val_loss: 0.8877 - val_accuracy: 0.5270\n",
      "Epoch 348/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7812 - accuracy: 0.6250\n",
      "Epoch 348: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7933 - accuracy: 0.6284 - val_loss: 0.8753 - val_accuracy: 0.5000\n",
      "Epoch 349/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7511 - accuracy: 0.6875\n",
      "Epoch 349: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8285 - accuracy: 0.6554 - val_loss: 0.9232 - val_accuracy: 0.5405\n",
      "Epoch 350/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9022 - accuracy: 0.5625\n",
      "Epoch 350: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8321 - accuracy: 0.6115 - val_loss: 0.9119 - val_accuracy: 0.4730\n",
      "Epoch 351/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8001 - accuracy: 0.6562\n",
      "Epoch 351: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8035 - accuracy: 0.6284 - val_loss: 0.9301 - val_accuracy: 0.5270\n",
      "Epoch 352/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7177 - accuracy: 0.7500\n",
      "Epoch 352: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8019 - accuracy: 0.6250 - val_loss: 0.9368 - val_accuracy: 0.5811\n",
      "Epoch 353/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9522 - accuracy: 0.5625\n",
      "Epoch 353: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8782 - accuracy: 0.5912 - val_loss: 0.9135 - val_accuracy: 0.4865\n",
      "Epoch 354/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6653 - accuracy: 0.6562\n",
      "Epoch 354: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8331 - accuracy: 0.6486 - val_loss: 0.9596 - val_accuracy: 0.4730\n",
      "Epoch 355/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0345 - accuracy: 0.4688\n",
      "Epoch 355: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8925 - accuracy: 0.5676 - val_loss: 0.9686 - val_accuracy: 0.5541\n",
      "Epoch 356/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8259 - accuracy: 0.5625\n",
      "Epoch 356: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9646 - accuracy: 0.5608 - val_loss: 0.9002 - val_accuracy: 0.5135\n",
      "Epoch 357/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8403 - accuracy: 0.5938\n",
      "Epoch 357: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8877 - accuracy: 0.5946 - val_loss: 0.9058 - val_accuracy: 0.5135\n",
      "Epoch 358/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9104 - accuracy: 0.5312\n",
      "Epoch 358: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8885 - accuracy: 0.5845 - val_loss: 0.9136 - val_accuracy: 0.5405\n",
      "Epoch 359/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8654 - accuracy: 0.5938\n",
      "Epoch 359: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8619 - accuracy: 0.6115 - val_loss: 0.9221 - val_accuracy: 0.5135\n",
      "Epoch 360/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8885 - accuracy: 0.5625\n",
      "Epoch 360: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8599 - accuracy: 0.5811 - val_loss: 0.9527 - val_accuracy: 0.5270\n",
      "Epoch 361/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8090 - accuracy: 0.6875\n",
      "Epoch 361: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8801 - accuracy: 0.5777 - val_loss: 0.8978 - val_accuracy: 0.5270\n",
      "Epoch 362/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9029 - accuracy: 0.5625\n",
      "Epoch 362: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8414 - accuracy: 0.6216 - val_loss: 0.8696 - val_accuracy: 0.5135\n",
      "Epoch 363/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6048 - accuracy: 0.7812\n",
      "Epoch 363: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8276 - accuracy: 0.6149 - val_loss: 0.8727 - val_accuracy: 0.5405\n",
      "Epoch 364/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8121 - accuracy: 0.7188\n",
      "Epoch 364: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8550 - accuracy: 0.6115 - val_loss: 0.8749 - val_accuracy: 0.5270\n",
      "Epoch 365/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9155 - accuracy: 0.6562\n",
      "Epoch 365: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9157 - accuracy: 0.6047 - val_loss: 0.9319 - val_accuracy: 0.5000\n",
      "Epoch 366/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8095 - accuracy: 0.6875\n",
      "Epoch 366: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8634 - accuracy: 0.6115 - val_loss: 0.9332 - val_accuracy: 0.5000\n",
      "Epoch 367/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7016 - accuracy: 0.6875\n",
      "Epoch 367: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8236 - accuracy: 0.6284 - val_loss: 0.9249 - val_accuracy: 0.5541\n",
      "Epoch 368/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7544 - accuracy: 0.5938\n",
      "Epoch 368: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8364 - accuracy: 0.6115 - val_loss: 0.9195 - val_accuracy: 0.5405\n",
      "Epoch 369/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7426 - accuracy: 0.6250\n",
      "Epoch 369: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8428 - accuracy: 0.6081 - val_loss: 0.9015 - val_accuracy: 0.5676\n",
      "Epoch 370/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6413 - accuracy: 0.6250\n",
      "Epoch 370: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8904 - accuracy: 0.6014 - val_loss: 0.9296 - val_accuracy: 0.5405\n",
      "Epoch 371/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8635 - accuracy: 0.5938\n",
      "Epoch 371: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8585 - accuracy: 0.6216 - val_loss: 0.9414 - val_accuracy: 0.5405\n",
      "Epoch 372/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9313 - accuracy: 0.6250\n",
      "Epoch 372: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8440 - accuracy: 0.5845 - val_loss: 0.9350 - val_accuracy: 0.5405\n",
      "Epoch 373/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6371 - accuracy: 0.7188\n",
      "Epoch 373: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8267 - accuracy: 0.6385 - val_loss: 0.9123 - val_accuracy: 0.5405\n",
      "Epoch 374/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8604 - accuracy: 0.6250\n",
      "Epoch 374: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8512 - accuracy: 0.5946 - val_loss: 0.8915 - val_accuracy: 0.5405\n",
      "Epoch 375/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9774 - accuracy: 0.6250\n",
      "Epoch 375: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8050 - accuracy: 0.6419 - val_loss: 0.8936 - val_accuracy: 0.5135\n",
      "Epoch 376/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7967 - accuracy: 0.5938\n",
      "Epoch 376: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8906 - accuracy: 0.6081 - val_loss: 0.8953 - val_accuracy: 0.5270\n",
      "Epoch 377/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7942 - accuracy: 0.6562\n",
      "Epoch 377: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8413 - accuracy: 0.6250 - val_loss: 0.8839 - val_accuracy: 0.5405\n",
      "Epoch 378/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7086 - accuracy: 0.5938\n",
      "Epoch 378: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8240 - accuracy: 0.6216 - val_loss: 0.9105 - val_accuracy: 0.5135\n",
      "Epoch 379/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0115 - accuracy: 0.4375\n",
      "Epoch 379: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.6385 - val_loss: 0.8932 - val_accuracy: 0.5270\n",
      "Epoch 380/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9127 - accuracy: 0.5938\n",
      "Epoch 380: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8076 - accuracy: 0.6182 - val_loss: 0.8707 - val_accuracy: 0.5270\n",
      "Epoch 381/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6437 - accuracy: 0.7188\n",
      "Epoch 381: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8076 - accuracy: 0.6385 - val_loss: 0.8592 - val_accuracy: 0.5000\n",
      "Epoch 382/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0474 - accuracy: 0.4688\n",
      "Epoch 382: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8189 - accuracy: 0.6250 - val_loss: 0.8615 - val_accuracy: 0.5270\n",
      "Epoch 383/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8448 - accuracy: 0.5625\n",
      "Epoch 383: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8470 - accuracy: 0.6149 - val_loss: 0.9349 - val_accuracy: 0.4730\n",
      "Epoch 384/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0012 - accuracy: 0.5938\n",
      "Epoch 384: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8627 - accuracy: 0.5811 - val_loss: 0.9968 - val_accuracy: 0.5405\n",
      "Epoch 385/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0188 - accuracy: 0.5938\n",
      "Epoch 385: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8325 - accuracy: 0.5946 - val_loss: 0.9187 - val_accuracy: 0.5541\n",
      "Epoch 386/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9280 - accuracy: 0.6250\n",
      "Epoch 386: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8617 - accuracy: 0.6284 - val_loss: 0.8954 - val_accuracy: 0.5270\n",
      "Epoch 387/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9250 - accuracy: 0.4375\n",
      "Epoch 387: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8653 - accuracy: 0.6081 - val_loss: 0.8953 - val_accuracy: 0.5405\n",
      "Epoch 388/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7597 - accuracy: 0.5625\n",
      "Epoch 388: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8402 - accuracy: 0.5878 - val_loss: 0.9394 - val_accuracy: 0.5405\n",
      "Epoch 389/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8900 - accuracy: 0.5938\n",
      "Epoch 389: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8441 - accuracy: 0.6081 - val_loss: 0.9126 - val_accuracy: 0.4865\n",
      "Epoch 390/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6841 - accuracy: 0.7500\n",
      "Epoch 390: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8133 - accuracy: 0.6385 - val_loss: 0.9253 - val_accuracy: 0.5676\n",
      "Epoch 391/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7298 - accuracy: 0.5625\n",
      "Epoch 391: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8212 - accuracy: 0.6318 - val_loss: 0.9445 - val_accuracy: 0.5541\n",
      "Epoch 392/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0139 - accuracy: 0.4688\n",
      "Epoch 392: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8457 - accuracy: 0.6149 - val_loss: 0.8895 - val_accuracy: 0.5270\n",
      "Epoch 393/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5844 - accuracy: 0.7812\n",
      "Epoch 393: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8509 - accuracy: 0.6182 - val_loss: 0.9052 - val_accuracy: 0.5135\n",
      "Epoch 394/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8070 - accuracy: 0.6250\n",
      "Epoch 394: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8770 - accuracy: 0.6014 - val_loss: 0.9027 - val_accuracy: 0.5405\n",
      "Epoch 395/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8748 - accuracy: 0.7188\n",
      "Epoch 395: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8381 - accuracy: 0.6149 - val_loss: 0.8714 - val_accuracy: 0.5270\n",
      "Epoch 396/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6914 - accuracy: 0.7188\n",
      "Epoch 396: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7777 - accuracy: 0.6723 - val_loss: 0.9072 - val_accuracy: 0.5270\n",
      "Epoch 397/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7094 - accuracy: 0.6250\n",
      "Epoch 397: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7748 - accuracy: 0.6554 - val_loss: 0.9111 - val_accuracy: 0.5541\n",
      "Epoch 398/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8052 - accuracy: 0.5312\n",
      "Epoch 398: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8161 - accuracy: 0.6081 - val_loss: 0.9222 - val_accuracy: 0.5541\n",
      "Epoch 399/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8863 - accuracy: 0.4688\n",
      "Epoch 399: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8467 - accuracy: 0.5878 - val_loss: 0.8889 - val_accuracy: 0.5270\n",
      "Epoch 400/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8190 - accuracy: 0.6562\n",
      "Epoch 400: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8308 - accuracy: 0.6453 - val_loss: 0.8757 - val_accuracy: 0.5541\n",
      "Epoch 401/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7388 - accuracy: 0.6875\n",
      "Epoch 401: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7977 - accuracy: 0.6351 - val_loss: 0.8743 - val_accuracy: 0.5676\n",
      "Epoch 402/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7924 - accuracy: 0.6250\n",
      "Epoch 402: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7945 - accuracy: 0.6149 - val_loss: 0.9025 - val_accuracy: 0.5541\n",
      "Epoch 403/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6977 - accuracy: 0.7500\n",
      "Epoch 403: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7968 - accuracy: 0.6419 - val_loss: 0.9018 - val_accuracy: 0.5541\n",
      "Epoch 404/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1633 - accuracy: 0.5312\n",
      "Epoch 404: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8455 - accuracy: 0.5946 - val_loss: 0.8905 - val_accuracy: 0.5541\n",
      "Epoch 405/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0487 - accuracy: 0.5000\n",
      "Epoch 405: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8319 - accuracy: 0.5878 - val_loss: 0.8818 - val_accuracy: 0.5405\n",
      "Epoch 406/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6904 - accuracy: 0.7188\n",
      "Epoch 406: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7902 - accuracy: 0.6419 - val_loss: 0.9405 - val_accuracy: 0.5405\n",
      "Epoch 407/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6824 - accuracy: 0.7188\n",
      "Epoch 407: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8229 - accuracy: 0.6115 - val_loss: 0.9128 - val_accuracy: 0.5135\n",
      "Epoch 408/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7426 - accuracy: 0.6875\n",
      "Epoch 408: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8123 - accuracy: 0.6419 - val_loss: 0.8821 - val_accuracy: 0.5405\n",
      "Epoch 409/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8589 - accuracy: 0.6562\n",
      "Epoch 409: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8052 - accuracy: 0.6520 - val_loss: 0.9050 - val_accuracy: 0.5270\n",
      "Epoch 410/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.6562\n",
      "Epoch 410: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7897 - accuracy: 0.6182 - val_loss: 0.8931 - val_accuracy: 0.5405\n",
      "Epoch 411/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8803 - accuracy: 0.5625\n",
      "Epoch 411: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7805 - accuracy: 0.6216 - val_loss: 0.8703 - val_accuracy: 0.5405\n",
      "Epoch 412/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7410 - accuracy: 0.6250\n",
      "Epoch 412: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8142 - accuracy: 0.6250 - val_loss: 0.8483 - val_accuracy: 0.5541\n",
      "Epoch 413/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7211 - accuracy: 0.5938\n",
      "Epoch 413: val_loss did not improve from 0.84636\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.6318 - val_loss: 0.8467 - val_accuracy: 0.5405\n",
      "Epoch 414/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7078 - accuracy: 0.7188\n",
      "Epoch 414: val_loss improved from 0.84636 to 0.83521, saving model to saved_models\\audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7918 - accuracy: 0.6182 - val_loss: 0.8352 - val_accuracy: 0.5405\n",
      "Epoch 415/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8313 - accuracy: 0.6250\n",
      "Epoch 415: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7752 - accuracy: 0.6554 - val_loss: 0.9651 - val_accuracy: 0.5541\n",
      "Epoch 416/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7333 - accuracy: 0.6562\n",
      "Epoch 416: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8147 - accuracy: 0.6588 - val_loss: 0.9050 - val_accuracy: 0.5405\n",
      "Epoch 417/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9036 - accuracy: 0.6562\n",
      "Epoch 417: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8067 - accuracy: 0.6520 - val_loss: 0.9090 - val_accuracy: 0.5405\n",
      "Epoch 418/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7278 - accuracy: 0.6562\n",
      "Epoch 418: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7441 - accuracy: 0.6723 - val_loss: 0.9307 - val_accuracy: 0.5541\n",
      "Epoch 419/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6367 - accuracy: 0.7812\n",
      "Epoch 419: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7583 - accuracy: 0.6284 - val_loss: 0.9296 - val_accuracy: 0.5405\n",
      "Epoch 420/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7610 - accuracy: 0.6562\n",
      "Epoch 420: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7690 - accuracy: 0.6520 - val_loss: 0.9206 - val_accuracy: 0.5676\n",
      "Epoch 421/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8370 - accuracy: 0.5000\n",
      "Epoch 421: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7741 - accuracy: 0.6284 - val_loss: 0.8874 - val_accuracy: 0.5270\n",
      "Epoch 422/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8454 - accuracy: 0.5000\n",
      "Epoch 422: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8225 - accuracy: 0.6250 - val_loss: 0.8472 - val_accuracy: 0.5405\n",
      "Epoch 423/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7123 - accuracy: 0.6250\n",
      "Epoch 423: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7937 - accuracy: 0.6318 - val_loss: 0.9089 - val_accuracy: 0.5405\n",
      "Epoch 424/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6308 - accuracy: 0.7500\n",
      "Epoch 424: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7880 - accuracy: 0.6284 - val_loss: 0.9130 - val_accuracy: 0.5405\n",
      "Epoch 425/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7829 - accuracy: 0.5938\n",
      "Epoch 425: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7929 - accuracy: 0.6486 - val_loss: 0.8487 - val_accuracy: 0.5270\n",
      "Epoch 426/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7408 - accuracy: 0.6562\n",
      "Epoch 426: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7893 - accuracy: 0.6419 - val_loss: 0.8536 - val_accuracy: 0.5135\n",
      "Epoch 427/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7579 - accuracy: 0.7188\n",
      "Epoch 427: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8024 - accuracy: 0.6351 - val_loss: 0.8512 - val_accuracy: 0.5270\n",
      "Epoch 428/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6709 - accuracy: 0.7812\n",
      "Epoch 428: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7637 - accuracy: 0.6486 - val_loss: 0.8846 - val_accuracy: 0.5405\n",
      "Epoch 429/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8021 - accuracy: 0.6875\n",
      "Epoch 429: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7898 - accuracy: 0.6081 - val_loss: 0.9037 - val_accuracy: 0.5405\n",
      "Epoch 430/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8521 - accuracy: 0.5625\n",
      "Epoch 430: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7818 - accuracy: 0.6486 - val_loss: 0.9625 - val_accuracy: 0.5541\n",
      "Epoch 431/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0969 - accuracy: 0.5000\n",
      "Epoch 431: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7569 - accuracy: 0.6216 - val_loss: 1.0437 - val_accuracy: 0.5135\n",
      "Epoch 432/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8300 - accuracy: 0.5938\n",
      "Epoch 432: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7764 - accuracy: 0.6486 - val_loss: 0.8594 - val_accuracy: 0.5405\n",
      "Epoch 433/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8986 - accuracy: 0.5625\n",
      "Epoch 433: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7664 - accuracy: 0.6824 - val_loss: 0.8840 - val_accuracy: 0.5541\n",
      "Epoch 434/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7767 - accuracy: 0.5312\n",
      "Epoch 434: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8336 - accuracy: 0.6182 - val_loss: 0.9575 - val_accuracy: 0.5270\n",
      "Epoch 435/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5689 - accuracy: 0.7500\n",
      "Epoch 435: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7692 - accuracy: 0.6453 - val_loss: 0.8864 - val_accuracy: 0.5405\n",
      "Epoch 436/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8878 - accuracy: 0.5625\n",
      "Epoch 436: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7845 - accuracy: 0.6486 - val_loss: 0.9339 - val_accuracy: 0.5405\n",
      "Epoch 437/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5672 - accuracy: 0.7812\n",
      "Epoch 437: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8159 - accuracy: 0.6486 - val_loss: 0.9148 - val_accuracy: 0.5541\n",
      "Epoch 438/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8038 - accuracy: 0.6875\n",
      "Epoch 438: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7827 - accuracy: 0.6520 - val_loss: 0.8917 - val_accuracy: 0.5405\n",
      "Epoch 439/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5710 - accuracy: 0.8125\n",
      "Epoch 439: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7698 - accuracy: 0.6655 - val_loss: 0.8450 - val_accuracy: 0.5405\n",
      "Epoch 440/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8236 - accuracy: 0.6562\n",
      "Epoch 440: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8199 - accuracy: 0.6554 - val_loss: 0.8935 - val_accuracy: 0.5541\n",
      "Epoch 441/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1103 - accuracy: 0.5000\n",
      "Epoch 441: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8805 - accuracy: 0.6216 - val_loss: 0.9548 - val_accuracy: 0.5270\n",
      "Epoch 442/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0237 - accuracy: 0.5625\n",
      "Epoch 442: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8050 - accuracy: 0.6486 - val_loss: 0.8863 - val_accuracy: 0.5405\n",
      "Epoch 443/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9697 - accuracy: 0.6562\n",
      "Epoch 443: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8749 - accuracy: 0.6284 - val_loss: 0.9735 - val_accuracy: 0.5270\n",
      "Epoch 444/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6505 - accuracy: 0.6562\n",
      "Epoch 444: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7866 - accuracy: 0.6318 - val_loss: 0.9722 - val_accuracy: 0.5000\n",
      "Epoch 445/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9007 - accuracy: 0.5938\n",
      "Epoch 445: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8280 - accuracy: 0.6216 - val_loss: 0.8890 - val_accuracy: 0.5676\n",
      "Epoch 446/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7668 - accuracy: 0.6562\n",
      "Epoch 446: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7747 - accuracy: 0.6486 - val_loss: 0.9084 - val_accuracy: 0.5676\n",
      "Epoch 447/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8985 - accuracy: 0.5938\n",
      "Epoch 447: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8040 - accuracy: 0.6385 - val_loss: 0.9528 - val_accuracy: 0.5405\n",
      "Epoch 448/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7228 - accuracy: 0.7188\n",
      "Epoch 448: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7640 - accuracy: 0.6588 - val_loss: 0.9385 - val_accuracy: 0.5676\n",
      "Epoch 449/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1009 - accuracy: 0.5000\n",
      "Epoch 449: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8012 - accuracy: 0.6419 - val_loss: 0.9073 - val_accuracy: 0.5541\n",
      "Epoch 450/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9839 - accuracy: 0.5312\n",
      "Epoch 450: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7800 - accuracy: 0.6351 - val_loss: 0.8915 - val_accuracy: 0.5541\n",
      "Epoch 451/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7167 - accuracy: 0.7500\n",
      "Epoch 451: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7796 - accuracy: 0.6655 - val_loss: 0.9048 - val_accuracy: 0.5405\n",
      "Epoch 452/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8194 - accuracy: 0.7500\n",
      "Epoch 452: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8191 - accuracy: 0.6655 - val_loss: 0.8653 - val_accuracy: 0.5405\n",
      "Epoch 453/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8763 - accuracy: 0.5000\n",
      "Epoch 453: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8320 - accuracy: 0.6520 - val_loss: 0.8907 - val_accuracy: 0.5541\n",
      "Epoch 454/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9742 - accuracy: 0.6250\n",
      "Epoch 454: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8050 - accuracy: 0.6182 - val_loss: 0.8987 - val_accuracy: 0.5405\n",
      "Epoch 455/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7372 - accuracy: 0.7812\n",
      "Epoch 455: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7634 - accuracy: 0.6655 - val_loss: 0.9163 - val_accuracy: 0.5270\n",
      "Epoch 456/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9391 - accuracy: 0.5938\n",
      "Epoch 456: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7898 - accuracy: 0.6419 - val_loss: 0.9317 - val_accuracy: 0.5270\n",
      "Epoch 457/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8202 - accuracy: 0.6250\n",
      "Epoch 457: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.6588 - val_loss: 0.9421 - val_accuracy: 0.5405\n",
      "Epoch 458/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7174 - accuracy: 0.6562\n",
      "Epoch 458: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8123 - accuracy: 0.6385 - val_loss: 0.9090 - val_accuracy: 0.5270\n",
      "Epoch 459/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9729 - accuracy: 0.6250\n",
      "Epoch 459: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8028 - accuracy: 0.6588 - val_loss: 0.9477 - val_accuracy: 0.5270\n",
      "Epoch 460/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9262 - accuracy: 0.5938\n",
      "Epoch 460: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7949 - accuracy: 0.6622 - val_loss: 0.9694 - val_accuracy: 0.5405\n",
      "Epoch 461/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9704 - accuracy: 0.5312\n",
      "Epoch 461: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8033 - accuracy: 0.6486 - val_loss: 0.9152 - val_accuracy: 0.5135\n",
      "Epoch 462/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7180 - accuracy: 0.7500\n",
      "Epoch 462: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7906 - accuracy: 0.6520 - val_loss: 0.9022 - val_accuracy: 0.5405\n",
      "Epoch 463/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7188\n",
      "Epoch 463: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8105 - accuracy: 0.6689 - val_loss: 0.9031 - val_accuracy: 0.5405\n",
      "Epoch 464/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0447 - accuracy: 0.4375\n",
      "Epoch 464: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7911 - accuracy: 0.6216 - val_loss: 0.8887 - val_accuracy: 0.5405\n",
      "Epoch 465/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7185 - accuracy: 0.6250\n",
      "Epoch 465: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7957 - accuracy: 0.6318 - val_loss: 0.8687 - val_accuracy: 0.5541\n",
      "Epoch 466/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9024 - accuracy: 0.5938\n",
      "Epoch 466: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7463 - accuracy: 0.6655 - val_loss: 0.9343 - val_accuracy: 0.5405\n",
      "Epoch 467/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7500 - accuracy: 0.6562\n",
      "Epoch 467: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7814 - accuracy: 0.6318 - val_loss: 0.9067 - val_accuracy: 0.5405\n",
      "Epoch 468/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7493 - accuracy: 0.6875\n",
      "Epoch 468: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7742 - accuracy: 0.6757 - val_loss: 0.8880 - val_accuracy: 0.5270\n",
      "Epoch 469/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8436 - accuracy: 0.6562\n",
      "Epoch 469: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7834 - accuracy: 0.6385 - val_loss: 0.8905 - val_accuracy: 0.5270\n",
      "Epoch 470/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8733 - accuracy: 0.6562\n",
      "Epoch 470: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7949 - accuracy: 0.6149 - val_loss: 0.8850 - val_accuracy: 0.5135\n",
      "Epoch 471/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9879 - accuracy: 0.5625\n",
      "Epoch 471: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8294 - accuracy: 0.6115 - val_loss: 0.9318 - val_accuracy: 0.5270\n",
      "Epoch 472/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7419 - accuracy: 0.6875\n",
      "Epoch 472: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8650 - accuracy: 0.6351 - val_loss: 0.9421 - val_accuracy: 0.5270\n",
      "Epoch 473/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8216 - accuracy: 0.5938\n",
      "Epoch 473: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.6250 - val_loss: 0.8669 - val_accuracy: 0.5270\n",
      "Epoch 474/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6481 - accuracy: 0.6562\n",
      "Epoch 474: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7951 - accuracy: 0.6318 - val_loss: 0.9338 - val_accuracy: 0.5135\n",
      "Epoch 475/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1130 - accuracy: 0.5312\n",
      "Epoch 475: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8324 - accuracy: 0.6486 - val_loss: 0.9162 - val_accuracy: 0.5811\n",
      "Epoch 476/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8667 - accuracy: 0.6562\n",
      "Epoch 476: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8119 - accuracy: 0.6554 - val_loss: 0.9222 - val_accuracy: 0.5541\n",
      "Epoch 477/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7196 - accuracy: 0.6250\n",
      "Epoch 477: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8118 - accuracy: 0.6318 - val_loss: 0.9219 - val_accuracy: 0.5135\n",
      "Epoch 478/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7892 - accuracy: 0.5938\n",
      "Epoch 478: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8391 - accuracy: 0.6318 - val_loss: 0.8944 - val_accuracy: 0.5270\n",
      "Epoch 479/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7682 - accuracy: 0.6250\n",
      "Epoch 479: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7731 - accuracy: 0.6318 - val_loss: 0.8638 - val_accuracy: 0.5270\n",
      "Epoch 480/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8290 - accuracy: 0.6562\n",
      "Epoch 480: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8080 - accuracy: 0.6520 - val_loss: 0.8959 - val_accuracy: 0.5270\n",
      "Epoch 481/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8459 - accuracy: 0.5938\n",
      "Epoch 481: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8527 - accuracy: 0.6351 - val_loss: 0.8726 - val_accuracy: 0.5270\n",
      "Epoch 482/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9361 - accuracy: 0.6250\n",
      "Epoch 482: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8074 - accuracy: 0.6385 - val_loss: 0.8735 - val_accuracy: 0.5405\n",
      "Epoch 483/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8183 - accuracy: 0.5938\n",
      "Epoch 483: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8287 - accuracy: 0.6385 - val_loss: 0.8566 - val_accuracy: 0.5270\n",
      "Epoch 484/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5913 - accuracy: 0.7188\n",
      "Epoch 484: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7162 - accuracy: 0.6689 - val_loss: 0.8554 - val_accuracy: 0.5405\n",
      "Epoch 485/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0574 - accuracy: 0.4688\n",
      "Epoch 485: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7769 - accuracy: 0.6115 - val_loss: 0.8509 - val_accuracy: 0.5405\n",
      "Epoch 486/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8100 - accuracy: 0.6562\n",
      "Epoch 486: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8251 - accuracy: 0.6047 - val_loss: 0.8874 - val_accuracy: 0.5270\n",
      "Epoch 487/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0107 - accuracy: 0.5000\n",
      "Epoch 487: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7872 - accuracy: 0.6149 - val_loss: 0.9166 - val_accuracy: 0.5270\n",
      "Epoch 488/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6750 - accuracy: 0.6875\n",
      "Epoch 488: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7928 - accuracy: 0.6351 - val_loss: 0.9144 - val_accuracy: 0.5676\n",
      "Epoch 489/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7055 - accuracy: 0.8125\n",
      "Epoch 489: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7709 - accuracy: 0.6486 - val_loss: 0.8746 - val_accuracy: 0.5405\n",
      "Epoch 490/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6144 - accuracy: 0.7812\n",
      "Epoch 490: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7379 - accuracy: 0.6858 - val_loss: 0.8703 - val_accuracy: 0.5405\n",
      "Epoch 491/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7711 - accuracy: 0.6875\n",
      "Epoch 491: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7826 - accuracy: 0.6723 - val_loss: 0.8988 - val_accuracy: 0.5270\n",
      "Epoch 492/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6325 - accuracy: 0.6875\n",
      "Epoch 492: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7536 - accuracy: 0.6622 - val_loss: 0.9151 - val_accuracy: 0.5135\n",
      "Epoch 493/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7349 - accuracy: 0.6562\n",
      "Epoch 493: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8831 - accuracy: 0.6284 - val_loss: 0.9195 - val_accuracy: 0.5811\n",
      "Epoch 494/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7448 - accuracy: 0.6250\n",
      "Epoch 494: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8096 - accuracy: 0.6385 - val_loss: 0.8895 - val_accuracy: 0.5676\n",
      "Epoch 495/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8357 - accuracy: 0.6875\n",
      "Epoch 495: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7983 - accuracy: 0.6250 - val_loss: 0.8477 - val_accuracy: 0.5541\n",
      "Epoch 496/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8331 - accuracy: 0.6250\n",
      "Epoch 496: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8027 - accuracy: 0.6554 - val_loss: 0.8794 - val_accuracy: 0.5676\n",
      "Epoch 497/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9510 - accuracy: 0.7188\n",
      "Epoch 497: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7880 - accuracy: 0.6622 - val_loss: 0.9023 - val_accuracy: 0.6351\n",
      "Epoch 498/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8152 - accuracy: 0.5938\n",
      "Epoch 498: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8009 - accuracy: 0.6486 - val_loss: 0.8852 - val_accuracy: 0.5676\n",
      "Epoch 499/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7047 - accuracy: 0.6875\n",
      "Epoch 499: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8781 - accuracy: 0.6318 - val_loss: 0.9456 - val_accuracy: 0.5270\n",
      "Epoch 500/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0171 - accuracy: 0.5312\n",
      "Epoch 500: val_loss did not improve from 0.83521\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9138 - accuracy: 0.5676 - val_loss: 0.9184 - val_accuracy: 0.5405\n",
      "Training completed in time:  0:00:26.230940\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Cargo       1.00      0.08      0.15        24\n",
      "   Passenger       0.55      0.80      0.65        20\n",
      "      Tanker       0.42      0.68      0.52        19\n",
      "         Tug       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.55        74\n",
      "   macro avg       0.70      0.62      0.55        74\n",
      "weighted avg       0.70      0.55      0.49        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Decode labels\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5540540814399719\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded)\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
